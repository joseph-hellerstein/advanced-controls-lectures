{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECH_hoT8ftZa"
   },
   "source": [
    "# DYNAMICAL SYSTEMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUcZvvx3LPKt"
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kbJEla5AftZd",
    "outputId": "7ab5a1f3-916b-40d5-840c-669be0418f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controlSBML version: 1.0.5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import controlSBML as ctl\n",
    "except:\n",
    "    !pip -q install controlSBML\n",
    "    import controlSBML as ctl\n",
    "from controlSBML.util import makeSimulationTimes\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sympy as sy\n",
    "import tellurium as te\n",
    "print(\"controlSBML version: \" + ctl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LINEAR_MDL = \"\"\"\n",
    "S1 -> S2; k1*S1\n",
    "S2 -> S3; k2*S2\n",
    "S3 -> S4; k3*S3\n",
    "\n",
    "k1 = 2\n",
    "k2 = 1.5\n",
    "k3 = 1\n",
    "S1 = 10\n",
    "S2 = 0\n",
    "S3 = 0\n",
    "S4 = 0\n",
    "\"\"\"\n",
    "LINEAR_RR = te.loada(LINEAR_MDL)\n",
    "LINEAR_DATA = LINEAR_RR.simulate()\n",
    "LINEAR_DF = ctl.Timeseries(LINEAR_DATA, columns=LINEAR_DATA.colnames)\n",
    "LINEAR_RR.plot(LINEAR_DATA)\n",
    "LINEAR_STATE_NAMES = [\"S1\", \"S2\", \"S3\", \"S4\"]\n",
    "LINEAR_PARAM_DCT = {\"input_names\": LINEAR_STATE_NAMES, \"output_names\": LINEAR_STATE_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Timeseries in module controlSBML.timeseries:\n",
      "\n",
      "class Timeseries(pandas.core.frame.DataFrame)\n",
      " |  Timeseries(mat, times=None, columns=None)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Timeseries\n",
      " |      pandas.core.frame.DataFrame\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.indexing.IndexingMixin\n",
      " |      pandas.core.arraylike.OpsMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |      Return a Timeseries object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key: column of Timeseries\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Timeseries\n",
      " |  \n",
      " |  __init__(self, mat, times=None, columns=None)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mat: DataFrame, numpy.darray, NamedArray\n",
      " |      times: list-float (time in seconds)\n",
      " |      columns: list-str\n",
      " |      \n",
      " |      Notes:\n",
      " |          1. Assigning a value to times overrides an existing time index.\n",
      " |          2. A column labelled \"time\" overrides an index.\n",
      " |          3. For DataFrames, if index.name is \"milliseconds\", then times\n",
      " |             are not converted.\n",
      " |  \n",
      " |  align(self, other)\n",
      " |      Returns objects with the same indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other: Timeseries/TimeseriesSer\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Timeseries/TimeseriesSer, Timeseries/Timeseries/Ser\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  mat2TS(mat, column_names=None, row_names=None)\n",
      " |      Converts a numpy ndarray or array-like to a Timeseries.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mat: np.Array, NamedArray, DataFrame\n",
      " |      column_names: list-str\n",
      " |      row_names: list-str\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  df\n",
      " |  \n",
      " |  times\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.frame.DataFrame:\n",
      " |  \n",
      " |  __dataframe__(self, nan_as_null: 'bool' = False, allow_copy: 'bool' = True) -> 'DataFrameXchg'\n",
      " |      Return the dataframe interchange object implementing the interchange protocol.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nan_as_null : bool, default False\n",
      " |          Whether to tell the DataFrame to overwrite null values in the data\n",
      " |          with ``NaN`` (or ``NaT``).\n",
      " |      allow_copy : bool, default True\n",
      " |          Whether to allow memory copying when exporting. If set to False\n",
      " |          it would cause non-zero-copy exports to fail.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame interchange object\n",
      " |          The object which consuming library can use to ingress the dataframe.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Details on the interchange protocol:\n",
      " |      https://data-apis.org/dataframe-protocol/latest/index.html\n",
      " |      \n",
      " |      `nan_as_null` currently has no effect; once support for nullable extension\n",
      " |      dtypes is added, this value should be propagated to columns.\n",
      " |  \n",
      " |  __divmod__(self, other) -> 'tuple[DataFrame, DataFrame]'\n",
      " |  \n",
      " |  __len__(self) -> 'int'\n",
      " |      Returns length of info axis, but here we use the index.\n",
      " |  \n",
      " |  __matmul__(self, other: 'AnyArrayLike | DataFrame') -> 'DataFrame | Series'\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __rdivmod__(self, other) -> 'tuple[DataFrame, DataFrame]'\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular DataFrame.\n",
      " |  \n",
      " |  __rmatmul__(self, other) -> 'DataFrame'\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  add(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `radd`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  agg = aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when Series.agg is called with single function\n",
      " |          * Series : when DataFrame.agg is called with a single function\n",
      " |          * DataFrame : when DataFrame.agg is called with several functions\n",
      " |      \n",
      " |          Return scalar, Series or DataFrame.\n",
      " |      \n",
      " |      The aggregation operations are always performed over an axis, either the\n",
      " |      index (default) or the column axis. This behavior is different from\n",
      " |      `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      " |      `var`), where the default is to compute the aggregation of the flattened\n",
      " |      array, e.g., ``numpy.mean(arr_2d)`` as opposed to\n",
      " |      ``numpy.mean(arr_2d, axis=0)``.\n",
      " |      \n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Perform any type of operations.\n",
      " |      DataFrame.transform : Perform transformation type operations.\n",
      " |      core.groupby.GroupBy : Perform operations over groups.\n",
      " |      core.resample.Resampler : Perform operations over resampled bins.\n",
      " |      core.window.Rolling : Perform operations over rolling window.\n",
      " |      core.window.Expanding : Perform operations over expanding window.\n",
      " |      core.window.ExponentialMovingWindow : Perform operation over exponential weighted\n",
      " |          window.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3],\n",
      " |      ...                    [4, 5, 6],\n",
      " |      ...                    [7, 8, 9],\n",
      " |      ...                    [np.nan, np.nan, np.nan]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Aggregate these functions over the rows.\n",
      " |      \n",
      " |      >>> df.agg(['sum', 'min'])\n",
      " |              A     B     C\n",
      " |      sum  12.0  15.0  18.0\n",
      " |      min   1.0   2.0   3.0\n",
      " |      \n",
      " |      Different aggregations per column.\n",
      " |      \n",
      " |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      " |              A    B\n",
      " |      sum  12.0  NaN\n",
      " |      min   1.0  2.0\n",
      " |      max   NaN  8.0\n",
      " |      \n",
      " |      Aggregate different functions over the columns and rename the index of the resulting\n",
      " |      DataFrame.\n",
      " |      \n",
      " |      >>> df.agg(x=('A', max), y=('B', 'min'), z=('C', np.mean))\n",
      " |           A    B    C\n",
      " |      x  7.0  NaN  NaN\n",
      " |      y  NaN  2.0  NaN\n",
      " |      z  NaN  NaN  6.0\n",
      " |      \n",
      " |      Aggregate over the columns.\n",
      " |      \n",
      " |      >>> df.agg(\"mean\", axis=\"columns\")\n",
      " |      0    2.0\n",
      " |      1    5.0\n",
      " |      2    8.0\n",
      " |      3    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is False or equivalent (e.g. zero or\n",
      " |      empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced. For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be True, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.all : Return True if all elements are True.\n",
      " |      DataFrame.any : Return True if one (or more) elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      >>> pd.Series([], dtype=\"float64\").all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrames**\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if values in each column all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if values in each row all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, *, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True, potentially over an axis.\n",
      " |      \n",
      " |      Returns False unless there is at least one element within a series or\n",
      " |      along a Dataframe axis that is True or equivalent (e.g. non-zero or\n",
      " |      non-empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced. For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be False, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.any : Numpy version of this method.\n",
      " |      Series.any : Return whether any element is True.\n",
      " |      Series.all : Return whether all elements are True.\n",
      " |      DataFrame.any : Return whether any element is True over requested axis.\n",
      " |      DataFrame.all : Return whether all elements are True over requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([False, False]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      >>> pd.Series([], dtype=\"float64\").any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, other, ignore_index: 'bool' = False, verify_integrity: 'bool' = False, sort: 'bool' = False) -> 'DataFrame'\n",
      " |      Append rows of `other` to the end of caller, returning a new object.\n",
      " |      \n",
      " |      .. deprecated:: 1.4.0\n",
      " |          Use :func:`concat` instead. For further details see\n",
      " |          :ref:`whatsnew_140.deprecations.frame_series_append`\n",
      " |      \n",
      " |      Columns in `other` that are not in the caller are added as new columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series/dict-like object, or list of these\n",
      " |          The data to append.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      verify_integrity : bool, default False\n",
      " |          If True, raise ValueError on creating index with duplicates.\n",
      " |      sort : bool, default False\n",
      " |          Sort columns if the columns of `self` and `other` are not aligned.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |              Changed to not sort by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A new DataFrame consisting of the rows of caller and the rows of `other`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      concat : General function to concatenate DataFrame or Series objects.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If a list of dict/series is passed and the keys are all contained in\n",
      " |      the DataFrame's index, the order of the columns in the resulting\n",
      " |      DataFrame will be unchanged.\n",
      " |      \n",
      " |      Iteratively appending rows to a DataFrame can be more computationally\n",
      " |      intensive than a single concatenate. A better solution is to append\n",
      " |      those rows to a list and then concatenate the list with the original\n",
      " |      DataFrame all at once.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'), index=['x', 'y'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      x  1  2\n",
      " |      y  3  4\n",
      " |      >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'), index=['x', 'y'])\n",
      " |      >>> df.append(df2)\n",
      " |         A  B\n",
      " |      x  1  2\n",
      " |      y  3  4\n",
      " |      x  5  6\n",
      " |      y  7  8\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> df.append(df2, ignore_index=True)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      3  7  8\n",
      " |      \n",
      " |      The following, while not recommended methods for generating DataFrames,\n",
      " |      show two ways to generate a DataFrame from multiple data sources.\n",
      " |      \n",
      " |      Less efficient:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(columns=['A'])\n",
      " |      >>> for i in range(5):\n",
      " |      ...     df = df.append({'A': i}, ignore_index=True)\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |      \n",
      " |      More efficient:\n",
      " |      \n",
      " |      >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
      " |      ...           ignore_index=True)\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |  \n",
      " |  apply(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type: \"Literal['expand', 'reduce', 'broadcast'] | None\" = None, args=(), **kwargs)\n",
      " |      Apply a function along an axis of the DataFrame.\n",
      " |      \n",
      " |      Objects passed to the function are Series objects whose index is\n",
      " |      either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      " |      (``axis=1``). By default (``result_type=None``), the final return type\n",
      " |      is inferred from the return type of the applied function. Otherwise,\n",
      " |      it depends on the `result_type` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to each column or row.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the function is applied:\n",
      " |      \n",
      " |          * 0 or 'index': apply function to each column.\n",
      " |          * 1 or 'columns': apply function to each row.\n",
      " |      \n",
      " |      raw : bool, default False\n",
      " |          Determines if row or column is passed as a Series or ndarray object:\n",
      " |      \n",
      " |          * ``False`` : passes each row or column as a Series to the\n",
      " |            function.\n",
      " |          * ``True`` : the passed function will receive ndarray objects\n",
      " |            instead.\n",
      " |            If you are just applying a NumPy reduction function this will\n",
      " |            achieve much better performance.\n",
      " |      \n",
      " |      result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      " |          These only act when ``axis=1`` (columns):\n",
      " |      \n",
      " |          * 'expand' : list-like results will be turned into columns.\n",
      " |          * 'reduce' : returns a Series if possible rather than expanding\n",
      " |            list-like results. This is the opposite of 'expand'.\n",
      " |          * 'broadcast' : results will be broadcast to the original shape\n",
      " |            of the DataFrame, the original index and columns will be\n",
      " |            retained.\n",
      " |      \n",
      " |          The default behaviour (None) depends on the return value of the\n",
      " |          applied function: list-like results will be returned as a Series\n",
      " |          of those. However if the apply function returns a Series these\n",
      " |          are expanded to columns.\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to `func` in addition to the\n",
      " |          array/series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Result of applying ``func`` along the given axis of the\n",
      " |          DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.applymap: For elementwise operations.\n",
      " |      DataFrame.aggregate: Only perform aggregating type operations.\n",
      " |      DataFrame.transform: Only perform transforming type operations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  4  9\n",
      " |      1  4  9\n",
      " |      2  4  9\n",
      " |      \n",
      " |      Using a numpy universal function (in this case the same as\n",
      " |      ``np.sqrt(df)``):\n",
      " |      \n",
      " |      >>> df.apply(np.sqrt)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  2.0  3.0\n",
      " |      2  2.0  3.0\n",
      " |      \n",
      " |      Using a reducing function on either axis\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=0)\n",
      " |      A    12\n",
      " |      B    27\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=1)\n",
      " |      0    13\n",
      " |      1    13\n",
      " |      2    13\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Returning a list-like will result in a Series\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1)\n",
      " |      0    [1, 2]\n",
      " |      1    [1, 2]\n",
      " |      2    [1, 2]\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Passing ``result_type='expand'`` will expand list-like results\n",
      " |      to columns of a Dataframe\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      " |         0  1\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |      \n",
      " |      Returning a Series inside the function is similar to passing\n",
      " |      ``result_type='expand'``. The resulting column names\n",
      " |      will be the Series index.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      " |         foo  bar\n",
      " |      0    1    2\n",
      " |      1    1    2\n",
      " |      2    1    2\n",
      " |      \n",
      " |      Passing ``result_type='broadcast'`` will ensure the same shape\n",
      " |      result, whether list-like or scalar is returned by the function,\n",
      " |      and broadcast it along the axis. The resulting column names will\n",
      " |      be the originals.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |  \n",
      " |  applymap(self, func: 'PythonFuncType', na_action: 'str | None' = None, **kwargs) -> 'DataFrame'\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |      \n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If ‘ignore’, propagate NaN values, without passing them to func.\n",
      " |      \n",
      " |          .. versionadded:: 1.2\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |      \n",
      " |      Like Series.map, NA values can be ignored:\n",
      " |      \n",
      " |      >>> df_copy = df.copy()\n",
      " |      >>> df_copy.iloc[0, 0] = pd.NA\n",
      " |      >>> df_copy.applymap(lambda x: len(str(x)), na_action='ignore')\n",
      " |           0  1\n",
      " |      0  NaN  4\n",
      " |      1  5.0  5\n",
      " |      \n",
      " |      Note that a vectorized version of `func` often exists, which will\n",
      " |      be much faster. You could square each number elementwise.\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: x**2)\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |      \n",
      " |      But it's better to avoid applymap in that case.\n",
      " |      \n",
      " |      >>> df ** 2\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |  \n",
      " |  asfreq(self, freq: 'Frequency', method: 'FillnaOptions | None' = None, how: 'str | None' = None, normalize: 'bool' = False, fill_value: 'Hashable' = None) -> 'DataFrame'\n",
      " |      Convert time series to specified frequency.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency.\n",
      " |      \n",
      " |      If the index of this DataFrame is a :class:`~pandas.PeriodIndex`, the new index\n",
      " |      is the result of transforming the original index with\n",
      " |      :meth:`PeriodIndex.asfreq <pandas.PeriodIndex.asfreq>` (so the original index\n",
      " |      will map one-to-one to the new index).\n",
      " |      \n",
      " |      Otherwise, the new index will be equivalent to ``pd.date_range(start, end,\n",
      " |      freq=freq)`` where ``start`` and ``end`` are, respectively, the first and\n",
      " |      last entries in the original index (see :func:`pandas.date_range`). The\n",
      " |      values corresponding to any timesteps in the new index which were not present\n",
      " |      in the original index will be null (``NaN``), unless a method for filling\n",
      " |      such unknowns is provided (see the ``method`` parameter below).\n",
      " |      \n",
      " |      The :meth:`resample` method is more appropriate if an operation on each group of\n",
      " |      timesteps (such as an aggregate) is necessary to represent the data at the new\n",
      " |      frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset or str\n",
      " |          Frequency DateOffset or string.\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill.\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only (see PeriodIndex.asfreq).\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight.\n",
      " |      fill_value : scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame object reindexed to the specified frequency.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex : Conform DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s': series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |  \n",
      " |  assign(self, **kwargs) -> 'DataFrame'\n",
      " |      Assign new columns to a DataFrame.\n",
      " |      \n",
      " |      Returns a new object with all original columns in addition to new ones.\n",
      " |      Existing columns that are re-assigned will be overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict of {str: callable or Series}\n",
      " |          The column names are keywords. If the values are\n",
      " |          callable, they are computed on the DataFrame and\n",
      " |          assigned to the new columns. The callable must not\n",
      " |          change input DataFrame (though pandas doesn't check it).\n",
      " |          If the values are not callable, (e.g. a Series, scalar, or array),\n",
      " |          they are simply assigned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A new DataFrame with the new columns in addition to\n",
      " |          all the existing columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Assigning multiple columns within the same ``assign`` is possible.\n",
      " |      Later items in '\\*\\*kwargs' may refer to newly created or modified\n",
      " |      columns in 'df'; items are computed and assigned into 'df' in order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n",
      " |      ...                   index=['Portland', 'Berkeley'])\n",
      " |      >>> df\n",
      " |                temp_c\n",
      " |      Portland    17.0\n",
      " |      Berkeley    25.0\n",
      " |      \n",
      " |      Where the value is a callable, evaluated on `df`:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |      \n",
      " |      Alternatively, the same behavior can be achieved by directly\n",
      " |      referencing an existing Series or sequence:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |      \n",
      " |      You can create multiple columns within the same assign where one\n",
      " |      of the columns depends on another one defined within the same assign:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\n",
      " |      ...           temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9)\n",
      " |                temp_c  temp_f  temp_k\n",
      " |      Portland    17.0    62.6  290.15\n",
      " |      Berkeley    25.0    77.0  298.15\n",
      " |  \n",
      " |  bfill(self, *, axis: 'None | Axis' = None, inplace: 'bool' = False, limit: 'None | int' = None, downcast=None) -> 'DataFrame | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  boxplot = boxplot_frame(self, column=None, by=None, ax=None, fontsize=None, rot: 'int' = 0, grid: 'bool' = True, figsize=None, layout=None, return_type=None, backend=None, **kwargs)\n",
      " |      Make a box plot from DataFrame columns.\n",
      " |      \n",
      " |      Make a box-and-whisker plot from DataFrame columns, optionally grouped\n",
      " |      by some other columns. A box plot is a method for graphically depicting\n",
      " |      groups of numerical data through their quartiles.\n",
      " |      The box extends from the Q1 to Q3 quartile values of the data,\n",
      " |      with a line at the median (Q2). The whiskers extend from the edges\n",
      " |      of box to show the range of the data. By default, they extend no more than\n",
      " |      `1.5 * IQR (IQR = Q3 - Q1)` from the edges of the box, ending at the farthest\n",
      " |      data point within that interval. Outliers are plotted as separate dots.\n",
      " |      \n",
      " |      For further details see\n",
      " |      Wikipedia's entry for `boxplot <https://en.wikipedia.org/wiki/Box_plot>`_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str or list of str, optional\n",
      " |          Column name or list of names, or vector.\n",
      " |          Can be any valid input to :meth:`pandas.DataFrame.groupby`.\n",
      " |      by : str or array-like, optional\n",
      " |          Column in the DataFrame to :meth:`pandas.DataFrame.groupby`.\n",
      " |          One box-plot will be done per value of columns in `by`.\n",
      " |      ax : object of class matplotlib.axes.Axes, optional\n",
      " |          The matplotlib axes to be used by boxplot.\n",
      " |      fontsize : float or str\n",
      " |          Tick label font size in points or as a string (e.g., `large`).\n",
      " |      rot : int or float, default 0\n",
      " |          The rotation angle of labels (in degrees)\n",
      " |          with respect to the screen coordinate system.\n",
      " |      grid : bool, default True\n",
      " |          Setting this to True will show the grid.\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |          The size of the figure to create in matplotlib.\n",
      " |      layout : tuple (rows, columns), optional\n",
      " |          For example, (3, 5) will display the subplots\n",
      " |          using 3 columns and 5 rows, starting from the top-left.\n",
      " |      return_type : {'axes', 'dict', 'both'} or None, default 'axes'\n",
      " |          The kind of object to return. The default is ``axes``.\n",
      " |      \n",
      " |          * 'axes' returns the matplotlib axes the boxplot is drawn on.\n",
      " |          * 'dict' returns a dictionary whose values are the matplotlib\n",
      " |            Lines of the boxplot.\n",
      " |          * 'both' returns a namedtuple with the axes and dict.\n",
      " |          * when grouping with ``by``, a Series mapping columns to\n",
      " |            ``return_type`` is returned.\n",
      " |      \n",
      " |            If ``return_type`` is `None`, a NumPy array\n",
      " |            of axes with the same shape as ``layout`` is returned.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :func:`matplotlib.pyplot.boxplot`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result\n",
      " |          See Notes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.plot.hist: Make a histogram.\n",
      " |      matplotlib.pyplot.boxplot : Matplotlib equivalent plot.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The return type depends on the `return_type` parameter:\n",
      " |      \n",
      " |      * 'axes' : object of class matplotlib.axes.Axes\n",
      " |      * 'dict' : dict of matplotlib.lines.Line2D objects\n",
      " |      * 'both' : a namedtuple with structure (ax, lines)\n",
      " |      \n",
      " |      For data grouped with ``by``, return a Series of the above or a numpy\n",
      " |      array:\n",
      " |      \n",
      " |      * :class:`~pandas.Series`\n",
      " |      * :class:`~numpy.array` (for ``return_type = None``)\n",
      " |      \n",
      " |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      " |      of the lines after plotting. In this case a dict containing the Lines\n",
      " |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Boxplots can be created for every column in the dataframe\n",
      " |      by ``df.boxplot()`` or indicating the columns to be used:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> np.random.seed(1234)\n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 4),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  # doctest: +SKIP\n",
      " |      \n",
      " |      Boxplots of variables distributions grouped by the values of a third\n",
      " |      variable can be created using the option ``by``. For instance:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 2),\n",
      " |          ...                   columns=['Col1', 'Col2'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> boxplot = df.boxplot(by='X')\n",
      " |      \n",
      " |      A list of strings (i.e. ``['X', 'Y']``) can be passed to boxplot\n",
      " |      in order to group the data by combination of the variables in the x-axis:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 3),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',\n",
      " |          ...                      'B', 'A', 'B', 'A', 'B'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])\n",
      " |      \n",
      " |      The layout of boxplot can be adjusted giving a tuple to ``layout``:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      layout=(2, 1))\n",
      " |      \n",
      " |      Additional formatting can be done to the boxplot, like suppressing the grid\n",
      " |      (``grid=False``), rotating the labels in the x-axis (i.e. ``rot=45``)\n",
      " |      or changing the fontsize (i.e. ``fontsize=15``):\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  # doctest: +SKIP\n",
      " |      \n",
      " |      The parameter ``return_type`` can be used to select the type of element\n",
      " |      returned by `boxplot`.  When ``return_type='axes'`` is selected,\n",
      " |      the matplotlib axes on which the boxplot is drawn are returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'matplotlib.axes._subplots.AxesSubplot'>\n",
      " |      \n",
      " |      When grouping with ``by``, a Series mapping columns to ``return_type``\n",
      " |      is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'pandas.core.series.Series'>\n",
      " |      \n",
      " |      If ``return_type`` is `None`, a NumPy array of axes with the same shape\n",
      " |      as ``layout`` is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type=None)\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'numpy.ndarray'>\n",
      " |  \n",
      " |  clip(self: 'DataFrame', lower: 'float | None' = None, upper: 'float | None' = None, *args, axis: 'Axis | None' = None, inplace: 'bool' = False, **kwargs) -> 'DataFrame | None'\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array-like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      upper : float or array-like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |          For `Series` this parameter is unused and defaults to `None`.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Trim values at input threshold in series.\n",
      " |      DataFrame.clip : Trim values at input threshold in dataframe.\n",
      " |      numpy.clip : Clip (limit) the values in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |      \n",
      " |      Clips using specific lower threshold per column element, with missing values:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, np.NaN, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2.0\n",
      " |      1   -4.0\n",
      " |      2    NaN\n",
      " |      3    6.0\n",
      " |      4    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df.clip(t, axis=0)\n",
      " |      col_0  col_1\n",
      " |      0      9      2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  combine(self, other: 'DataFrame', func: 'Callable[[Series, Series], Series | Hashable]', fill_value=None, overwrite: 'bool' = True) -> 'DataFrame'\n",
      " |      Perform column-wise combine with another DataFrame.\n",
      " |      \n",
      " |      Combines a DataFrame with `other` DataFrame using `func`\n",
      " |      to element-wise combine columns. The row and column indexes of the\n",
      " |      resulting DataFrame will be the union of the two.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          The DataFrame to merge column-wise.\n",
      " |      func : function\n",
      " |          Function that takes two series as inputs and return a Series or a\n",
      " |          scalar. Used to merge the two dataframes column by columns.\n",
      " |      fill_value : scalar value, default None\n",
      " |          The value to fill NaNs with prior to passing any column to the\n",
      " |          merge func.\n",
      " |      overwrite : bool, default True\n",
      " |          If True, columns in `self` that do not exist in `other` will be\n",
      " |          overwritten with NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Combination of the provided DataFrames.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      " |          non-null values in frame calling the method.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Combine using a simple function that chooses the smaller column.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |         A  B\n",
      " |      0  0  3\n",
      " |      1  0  3\n",
      " |      \n",
      " |      Example using a true element-wise combine function.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, np.minimum)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  0  3\n",
      " |      \n",
      " |      Using `fill_value` fills Nones prior to passing the column to the\n",
      " |      merge function.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |         A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  4.0\n",
      " |      \n",
      " |      However, if the same element in both dataframes is None, that None\n",
      " |      is preserved\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |          A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  3.0\n",
      " |      \n",
      " |      Example that demonstrates the use of `overwrite` and behavior when\n",
      " |      the axis differ between the dataframes.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |           A    B     C\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |      \n",
      " |      >>> df1.combine(df2, take_smaller, overwrite=False)\n",
      " |           A    B     C\n",
      " |      0  0.0  NaN   NaN\n",
      " |      1  0.0  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |      \n",
      " |      Demonstrating the preference of the passed in dataframe.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\n",
      " |      >>> df2.combine(df1, take_smaller)\n",
      " |         A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 NaN\n",
      " |      2  NaN  3.0 NaN\n",
      " |      \n",
      " |      >>> df2.combine(df1, take_smaller, overwrite=False)\n",
      " |           A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 1.0\n",
      " |      2  NaN  3.0 1.0\n",
      " |  \n",
      " |  combine_first(self, other: 'DataFrame') -> 'DataFrame'\n",
      " |      Update null elements with value in the same location in `other`.\n",
      " |      \n",
      " |      Combine two DataFrame objects by filling null values in one DataFrame\n",
      " |      with non-null values from other DataFrame. The row and column indexes\n",
      " |      of the resulting DataFrame will be the union of the two. The resulting\n",
      " |      dataframe contains the 'first' dataframe values and overrides the\n",
      " |      second one values where both first.loc[index, col] and\n",
      " |      second.loc[index, col] are not missing values, upon calling\n",
      " |      first.combine_first(second).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Provided DataFrame to use to fill null values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of combining the provided DataFrame with the other object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine : Perform series-wise operation on two DataFrames\n",
      " |          using a given function.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B\n",
      " |      0  1.0  3.0\n",
      " |      1  0.0  4.0\n",
      " |      \n",
      " |      Null values still persist if the location of that null value\n",
      " |      does not exist in `other`\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B    C\n",
      " |      0  NaN  4.0  NaN\n",
      " |      1  0.0  3.0  1.0\n",
      " |      2  NaN  3.0  1.0\n",
      " |  \n",
      " |  compare(self, other: 'DataFrame', align_axis: 'Axis' = 1, keep_shape: 'bool' = False, keep_equal: 'bool' = False, result_names: 'Suffixes' = ('self', 'other')) -> 'DataFrame'\n",
      " |      Compare to another DataFrame and show the differences.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Object to compare with.\n",
      " |      \n",
      " |      align_axis : {0 or 'index', 1 or 'columns'}, default 1\n",
      " |          Determine which axis to align the comparison on.\n",
      " |      \n",
      " |          * 0, or 'index' : Resulting differences are stacked vertically\n",
      " |              with rows drawn alternately from self and other.\n",
      " |          * 1, or 'columns' : Resulting differences are aligned horizontally\n",
      " |              with columns drawn alternately from self and other.\n",
      " |      \n",
      " |      keep_shape : bool, default False\n",
      " |          If true, all rows and columns are kept.\n",
      " |          Otherwise, only the ones with different values are kept.\n",
      " |      \n",
      " |      keep_equal : bool, default False\n",
      " |          If true, the result keeps values that are equal.\n",
      " |          Otherwise, equal values are shown as NaNs.\n",
      " |      \n",
      " |      result_names : tuple, default ('self', 'other')\n",
      " |          Set the dataframes names in the comparison.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame that shows the differences stacked side by side.\n",
      " |      \n",
      " |          The resulting index will be a MultiIndex with 'self' and 'other'\n",
      " |          stacked alternately at the inner level.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the two DataFrames don't have identical labels or shape.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.compare : Compare with another Series and show differences.\n",
      " |      DataFrame.equals : Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Matching NaNs will not appear as a difference.\n",
      " |      \n",
      " |      Can only compare identically-labeled\n",
      " |      (i.e. same shape, identical row and column labels) DataFrames\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n",
      " |      ...         \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n",
      " |      ...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n",
      " |      ...     },\n",
      " |      ...     columns=[\"col1\", \"col2\", \"col3\"],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |        col1  col2  col3\n",
      " |      0    a   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   3.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |      \n",
      " |      >>> df2 = df.copy()\n",
      " |      >>> df2.loc[0, 'col1'] = 'c'\n",
      " |      >>> df2.loc[2, 'col3'] = 4.0\n",
      " |      >>> df2\n",
      " |        col1  col2  col3\n",
      " |      0    c   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   4.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |      \n",
      " |      Align the differences on columns\n",
      " |      \n",
      " |      >>> df.compare(df2)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  NaN   NaN\n",
      " |      2  NaN   NaN  3.0   4.0\n",
      " |      \n",
      " |      Assign result_names\n",
      " |      \n",
      " |      >>> df.compare(df2, result_names=(\"left\", \"right\"))\n",
      " |        col1       col3\n",
      " |        left right left right\n",
      " |      0    a     c  NaN   NaN\n",
      " |      2  NaN   NaN  3.0   4.0\n",
      " |      \n",
      " |      Stack the differences on rows\n",
      " |      \n",
      " |      >>> df.compare(df2, align_axis=0)\n",
      " |              col1  col3\n",
      " |      0 self     a   NaN\n",
      " |        other    c   NaN\n",
      " |      2 self   NaN   3.0\n",
      " |        other  NaN   4.0\n",
      " |      \n",
      " |      Keep the equal values\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_equal=True)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  1.0   1.0\n",
      " |      2    b     b  3.0   4.0\n",
      " |      \n",
      " |      Keep all original rows and columns\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_shape=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  NaN   NaN  NaN   NaN\n",
      " |      1  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      2  NaN   NaN  NaN   NaN  3.0   4.0\n",
      " |      3  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      4  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      \n",
      " |      Keep all original rows and columns and also all original values\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_shape=True, keep_equal=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  1.0   1.0  1.0   1.0\n",
      " |      1    a     a  2.0   2.0  2.0   2.0\n",
      " |      2    b     b  3.0   3.0  3.0   4.0\n",
      " |      3    b     b  NaN   NaN  4.0   4.0\n",
      " |      4    a     a  5.0   5.0  5.0   5.0\n",
      " |  \n",
      " |  corr(self, method: 'str | Callable[[np.ndarray, np.ndarray], float]' = 'pearson', min_periods: 'int' = 1, numeric_only: 'bool | lib.NoDefault' = <no_default>) -> 'DataFrame'\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float. Note that the returned matrix from corr\n",
      " |              will have 1 along the diagonals and will be symmetric\n",
      " |              regardless of the callable's behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for Pearson\n",
      " |          and Spearman correlation.\n",
      " |      numeric_only : bool, default True\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              The default value of ``numeric_only`` will be ``False`` in a future\n",
      " |              version of pandas.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Correlation matrix.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Pearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\n",
      " |      \n",
      " |      * `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`_\n",
      " |      * `Kendall rank correlation coefficient <https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient>`_\n",
      " |      * `Spearman's rank correlation coefficient <https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   0.3\n",
      " |      cats   0.3   1.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(min_periods=3)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   NaN\n",
      " |      cats   NaN   1.0\n",
      " |  \n",
      " |  corrwith(self, other: 'DataFrame | Series', axis: 'Axis' = 0, drop: 'bool' = False, method: \"Literal['pearson', 'kendall', 'spearman'] | Callable[[np.ndarray, np.ndarray], float]\" = 'pearson', numeric_only: 'bool | lib.NoDefault' = <no_default>) -> 'Series'\n",
      " |      Compute pairwise correlation.\n",
      " |      \n",
      " |      Pairwise correlation is computed between rows or columns of\n",
      " |      DataFrame with rows or columns of Series or DataFrame. DataFrames\n",
      " |      are first aligned along both axes before computing the\n",
      " |      correlations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |          Object with which to compute correlations.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' to compute row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      drop : bool, default False\n",
      " |          Drop missing indices from result.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float.\n",
      " |      \n",
      " |      numeric_only : bool, default True\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              The default value of ``numeric_only`` will be ``False`` in a future\n",
      " |              version of pandas.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Pairwise correlations.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
      " |      >>> columns = [\"one\", \"two\", \"three\", \"four\"]\n",
      " |      >>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n",
      " |      >>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n",
      " |      >>> df1.corrwith(df2)\n",
      " |      one      1.0\n",
      " |      two      1.0\n",
      " |      three    1.0\n",
      " |      four     1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df2.corrwith(df1, axis=1)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  count(self, axis: 'Axis' = 0, level: 'Level' = None, numeric_only: 'bool' = False)\n",
      " |      Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n",
      " |      on `pandas.options.mode.use_inf_as_na`) are considered NA.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          If 0 or 'index' counts are generated for each column.\n",
      " |          If 1 or 'columns' counts are generated for each row.\n",
      " |      level : int or str, optional\n",
      " |          If the axis is a `MultiIndex` (hierarchical), count along a\n",
      " |          particular `level`, collapsing into a `DataFrame`.\n",
      " |          A `str` specifies the level name.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          For each column/row the number of non-NA/null entries.\n",
      " |          If `level` is specified returns a `DataFrame`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: Number of non-NA elements in a Series.\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |      DataFrame.shape: Number of DataFrame rows and columns (including NA\n",
      " |          elements).\n",
      " |      DataFrame.isna: Boolean same-sized DataFrame showing places of NA\n",
      " |          elements.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Constructing DataFrame from a dictionary:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"Person\":\n",
      " |      ...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n",
      " |      ...                    \"Age\": [24., np.nan, 21., 33, 26],\n",
      " |      ...                    \"Single\": [False, True, True, True, False]})\n",
      " |      >>> df\n",
      " |         Person   Age  Single\n",
      " |      0    John  24.0   False\n",
      " |      1    Myla   NaN    True\n",
      " |      2   Lewis  21.0    True\n",
      " |      3    John  33.0    True\n",
      " |      4    Myla  26.0   False\n",
      " |      \n",
      " |      Notice the uncounted NA values:\n",
      " |      \n",
      " |      >>> df.count()\n",
      " |      Person    5\n",
      " |      Age       4\n",
      " |      Single    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Counts for each **row**:\n",
      " |      \n",
      " |      >>> df.count(axis='columns')\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  cov(self, min_periods: 'int | None' = None, ddof: 'int | None' = 1, numeric_only: 'bool | lib.NoDefault' = <no_default>) -> 'DataFrame'\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      numeric_only : bool, default True\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              The default value of ``numeric_only`` will be ``False`` in a future\n",
      " |              version of pandas.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.cov : Compute covariance with another Series.\n",
      " |      core.window.ewm.ExponentialMovingWindow.cov : Exponential weighted sample\n",
      " |          covariance.\n",
      " |      core.window.expanding.Expanding.cov : Expanding sample covariance.\n",
      " |      core.window.rolling.Rolling.cov : Rolling sample covariance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-ddof.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative maximum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.max : Return the maximum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative minimum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.min : Return the minimum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative product of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.prod : Return the product over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative sum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.sum : Return the sum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  diff(self, periods: 'int' = 1, axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a DataFrame element compared with another\n",
      " |      element in the DataFrame (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          First differences of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pct_change: Percent change over given number of periods.\n",
      " |      DataFrame.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      Series.diff: First discrete difference of object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      " |      :meth:`operator.sub`.\n",
      " |      The result is calculated according to current dtype in DataFrame,\n",
      " |      however dtype of the result is always float64.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |      \n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |      \n",
      " |      Difference with previous column\n",
      " |      \n",
      " |      >>> df.diff(axis=1)\n",
      " |          a  b   c\n",
      " |      0 NaN  0   0\n",
      " |      1 NaN -1   3\n",
      " |      2 NaN -1   7\n",
      " |      3 NaN -1  13\n",
      " |      4 NaN  0  20\n",
      " |      5 NaN  2  28\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |      \n",
      " |      Overflow in input dtype\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 0]}, dtype=np.uint8)\n",
      " |      >>> df.diff()\n",
      " |             a\n",
      " |      0    NaN\n",
      " |      1  255.0\n",
      " |  \n",
      " |  div = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  divide = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  dot(self, other: 'AnyArrayLike | DataFrame') -> 'DataFrame | Series'\n",
      " |      Compute the matrix multiplication between the DataFrame and other.\n",
      " |      \n",
      " |      This method computes the matrix product between the DataFrame and the\n",
      " |      values of an other Series, DataFrame or a numpy array.\n",
      " |      \n",
      " |      It can also be called using ``self @ other`` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame or array-like\n",
      " |          The other object to compute the matrix product with.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If other is a Series, return the matrix product between self and\n",
      " |          other as a Series. If other is a DataFrame or a numpy.array, return\n",
      " |          the matrix product of self and other in a DataFrame of a np.array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dot: Similar method for Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dimensions of DataFrame and other must be compatible in order to\n",
      " |      compute the matrix multiplication. In addition, the column names of\n",
      " |      DataFrame and the index of other must contain the same values, as they\n",
      " |      will be aligned prior to the multiplication.\n",
      " |      \n",
      " |      The dot method for Series computes the inner product, instead of the\n",
      " |      matrix product here.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Here we multiply a DataFrame with a Series.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n",
      " |      >>> s = pd.Series([1, 1, 2, 1])\n",
      " |      >>> df.dot(s)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Here we multiply a DataFrame with another DataFrame.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(other)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      Note that the dot method give the same result as @\n",
      " |      \n",
      " |      >>> df @ other\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      The dot method works also if other is an np.array.\n",
      " |      \n",
      " |      >>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(arr)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      Note how shuffling of the objects does not change the result.\n",
      " |      \n",
      " |      >>> s2 = s.reindex([1, 0, 2, 3])\n",
      " |      >>> df.dot(s2)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  drop(self, labels: 'IndexLabel' = None, *, axis: 'Axis' = 0, index: 'IndexLabel' = None, columns: 'IndexLabel' = None, level: 'Level' = None, inplace: 'bool' = False, errors: 'IgnoreRaise' = 'raise') -> 'DataFrame | None'\n",
      " |      Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Remove rows or columns by specifying label names and corresponding\n",
      " |      axis, or by specifying directly index or column names. When using a\n",
      " |      multi-index, labels on different levels can be removed by specifying\n",
      " |      the level. See the `user guide <advanced.shown_levels>`\n",
      " |      for more information about the now unused levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index or column labels to drop. A tuple will be used as a single\n",
      " |          label and not treated as a list-like.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Whether to drop labels from the index (0 or 'index') or\n",
      " |          columns (1 or 'columns').\n",
      " |      index : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=0``\n",
      " |          is equivalent to ``index=labels``).\n",
      " |      columns : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=1``\n",
      " |          is equivalent to ``columns=labels``).\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level from which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If False, return a copy. Otherwise, do operation\n",
      " |          inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are\n",
      " |          dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame without the removed index or column labels or\n",
      " |          None if ``inplace=True``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Label-location based indexer for selection by label.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      " |          removed, optionally only considering certain columns.\n",
      " |      Series.drop : Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
      " |      ...                   columns=['A', 'B', 'C', 'D'])\n",
      " |      >>> df\n",
      " |         A  B   C   D\n",
      " |      0  0  1   2   3\n",
      " |      1  4  5   6   7\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns\n",
      " |      \n",
      " |      >>> df.drop(['B', 'C'], axis=1)\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      >>> df.drop(columns=['B', 'C'])\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      Drop a row by index\n",
      " |      \n",
      " |      >>> df.drop([0, 1])\n",
      " |         A  B   C   D\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns and/or rows of MultiIndex DataFrame\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      " |      ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      " |      ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      " |      ...                         [1, 0.8], [0.3, 0.2]])\n",
      " |      >>> df\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |              length  0.3     0.2\n",
      " |      \n",
      " |      Drop a specific index combination from the MultiIndex\n",
      " |      DataFrame, i.e., drop the combination ``'falcon'`` and\n",
      " |      ``'weight'``, which deletes only the corresponding row\n",
      " |      \n",
      " |      >>> df.drop(index=('falcon', 'weight'))\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              length  0.3     0.2\n",
      " |      \n",
      " |      >>> df.drop(index='cow', columns='small')\n",
      " |                      big\n",
      " |      lama    speed   45.0\n",
      " |              weight  200.0\n",
      " |              length  1.5\n",
      " |      falcon  speed   320.0\n",
      " |              weight  1.0\n",
      " |              length  0.3\n",
      " |      \n",
      " |      >>> df.drop(index='length', level=1)\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |  \n",
      " |  drop_duplicates(self, subset: 'Hashable | Sequence[Hashable] | None' = None, *, keep: \"Literal['first', 'last', False]\" = 'first', inplace: 'bool' = False, ignore_index: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Return DataFrame with duplicate rows removed.\n",
      " |      \n",
      " |      Considering certain columns is optional. Indexes, including time indexes\n",
      " |      are ignored.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Determines which duplicates (if any) to keep.\n",
      " |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      " |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      " |          - False : Drop all duplicates.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with duplicates removed or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      By default, it removes duplicate rows based on all columns.\n",
      " |      \n",
      " |      >>> df.drop_duplicates()\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      To remove duplicates on specific column(s), use ``subset``.\n",
      " |      \n",
      " |      >>> df.drop_duplicates(subset=['brand'])\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      \n",
      " |      To remove duplicates and keep last occurrences, use ``keep``.\n",
      " |      \n",
      " |      >>> df.drop_duplicates(subset=['brand', 'style'], keep='last')\n",
      " |          brand style  rating\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      4  Indomie  pack     5.0\n",
      " |  \n",
      " |  dropna(self, *, axis: 'Axis' = 0, how: 'str | NoDefault' = <no_default>, thresh: 'int | NoDefault' = <no_default>, subset: 'IndexLabel' = None, inplace: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Remove missing values.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine if rows or columns which contain missing values are\n",
      " |          removed.\n",
      " |      \n",
      " |          * 0, or 'index' : Drop rows which contain missing values.\n",
      " |          * 1, or 'columns' : Drop columns which contain missing value.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             Pass tuple or list to drop on multiple axes.\n",
      " |             Only a single axis is allowed.\n",
      " |      \n",
      " |      how : {'any', 'all'}, default 'any'\n",
      " |          Determine if row or column is removed from DataFrame, when we have\n",
      " |          at least one NA or all NA.\n",
      " |      \n",
      " |          * 'any' : If any NA values are present, drop that row or column.\n",
      " |          * 'all' : If all values are NA, drop that row or column.\n",
      " |      \n",
      " |      thresh : int, optional\n",
      " |          Require that many non-NA values. Cannot be combined with how.\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      " |          these would be a list of columns to include.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with NA entries dropped from it or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isna: Indicate missing values.\n",
      " |      DataFrame.notna : Indicate existing (non-missing) values.\n",
      " |      DataFrame.fillna : Replace missing values.\n",
      " |      Series.dropna : Drop missing values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      " |      ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      " |      ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      " |      ...                             pd.NaT]})\n",
      " |      >>> df\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Drop the rows where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna()\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |      \n",
      " |      Drop the columns where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna(axis='columns')\n",
      " |             name\n",
      " |      0    Alfred\n",
      " |      1    Batman\n",
      " |      2  Catwoman\n",
      " |      \n",
      " |      Drop the rows where all elements are missing.\n",
      " |      \n",
      " |      >>> df.dropna(how='all')\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Keep only the rows with at least 2 non-NA values.\n",
      " |      \n",
      " |      >>> df.dropna(thresh=2)\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Define in which columns to look for missing values.\n",
      " |      \n",
      " |      >>> df.dropna(subset=['name', 'toy'])\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Keep the DataFrame with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> df.dropna(inplace=True)\n",
      " |      >>> df\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |  \n",
      " |  duplicated(self, subset: 'Hashable | Sequence[Hashable] | None' = None, keep: \"Literal['first', 'last', False]\" = 'first') -> 'Series'\n",
      " |      Return boolean Series denoting duplicate rows.\n",
      " |      \n",
      " |      Considering certain columns is optional.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Determines which duplicates (if any) to mark.\n",
      " |      \n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Boolean series for each duplicated rows.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.duplicated : Equivalent method on index.\n",
      " |      Series.duplicated : Equivalent method on Series.\n",
      " |      Series.drop_duplicates : Remove duplicate values from Series.\n",
      " |      DataFrame.drop_duplicates : Remove duplicate values from DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      By default, for each set of duplicated values, the first occurrence\n",
      " |      is set on False and all others on True.\n",
      " |      \n",
      " |      >>> df.duplicated()\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True.\n",
      " |      \n",
      " |      >>> df.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By setting ``keep`` on False, all duplicates are True.\n",
      " |      \n",
      " |      >>> df.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      To find duplicates on specific column(s), use ``subset``.\n",
      " |      \n",
      " |      >>> df.duplicated(subset=['brand'])\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3     True\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  eq(self, other, axis='columns', level=None)\n",
      " |      Get Equal to of dataframe and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  eval(self, expr: 'str', *, inplace: 'bool' = False, **kwargs) -> 'Any | None'\n",
      " |      Evaluate a string describing operations on DataFrame columns.\n",
      " |      \n",
      " |      Operates on columns only, not specific rows or elements.  This allows\n",
      " |      `eval` to run arbitrary code, which can make you vulnerable to code\n",
      " |      injection if you pass user input to this function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The expression string to evaluate.\n",
      " |      inplace : bool, default False\n",
      " |          If the expression contains an assignment, whether to perform the\n",
      " |          operation inplace and mutate the existing DataFrame. Otherwise,\n",
      " |          a new DataFrame is returned.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by\n",
      " |          :meth:`~pandas.DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray, scalar, pandas object, or None\n",
      " |          The result of the evaluation or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.query : Evaluates a boolean expression to query the columns\n",
      " |          of a frame.\n",
      " |      DataFrame.assign : Can evaluate an expression or function to create new\n",
      " |          values for a column.\n",
      " |      eval : Evaluate a Python expression as a string using various\n",
      " |          backends.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For more details see the API documentation for :func:`~eval`.\n",
      " |      For detailed examples see :ref:`enhancing performance with eval\n",
      " |      <enhancingperf.eval>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      >>> df.eval('A + B')\n",
      " |      0    11\n",
      " |      1    10\n",
      " |      2     9\n",
      " |      3     8\n",
      " |      4     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Assignment is allowed though by default the original DataFrame is not\n",
      " |      modified.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B')\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      \n",
      " |      Use ``inplace=True`` to modify the original DataFrame.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B', inplace=True)\n",
      " |      >>> df\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      \n",
      " |      Multiple columns can be assigned to using multi-line expressions:\n",
      " |      \n",
      " |      >>> df.eval(\n",
      " |      ...     '''\n",
      " |      ... C = A + B\n",
      " |      ... D = A - B\n",
      " |      ... '''\n",
      " |      ... )\n",
      " |         A   B   C  D\n",
      " |      0  1  10  11 -9\n",
      " |      1  2   8  10 -6\n",
      " |      2  3   6   9 -3\n",
      " |      3  4   4   8  0\n",
      " |      4  5   2   7  3\n",
      " |  \n",
      " |  explode(self, column: 'IndexLabel', ignore_index: 'bool' = False) -> 'DataFrame'\n",
      " |      Transform each element of a list-like to a row, replicating index values.\n",
      " |      \n",
      " |      .. versionadded:: 0.25.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : IndexLabel\n",
      " |          Column(s) to explode.\n",
      " |          For multiple columns, specify a non-empty list with each element\n",
      " |          be str or tuple, and all specified columns their list-like data\n",
      " |          on same row of the frame must have matching length.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |              Multi-column explode\n",
      " |      \n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Exploded lists to rows of the subset columns;\n",
      " |          index will be duplicated for these rows.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError :\n",
      " |          * If columns of the frame are not unique.\n",
      " |          * If specified columns to explode is empty list.\n",
      " |          * If specified columns to explode have not matching count of\n",
      " |            elements rowwise in the frame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Pivot a level of the (necessarily hierarchical)\n",
      " |          index labels.\n",
      " |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n",
      " |      Series.explode : Explode a DataFrame from list-like columns to long format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This routine will explode list-likes including lists, tuples, sets,\n",
      " |      Series, and np.ndarray. The result dtype of the subset rows will\n",
      " |      be object. Scalars will be returned unchanged, and empty list-likes will\n",
      " |      result in a np.nan for that row. In addition, the ordering of rows in the\n",
      " |      output will be non-deterministic when exploding sets.\n",
      " |      \n",
      " |      Reference :ref:`the user guide <reshaping.explode>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],\n",
      " |      ...                    'B': 1,\n",
      " |      ...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})\n",
      " |      >>> df\n",
      " |                 A  B          C\n",
      " |      0  [0, 1, 2]  1  [a, b, c]\n",
      " |      1        foo  1        NaN\n",
      " |      2         []  1         []\n",
      " |      3     [3, 4]  1     [d, e]\n",
      " |      \n",
      " |      Single-column explode.\n",
      " |      \n",
      " |      >>> df.explode('A')\n",
      " |           A  B          C\n",
      " |      0    0  1  [a, b, c]\n",
      " |      0    1  1  [a, b, c]\n",
      " |      0    2  1  [a, b, c]\n",
      " |      1  foo  1        NaN\n",
      " |      2  NaN  1         []\n",
      " |      3    3  1     [d, e]\n",
      " |      3    4  1     [d, e]\n",
      " |      \n",
      " |      Multi-column explode.\n",
      " |      \n",
      " |      >>> df.explode(list('AC'))\n",
      " |           A  B    C\n",
      " |      0    0  1    a\n",
      " |      0    1  1    b\n",
      " |      0    2  1    c\n",
      " |      1  foo  1  NaN\n",
      " |      2  NaN  1  NaN\n",
      " |      3    3  1    d\n",
      " |      3    4  1    e\n",
      " |  \n",
      " |  ffill(self, *, axis: 'None | Axis' = None, inplace: 'bool' = False, limit: 'None | int' = None, downcast: 'dict | None' = None) -> 'DataFrame | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  fillna(self, value: 'Hashable | Mapping | Series | DataFrame' = None, *, method: 'FillnaOptions | None' = None, axis: 'Axis | None' = None, inplace: 'bool' = False, limit: 'int | None' = None, downcast: 'dict | None' = None) -> 'DataFrame | None'\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use next valid observation to fill gap.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Axis along which to fill missing values. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex : Conform object to new index.\n",
      " |      asfreq : Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, np.nan],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list(\"ABCD\"))\n",
      " |      >>> df\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  NaN  NaN NaN  NaN\n",
      " |      3  NaN  3.0 NaN  4.0\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  0.0\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method=\"ffill\")\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  3.0  4.0 NaN  1.0\n",
      " |      3  3.0  3.0 NaN  4.0\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  2.0  1.0\n",
      " |      2  0.0  1.0  2.0  3.0\n",
      " |      3  0.0  3.0  2.0  4.0\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  NaN  1.0\n",
      " |      2  NaN  1.0  NaN  3.0\n",
      " |      3  NaN  3.0  NaN  4.0\n",
      " |      \n",
      " |      When filling using a DataFrame, replacement happens along\n",
      " |      the same column names and same indices\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
      " |      >>> df.fillna(df2)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  NaN\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |      \n",
      " |      Note that column D is not affected since it is not present in df2.\n",
      " |  \n",
      " |  floordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rfloordiv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  ge(self, other, axis='columns', level=None)\n",
      " |      Get Greater than or equal to of dataframe and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  groupby(self, by=None, axis: 'Axis' = 0, level: 'IndexLabel | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool | lib.NoDefault' = <no_default>, squeeze: 'bool | lib.NoDefault' = <no_default>, observed: 'bool' = False, dropna: 'bool' = True) -> 'DataFrameGroupBy'\n",
      " |      Group DataFrame using a mapper or by a Series of columns.\n",
      " |      \n",
      " |      A groupby operation involves some combination of splitting the\n",
      " |      object, applying a function, and combining the results. This can be\n",
      " |      used to group large amounts of data and compute operations on these\n",
      " |      groups.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If a list or ndarray of length\n",
      " |          equal to the selected axis is passed (see the `groupby user guide\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#splitting-an-object-into-groups>`_),\n",
      " |          the values are used as-is to determine the groups. A label or list\n",
      " |          of labels may be passed to group by the columns in ``self``.\n",
      " |          Notice that a tuple is interpreted as a (single) key.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Split along rows (0) or columns (1). For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels. Do not specify both ``by`` and ``level``.\n",
      " |      as_index : bool, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output.\n",
      " |      sort : bool, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group. Groupby preserves the order of rows within each group.\n",
      " |      group_keys : bool, optional\n",
      " |          When calling apply and the ``by`` argument produces a like-indexed\n",
      " |          (i.e. :ref:`a transform <groupby.transform>`) result, add group keys to\n",
      " |          index to identify pieces. By default group keys are not included\n",
      " |          when the result's index (and column) labels match the inputs, and\n",
      " |          are included otherwise. This argument has no effect if the result produced\n",
      " |          is not like-indexed with respect to the input.\n",
      " |      \n",
      " |          .. versionchanged:: 1.5.0\n",
      " |      \n",
      " |             Warns that `group_keys` will no longer be ignored when the\n",
      " |             result from ``apply`` is a like-indexed Series or DataFrame.\n",
      " |             Specify ``group_keys`` explicitly to include the group keys or\n",
      " |             not.\n",
      " |      squeeze : bool, default False\n",
      " |          Reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |      \n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      dropna : bool, default True\n",
      " |          If True, and if group keys contain NA values, NA values together\n",
      " |          with row/column will be dropped.\n",
      " |          If False, NA values will also be treated as the key in groups.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrameGroupBy\n",
      " |          Returns a groupby object that contains information about the groups.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/groupby.html>`__ for more\n",
      " |      detailed usage and examples, including splitting an object into groups,\n",
      " |      iterating through groups, selecting a group, aggregation, and more.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
      " |      ...                               'Parrot', 'Parrot'],\n",
      " |      ...                    'Max Speed': [380., 370., 24., 26.]})\n",
      " |      >>> df\n",
      " |         Animal  Max Speed\n",
      " |      0  Falcon      380.0\n",
      " |      1  Falcon      370.0\n",
      " |      2  Parrot       24.0\n",
      " |      3  Parrot       26.0\n",
      " |      >>> df.groupby(['Animal']).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      375.0\n",
      " |      Parrot       25.0\n",
      " |      \n",
      " |      **Hierarchical Indexes**\n",
      " |      \n",
      " |      We can groupby different levels of a hierarchical index\n",
      " |      using the `level` parameter:\n",
      " |      \n",
      " |      >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      " |      ...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
      " |      >>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                      Max Speed\n",
      " |      Animal Type\n",
      " |      Falcon Captive      390.0\n",
      " |             Wild         350.0\n",
      " |      Parrot Captive       30.0\n",
      " |             Wild          20.0\n",
      " |      >>> df.groupby(level=0).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      370.0\n",
      " |      Parrot       25.0\n",
      " |      >>> df.groupby(level=\"Type\").mean()\n",
      " |               Max Speed\n",
      " |      Type\n",
      " |      Captive      210.0\n",
      " |      Wild         185.0\n",
      " |      \n",
      " |      We can also choose to include NA in group keys or not by setting\n",
      " |      `dropna` parameter, the default setting is `True`.\n",
      " |      \n",
      " |      >>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |      \n",
      " |      >>> df.groupby(by=[\"b\"]).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      \n",
      " |      >>> df.groupby(by=[\"b\"], dropna=False).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      NaN 1   4\n",
      " |      \n",
      " |      >>> l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |      \n",
      " |      >>> df.groupby(by=\"a\").sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      \n",
      " |      >>> df.groupby(by=\"a\", dropna=False).sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      NaN 12.3   33.0\n",
      " |      \n",
      " |      When using ``.apply()``, use ``group_keys`` to include or exclude the group keys.\n",
      " |      The ``group_keys`` argument defaults to ``True`` (include).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
      " |      ...                               'Parrot', 'Parrot'],\n",
      " |      ...                    'Max Speed': [380., 370., 24., 26.]})\n",
      " |      >>> df.groupby(\"Animal\", group_keys=True).apply(lambda x: x)\n",
      " |                Animal  Max Speed\n",
      " |      Animal\n",
      " |      Falcon 0  Falcon      380.0\n",
      " |             1  Falcon      370.0\n",
      " |      Parrot 2  Parrot       24.0\n",
      " |             3  Parrot       26.0\n",
      " |      \n",
      " |      >>> df.groupby(\"Animal\", group_keys=False).apply(lambda x: x)\n",
      " |         Animal  Max Speed\n",
      " |      0  Falcon      380.0\n",
      " |      1  Falcon      370.0\n",
      " |      2  Parrot       24.0\n",
      " |      3  Parrot       26.0\n",
      " |  \n",
      " |  gt(self, other, axis='columns', level=None)\n",
      " |      Get Greater than of dataframe and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  hist = hist_frame(data: 'DataFrame', column: 'IndexLabel' = None, by=None, grid: 'bool' = True, xlabelsize: 'int | None' = None, xrot: 'float | None' = None, ylabelsize: 'int | None' = None, yrot: 'float | None' = None, ax=None, sharex: 'bool' = False, sharey: 'bool' = False, figsize: 'tuple[int, int] | None' = None, layout: 'tuple[int, int] | None' = None, bins: 'int | Sequence[int]' = 10, backend: 'str | None' = None, legend: 'bool' = False, **kwargs)\n",
      " |      Make a histogram of the DataFrame's columns.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : str or sequence, optional\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple, optional\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      \n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This example draws a histogram based on the length and width of\n",
      " |      some animals, displayed in three bins\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax(self, axis: 'Axis' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False) -> 'Series'\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of maxima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax : Return index of the maximum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the maximum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmax()\n",
      " |      consumption     Wheat Products\n",
      " |      co2_emissions             Beef\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the maximum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmax(axis=\"columns\")\n",
      " |      Pork              co2_emissions\n",
      " |      Wheat Products     consumption\n",
      " |      Beef              co2_emissions\n",
      " |      dtype: object\n",
      " |  \n",
      " |  idxmin(self, axis: 'Axis' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False) -> 'Series'\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of minima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin : Return index of the minimum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the minimum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmin()\n",
      " |      consumption                Pork\n",
      " |      co2_emissions    Wheat Products\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the minimum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmin(axis=\"columns\")\n",
      " |      Pork                consumption\n",
      " |      Wheat Products    co2_emissions\n",
      " |      Beef                consumption\n",
      " |      dtype: object\n",
      " |  \n",
      " |  info(self, verbose: 'bool | None' = None, buf: 'WriteBuffer[str] | None' = None, max_cols: 'int | None' = None, memory_usage: 'bool | str | None' = None, show_counts: 'bool | None' = None, null_counts: 'bool | None' = None) -> 'None'\n",
      " |      Print a concise summary of a DataFrame.\n",
      " |      \n",
      " |      This method prints information about a DataFrame including\n",
      " |      the index dtype and columns, non-null values and memory usage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbose : bool, optional\n",
      " |          Whether to print the full summary. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is followed.\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |          Where to send the output. By default, the output is printed to\n",
      " |          sys.stdout. Pass a writable buffer if you need to further process\n",
      " |          the output.    max_cols : int, optional\n",
      " |          When to switch from the verbose to the truncated output. If the\n",
      " |          DataFrame has more than `max_cols` columns, the truncated output\n",
      " |          is used. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is used.\n",
      " |      memory_usage : bool, str, optional\n",
      " |          Specifies whether total memory usage of the DataFrame\n",
      " |          elements (including the index) should be displayed. By default,\n",
      " |          this follows the ``pandas.options.display.memory_usage`` setting.\n",
      " |      \n",
      " |          True always show memory usage. False never shows memory usage.\n",
      " |          A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      " |          Memory usage is shown in human-readable units (base-2\n",
      " |          representation). Without deep introspection a memory estimation is\n",
      " |          made based in column dtype and number of rows assuming values\n",
      " |          consume the same memory amount for corresponding dtypes. With deep\n",
      " |          memory introspection, a real memory usage calculation is performed\n",
      " |          at the cost of computational resources. See the\n",
      " |          :ref:`Frequently Asked Questions <df-memory-usage>` for more\n",
      " |          details.\n",
      " |      show_counts : bool, optional\n",
      " |          Whether to show the non-null counts. By default, this is shown\n",
      " |          only if the DataFrame is smaller than\n",
      " |          ``pandas.options.display.max_info_rows`` and\n",
      " |          ``pandas.options.display.max_info_columns``. A value of True always\n",
      " |          shows the counts, and False never shows the counts.\n",
      " |      null_counts : bool, optional\n",
      " |          .. deprecated:: 1.2.0\n",
      " |              Use show_counts instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method prints a summary of a DataFrame and returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.describe: Generate descriptive statistics of DataFrame\n",
      " |          columns.\n",
      " |      DataFrame.memory_usage: Memory usage of DataFrame columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> int_values = [1, 2, 3, 4, 5]\n",
      " |      >>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      " |      >>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      " |      >>> df = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n",
      " |      ...                   \"float_col\": float_values})\n",
      " |      >>> df\n",
      " |          int_col text_col  float_col\n",
      " |      0        1    alpha       0.00\n",
      " |      1        2     beta       0.25\n",
      " |      2        3    gamma       0.50\n",
      " |      3        4    delta       0.75\n",
      " |      4        5  epsilon       1.00\n",
      " |      \n",
      " |      Prints information of all columns:\n",
      " |      \n",
      " |      >>> df.info(verbose=True)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column     Non-Null Count  Dtype\n",
      " |      ---  ------     --------------  -----\n",
      " |       0   int_col    5 non-null      int64\n",
      " |       1   text_col   5 non-null      object\n",
      " |       2   float_col  5 non-null      float64\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 248.0+ bytes\n",
      " |      \n",
      " |      Prints a summary of columns count and its dtypes but not per column\n",
      " |      information:\n",
      " |      \n",
      " |      >>> df.info(verbose=False)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Columns: 3 entries, int_col to float_col\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 248.0+ bytes\n",
      " |      \n",
      " |      Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n",
      " |      buffer content and writes to a text file:\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> buffer = io.StringIO()\n",
      " |      >>> df.info(buf=buffer)\n",
      " |      >>> s = buffer.getvalue()\n",
      " |      >>> with open(\"df_info.txt\", \"w\",\n",
      " |      ...           encoding=\"utf-8\") as f:  # doctest: +SKIP\n",
      " |      ...     f.write(s)\n",
      " |      260\n",
      " |      \n",
      " |      The `memory_usage` parameter allows deep introspection mode, specially\n",
      " |      useful for big DataFrames and fine-tune memory optimization:\n",
      " |      \n",
      " |      >>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      ... })\n",
      " |      >>> df.info()\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column    Non-Null Count    Dtype\n",
      " |      ---  ------    --------------    -----\n",
      " |       0   column_1  1000000 non-null  object\n",
      " |       1   column_2  1000000 non-null  object\n",
      " |       2   column_3  1000000 non-null  object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 22.9+ MB\n",
      " |      \n",
      " |      >>> df.info(memory_usage='deep')\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column    Non-Null Count    Dtype\n",
      " |      ---  ------    --------------    -----\n",
      " |       0   column_1  1000000 non-null  object\n",
      " |       1   column_2  1000000 non-null  object\n",
      " |       2   column_3  1000000 non-null  object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 165.9 MB\n",
      " |  \n",
      " |  insert(self, loc: 'int', column: 'Hashable', value: 'Scalar | AnyArrayLike', allow_duplicates: 'bool | lib.NoDefault' = <no_default>) -> 'None'\n",
      " |      Insert column into DataFrame at specified location.\n",
      " |      \n",
      " |      Raises a ValueError if `column` is already contained in the DataFrame,\n",
      " |      unless `allow_duplicates` is set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |          Insertion index. Must verify 0 <= loc <= len(columns).\n",
      " |      column : str, number, or hashable object\n",
      " |          Label of the inserted column.\n",
      " |      value : Scalar, Series, or array-like\n",
      " |      allow_duplicates : bool, optional, default lib.no_default\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.insert : Insert new item by index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      >>> df.insert(1, \"newcol\", [99, 99])\n",
      " |      >>> df\n",
      " |         col1  newcol  col2\n",
      " |      0     1      99     3\n",
      " |      1     2      99     4\n",
      " |      >>> df.insert(0, \"col1\", [100, 100], allow_duplicates=True)\n",
      " |      >>> df\n",
      " |         col1  col1  newcol  col2\n",
      " |      0   100     1      99     3\n",
      " |      1   100     2      99     4\n",
      " |      \n",
      " |      Notice that pandas uses index alignment in case of `value` from type `Series`:\n",
      " |      \n",
      " |      >>> df.insert(0, \"col0\", pd.Series([5, 6], index=[1, 2]))\n",
      " |      >>> df\n",
      " |         col0  col1  col1  newcol  col2\n",
      " |      0   NaN   100     1      99     3\n",
      " |      1   5.0   100     2      99     4\n",
      " |  \n",
      " |  interpolate(self: 'DataFrame', method: 'str' = 'linear', *, axis: 'Axis' = 0, limit: 'int | None' = None, inplace: 'bool' = False, limit_direction: 'str | None' = None, limit_area: 'str | None' = None, downcast: 'str | None' = None, **kwargs) -> 'DataFrame | None'\n",
      " |      Fill NaN values using an interpolation method.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrame/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, default 'linear'\n",
      " |          Interpolation technique to use. One of:\n",
      " |      \n",
      " |          * 'linear': Ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |          * 'time': Works on daily and higher resolution data to interpolate\n",
      " |            given length of interval.\n",
      " |          * 'index', 'values': use the actual numerical values of the index.\n",
      " |          * 'pad': Fill in NaNs using existing values.\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'spline',\n",
      " |            'barycentric', 'polynomial': Passed to\n",
      " |            `scipy.interpolate.interp1d`. These methods use the numerical\n",
      " |            values of the index.  Both 'polynomial' and 'spline' require that\n",
      " |            you also specify an `order` (int), e.g.\n",
      " |            ``df.interpolate(method='polynomial', order=5)``.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima',\n",
      " |            'cubicspline': Wrappers around the SciPy interpolation methods of\n",
      " |            similar names. See `Notes`.\n",
      " |          * 'from_derivatives': Refers to\n",
      " |            `scipy.interpolate.BPoly.from_derivatives` which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18.\n",
      " |      \n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to interpolate along. For `Series` this parameter is unused\n",
      " |          and defaults to 0.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than\n",
      " |          0.\n",
      " |      inplace : bool, default False\n",
      " |          Update the data in place if possible.\n",
      " |      limit_direction : {{'forward', 'backward', 'both'}}, Optional\n",
      " |          Consecutive NaNs will be filled in this direction.\n",
      " |      \n",
      " |          If limit is specified:\n",
      " |              * If 'method' is 'pad' or 'ffill', 'limit_direction' must be 'forward'.\n",
      " |              * If 'method' is 'backfill' or 'bfill', 'limit_direction' must be\n",
      " |                'backwards'.\n",
      " |      \n",
      " |          If 'limit' is not specified:\n",
      " |              * If 'method' is 'backfill' or 'bfill', the default is 'backward'\n",
      " |              * else the default is 'forward'\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |              raises ValueError if `limit_direction` is 'forward' or 'both' and\n",
      " |                  method is 'backfill' or 'bfill'.\n",
      " |              raises ValueError if `limit_direction` is 'backward' or 'both' and\n",
      " |                  method is 'pad' or 'ffill'.\n",
      " |      \n",
      " |      limit_area : {{`None`, 'inside', 'outside'}}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |      \n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      ``**kwargs`` : optional\n",
      " |          Keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Returns the same object type as the caller, interpolated at\n",
      " |          some or all ``NaN`` values or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      fillna : Fill missing values using different methods.\n",
      " |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials\n",
      " |          (Akima interpolator).\n",
      " |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the\n",
      " |          Bernstein basis.\n",
      " |      scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
      " |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh\n",
      " |          interpolator).\n",
      " |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic\n",
      " |          interpolation.\n",
      " |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |      methods are wrappers around the respective SciPy implementations of\n",
      " |      similar names. These use the actual numerical values of the index.\n",
      " |      For more information on their behavior, see the\n",
      " |      `SciPy documentation\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear\n",
      " |      interpolation.\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    NaN\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.interpolate()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series by padding, but filling at most two\n",
      " |      consecutive ``NaN`` at a time.\n",
      " |      \n",
      " |      >>> s = pd.Series([np.nan, \"single_one\", np.nan,\n",
      " |      ...                \"fill_two_more\", np.nan, np.nan, np.nan,\n",
      " |      ...                4.71, np.nan])\n",
      " |      >>> s\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2              NaN\n",
      " |      3    fill_two_more\n",
      " |      4              NaN\n",
      " |      5              NaN\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8              NaN\n",
      " |      dtype: object\n",
      " |      >>> s.interpolate(method='pad', limit=2)\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2       single_one\n",
      " |      3    fill_two_more\n",
      " |      4    fill_two_more\n",
      " |      5    fill_two_more\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8             4.71\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:\n",
      " |      Both 'polynomial' and 'spline' methods require that you also specify\n",
      " |      an ``order`` (int).\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 2, np.nan, 8])\n",
      " |      >>> s.interpolate(method='polynomial', order=2)\n",
      " |      0    0.000000\n",
      " |      1    2.000000\n",
      " |      2    4.666667\n",
      " |      3    8.000000\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Fill the DataFrame forward (that is, going down) along each column\n",
      " |      using linear interpolation.\n",
      " |      \n",
      " |      Note how the last entry in column 'a' is interpolated differently,\n",
      " |      because there is no entry after it to use for interpolation.\n",
      " |      Note how the first entry in column 'b' remains ``NaN``, because there\n",
      " |      is no entry before it to use for interpolation.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),\n",
      " |      ...                    (np.nan, 2.0, np.nan, np.nan),\n",
      " |      ...                    (2.0, 3.0, np.nan, 9.0),\n",
      " |      ...                    (np.nan, 4.0, -4.0, 16.0)],\n",
      " |      ...                   columns=list('abcd'))\n",
      " |      >>> df\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  NaN  2.0  NaN   NaN\n",
      " |      2  2.0  3.0  NaN   9.0\n",
      " |      3  NaN  4.0 -4.0  16.0\n",
      " |      >>> df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  1.0  2.0 -2.0   5.0\n",
      " |      2  2.0  3.0 -3.0   9.0\n",
      " |      3  2.0  4.0 -4.0  16.0\n",
      " |      \n",
      " |      Using polynomial interpolation.\n",
      " |      \n",
      " |      >>> df['d'].interpolate(method='polynomial', order=2)\n",
      " |      0     1.0\n",
      " |      1     4.0\n",
      " |      2     9.0\n",
      " |      3    16.0\n",
      " |      Name: d, dtype: float64\n",
      " |  \n",
      " |  isetitem(self, loc, value) -> 'None'\n",
      " |      Set the given value in the column with position 'loc'.\n",
      " |      \n",
      " |      This is a positional analogue to __setitem__.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int or sequence of ints\n",
      " |      value : scalar or arraylike\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Unlike `frame.iloc[:, i] = value`, `frame.isetitem(loc, value)` will\n",
      " |      _never_ try to set the values in place, but will always insert a new\n",
      " |      array.\n",
      " |      \n",
      " |      In cases where `frame.columns` is unique, this is equivalent to\n",
      " |      `frame[frame.columns[i]] = value`.\n",
      " |  \n",
      " |  isin(self, values: 'Series | DataFrame | Sequence | Mapping') -> 'DataFrame'\n",
      " |      Whether each element in the DataFrame is contained in values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : iterable, Series, DataFrame or dict\n",
      " |          The result will only be true at a location if all the\n",
      " |          labels match. If `values` is a Series, that's the index. If\n",
      " |          `values` is a dict, the keys must be the column names,\n",
      " |          which must match. If `values` is a DataFrame,\n",
      " |          then both the index and column labels must match.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame of booleans showing whether each element in the DataFrame\n",
      " |          is contained in values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq: Equality test for DataFrame.\n",
      " |      Series.isin: Equivalent method on Series.\n",
      " |      Series.str.contains: Test if pattern or regex is contained within a\n",
      " |          string of a Series or Index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n",
      " |      ...                   index=['falcon', 'dog'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      \n",
      " |      When ``values`` is a list check whether every value in the DataFrame\n",
      " |      is present in the list (which animals have 0 or 2 legs or wings)\n",
      " |      \n",
      " |      >>> df.isin([0, 2])\n",
      " |              num_legs  num_wings\n",
      " |      falcon      True       True\n",
      " |      dog        False       True\n",
      " |      \n",
      " |      To check if ``values`` is *not* in the DataFrame, use the ``~`` operator:\n",
      " |      \n",
      " |      >>> ~df.isin([0, 2])\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False      False\n",
      " |      dog         True      False\n",
      " |      \n",
      " |      When ``values`` is a dict, we can pass values to check for each\n",
      " |      column separately:\n",
      " |      \n",
      " |      >>> df.isin({'num_wings': [0, 3]})\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False      False\n",
      " |      dog        False       True\n",
      " |      \n",
      " |      When ``values`` is a Series or DataFrame the index and column must\n",
      " |      match. Note that 'falcon' does not match based on the number of legs\n",
      " |      in other.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'num_legs': [8, 3], 'num_wings': [0, 2]},\n",
      " |      ...                      index=['spider', 'falcon'])\n",
      " |      >>> df.isin(other)\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False       True\n",
      " |      dog        False      False\n",
      " |  \n",
      " |  isna(self) -> 'DataFrame'\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self) -> 'DataFrame'\n",
      " |      DataFrame.isnull is an alias for DataFrame.isna.\n",
      " |      \n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Iterates over the DataFrame columns, returning a tuple with\n",
      " |      the column name and the content as a Series.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      label : object\n",
      " |          The column names for the DataFrame being iterated over.\n",
      " |      content : Series\n",
      " |          The column entries belonging to each label, as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as\n",
      " |          (index, Series) pairs.\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\n",
      " |          of the values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\n",
      " |      ...                   'population': [1864, 22000, 80000]},\n",
      " |      ...                   index=['panda', 'polar', 'koala'])\n",
      " |      >>> df\n",
      " |              species   population\n",
      " |      panda   bear      1864\n",
      " |      polar   bear      22000\n",
      " |      koala   marsupial 80000\n",
      " |      >>> for label, content in df.items():\n",
      " |      ...     print(f'label: {label}')\n",
      " |      ...     print(f'content: {content}', sep='\\n')\n",
      " |      ...\n",
      " |      label: species\n",
      " |      content:\n",
      " |      panda         bear\n",
      " |      polar         bear\n",
      " |      koala    marsupial\n",
      " |      Name: species, dtype: object\n",
      " |      label: population\n",
      " |      content:\n",
      " |      panda     1864\n",
      " |      polar    22000\n",
      " |      koala    80000\n",
      " |      Name: population, dtype: int64\n",
      " |  \n",
      " |  iteritems(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      .. deprecated:: 1.5.0\n",
      " |          iteritems is deprecated and will be removed in a future version.\n",
      " |          Use .items instead.\n",
      " |      \n",
      " |      Iterates over the DataFrame columns, returning a tuple with\n",
      " |      the column name and the content as a Series.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      label : object\n",
      " |          The column names for the DataFrame being iterated over.\n",
      " |      content : Series\n",
      " |          The column entries belonging to each label, as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iter : Recommended alternative.\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as\n",
      " |          (index, Series) pairs.\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\n",
      " |          of the values.\n",
      " |  \n",
      " |  iterrows(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      index : label or tuple of label\n",
      " |          The index of the row. A tuple for a `MultiIndex`.\n",
      " |      data : Series\n",
      " |          The data of the row as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      1. Because ``iterrows`` returns a Series for each row,\n",
      " |         it does **not** preserve dtypes across the rows (dtypes are\n",
      " |         preserved across columns for DataFrames). For example,\n",
      " |      \n",
      " |         >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n",
      " |         >>> row = next(df.iterrows())[1]\n",
      " |         >>> row\n",
      " |         int      1.0\n",
      " |         float    1.5\n",
      " |         Name: 0, dtype: float64\n",
      " |         >>> print(row['int'].dtype)\n",
      " |         float64\n",
      " |         >>> print(df['int'].dtype)\n",
      " |         int64\n",
      " |      \n",
      " |         To preserve dtypes while iterating over the rows, it is better\n",
      " |         to use :meth:`itertuples` which returns namedtuples of the values\n",
      " |         and which is generally faster than ``iterrows``.\n",
      " |      \n",
      " |      2. You should **never modify** something you are iterating over.\n",
      " |         This is not guaranteed to work in all cases. Depending on the\n",
      " |         data types, the iterator returns a copy and not a view, and writing\n",
      " |         to it will have no effect.\n",
      " |  \n",
      " |  itertuples(self, index: 'bool' = True, name: 'str | None' = 'Pandas') -> 'Iterable[tuple[Any, ...]]'\n",
      " |      Iterate over DataFrame rows as namedtuples.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          If True, return the index as the first element of the tuple.\n",
      " |      name : str or None, default \"Pandas\"\n",
      " |          The name of the returned namedtuples or None to return regular\n",
      " |          tuples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          An object to iterate over namedtuples for each row in the\n",
      " |          DataFrame with the first field possibly being the index and\n",
      " |          following fields being the column values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)\n",
      " |          pairs.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The column names will be renamed to positional names if they are\n",
      " |      invalid Python identifiers, repeated, or start with an underscore.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},\n",
      " |      ...                   index=['dog', 'hawk'])\n",
      " |      >>> df\n",
      " |            num_legs  num_wings\n",
      " |      dog          4          0\n",
      " |      hawk         2          2\n",
      " |      >>> for row in df.itertuples():\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Pandas(Index='hawk', num_legs=2, num_wings=2)\n",
      " |      \n",
      " |      By setting the `index` parameter to False we can remove the index\n",
      " |      as the first element of the tuple:\n",
      " |      \n",
      " |      >>> for row in df.itertuples(index=False):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(num_legs=4, num_wings=0)\n",
      " |      Pandas(num_legs=2, num_wings=2)\n",
      " |      \n",
      " |      With the `name` parameter set we set a custom name for the yielded\n",
      " |      namedtuples:\n",
      " |      \n",
      " |      >>> for row in df.itertuples(name='Animal'):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Animal(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Animal(Index='hawk', num_legs=2, num_wings=2)\n",
      " |  \n",
      " |  join(self, other: 'DataFrame | Series | list[DataFrame | Series]', on: 'IndexLabel | None' = None, how: 'str' = 'left', lsuffix: 'str' = '', rsuffix: 'str' = '', sort: 'bool' = False, validate: 'str | None' = None) -> 'DataFrame'\n",
      " |      Join columns of another DataFrame.\n",
      " |      \n",
      " |      Join columns with `other` DataFrame either on index or on a key\n",
      " |      column. Efficiently join multiple DataFrame objects by index at once by\n",
      " |      passing a list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series, or a list containing any combination of them\n",
      " |          Index should be similar to one of the columns in this one. If a\n",
      " |          Series is passed, its name attribute must be set, and that will be\n",
      " |          used as the column name in the resulting joined DataFrame.\n",
      " |      on : str, list of str, or array-like, optional\n",
      " |          Column or index level name(s) in the caller to join on the index\n",
      " |          in `other`, otherwise joins index-on-index. If multiple\n",
      " |          values given, the `other` DataFrame must have a MultiIndex. Can\n",
      " |          pass an array as the join key if it is not already contained in\n",
      " |          the calling DataFrame. Like an Excel VLOOKUP operation.\n",
      " |      how : {'left', 'right', 'outer', 'inner'}, default 'left'\n",
      " |          How to handle the operation of the two objects.\n",
      " |      \n",
      " |          * left: use calling frame's index (or column if on is specified)\n",
      " |          * right: use `other`'s index.\n",
      " |          * outer: form union of calling frame's index (or column if on is\n",
      " |            specified) with `other`'s index, and sort it.\n",
      " |            lexicographically.\n",
      " |          * inner: form intersection of calling frame's index (or column if\n",
      " |            on is specified) with `other`'s index, preserving the order\n",
      " |            of the calling's one.\n",
      " |          * cross: creates the cartesian product from both frames, preserves the order\n",
      " |            of the left keys.\n",
      " |      \n",
      " |            .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      lsuffix : str, default ''\n",
      " |          Suffix to use from left frame's overlapping columns.\n",
      " |      rsuffix : str, default ''\n",
      " |          Suffix to use from right frame's overlapping columns.\n",
      " |      sort : bool, default False\n",
      " |          Order result DataFrame lexicographically by the join key. If False,\n",
      " |          the order of the join key depends on the join type (how keyword).\n",
      " |      validate : str, optional\n",
      " |          If specified, checks if join is of specified type.\n",
      " |          * \"one_to_one\" or \"1:1\": check if join keys are unique in both left\n",
      " |          and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if join keys are unique in left dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if join keys are unique in right dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A dataframe containing columns from both the caller and `other`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.merge : For column(s)-on-column(s) operations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\n",
      " |      passing a list of `DataFrame` objects.\n",
      " |      \n",
      " |      Support for specifying index levels as the `on` parameter was added\n",
      " |      in version 0.23.0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      " |      ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |      \n",
      " |      >>> df\n",
      " |        key   A\n",
      " |      0  K0  A0\n",
      " |      1  K1  A1\n",
      " |      2  K2  A2\n",
      " |      3  K3  A3\n",
      " |      4  K4  A4\n",
      " |      5  K5  A5\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      " |      ...                       'B': ['B0', 'B1', 'B2']})\n",
      " |      \n",
      " |      >>> other\n",
      " |        key   B\n",
      " |      0  K0  B0\n",
      " |      1  K1  B1\n",
      " |      2  K2  B2\n",
      " |      \n",
      " |      Join DataFrames using their indexes.\n",
      " |      \n",
      " |      >>> df.join(other, lsuffix='_caller', rsuffix='_other')\n",
      " |        key_caller   A key_other    B\n",
      " |      0         K0  A0        K0   B0\n",
      " |      1         K1  A1        K1   B1\n",
      " |      2         K2  A2        K2   B2\n",
      " |      3         K3  A3       NaN  NaN\n",
      " |      4         K4  A4       NaN  NaN\n",
      " |      5         K5  A5       NaN  NaN\n",
      " |      \n",
      " |      If we want to join using the key columns, we need to set key to be\n",
      " |      the index in both `df` and `other`. The joined DataFrame will have\n",
      " |      key as its index.\n",
      " |      \n",
      " |      >>> df.set_index('key').join(other.set_index('key'))\n",
      " |            A    B\n",
      " |      key\n",
      " |      K0   A0   B0\n",
      " |      K1   A1   B1\n",
      " |      K2   A2   B2\n",
      " |      K3   A3  NaN\n",
      " |      K4   A4  NaN\n",
      " |      K5   A5  NaN\n",
      " |      \n",
      " |      Another option to join using the key columns is to use the `on`\n",
      " |      parameter. DataFrame.join always uses `other`'s index but we can use\n",
      " |      any column in `df`. This method preserves the original DataFrame's\n",
      " |      index in the result.\n",
      " |      \n",
      " |      >>> df.join(other.set_index('key'), on='key')\n",
      " |        key   A    B\n",
      " |      0  K0  A0   B0\n",
      " |      1  K1  A1   B1\n",
      " |      2  K2  A2   B2\n",
      " |      3  K3  A3  NaN\n",
      " |      4  K4  A4  NaN\n",
      " |      5  K5  A5  NaN\n",
      " |      \n",
      " |      Using non-unique key values shows how they are matched.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K1', 'K3', 'K0', 'K1'],\n",
      " |      ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |      \n",
      " |      >>> df\n",
      " |        key   A\n",
      " |      0  K0  A0\n",
      " |      1  K1  A1\n",
      " |      2  K1  A2\n",
      " |      3  K3  A3\n",
      " |      4  K0  A4\n",
      " |      5  K1  A5\n",
      " |      \n",
      " |      >>> df.join(other.set_index('key'), on='key', validate='m:1')\n",
      " |        key   A    B\n",
      " |      0  K0  A0   B0\n",
      " |      1  K1  A1   B1\n",
      " |      2  K1  A2   B1\n",
      " |      3  K3  A3  NaN\n",
      " |      4  K0  A4   B0\n",
      " |      5  K1  A5   B1\n",
      " |  \n",
      " |  kurt(self, axis: 'Axis | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis.\n",
      " |      \n",
      " |      Kurtosis obtained using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis: 'Axis | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  le(self, other, axis='columns', level=None)\n",
      " |      Get Less than or equal to of dataframe and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  lookup(self, row_labels: 'Sequence[IndexLabel]', col_labels: 'Sequence[IndexLabel]') -> 'np.ndarray'\n",
      " |      Label-based \"fancy indexing\" function for DataFrame.\n",
      " |      \n",
      " |      .. deprecated:: 1.2.0\n",
      " |          DataFrame.lookup is deprecated,\n",
      " |          use pandas.factorize and NumPy indexing instead.\n",
      " |          For further details see\n",
      " |          :ref:`Looking up values by index/column labels <indexing.lookup>`.\n",
      " |      \n",
      " |      Given equal-length arrays of row and column labels, return an\n",
      " |      array of the values corresponding to each (row, col) pair.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      row_labels : sequence\n",
      " |          The row labels to use for lookup.\n",
      " |      col_labels : sequence\n",
      " |          The column labels to use for lookup.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The found values.\n",
      " |  \n",
      " |  lt(self, other, axis='columns', level=None)\n",
      " |      Get Less than of dataframe and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=True, level=None)\n",
      " |      Return the mean absolute deviation of the values over the requested axis.\n",
      " |      \n",
      " |      .. deprecated:: 1.5.0\n",
      " |          mad is deprecated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  mask(self, cond, other=nan, *, inplace: 'bool' = False, axis: 'Axis | None' = None, level: 'Level' = None, errors: 'IgnoreRaise | lib.NoDefault' = 'raise', try_cast: 'bool | lib.NoDefault' = <no_default>) -> 'DataFrame | None'\n",
      " |      Replace values where the condition is True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed. For `Series` this parameter is\n",
      " |          unused and defaults to 0.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |             This argument had no effect.\n",
      " |      \n",
      " |      try_cast : bool, default None\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              Manually cast back if necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used. If the axis of ``other`` does not align with axis of\n",
      " |      ``cond`` Series/DataFrame, the misaligned index positions will be filled with\n",
      " |      True.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      The dtype of the object takes precedence. The fill value is casted to\n",
      " |      the object's dtype, if this can be done losslessly.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> t = pd.Series([True, False])\n",
      " |      >>> s.where(t, 99)\n",
      " |      0     0\n",
      " |      1    99\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(t, 99)\n",
      " |      0    99\n",
      " |      1     1\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  max(self, axis: 'int | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the maximum of the values over the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the maximum, use ``idxmax``. This is the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.max()\n",
      " |      8\n",
      " |  \n",
      " |  mean(self, axis: 'int | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  median(self, axis: 'int | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level: 'Level' = None, ignore_index: 'bool' = True) -> 'DataFrame'\n",
      " |      Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.\n",
      " |      \n",
      " |      This function is useful to massage a DataFrame into a format where one\n",
      " |      or more columns are identifier variables (`id_vars`), while all other\n",
      " |      columns, considered measured variables (`value_vars`), are \"unpivoted\" to\n",
      " |      the row axis, leaving just two non-identifier columns, 'variable' and\n",
      " |      'value'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      id_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to use as identifier variables.\n",
      " |      value_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to unpivot. If not specified, uses all columns that\n",
      " |          are not set as `id_vars`.\n",
      " |      var_name : scalar\n",
      " |          Name to use for the 'variable' column. If None it uses\n",
      " |          ``frame.columns.name`` or 'variable'.\n",
      " |      value_name : scalar, default 'value'\n",
      " |          Name to use for the 'value' column.\n",
      " |      col_level : int or str, optional\n",
      " |          If columns are a MultiIndex then use this level to melt.\n",
      " |      ignore_index : bool, default True\n",
      " |          If True, original index is ignored. If False, the original index is retained.\n",
      " |          Index labels will be repeated as necessary.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Unpivoted DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      melt : Identical method.\n",
      " |      pivot_table : Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      DataFrame.pivot : Return reshaped DataFrame organized\n",
      " |          by given index / column values.\n",
      " |      DataFrame.explode : Explode a DataFrame from list-like\n",
      " |              columns to long format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.melt>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
      " |      ...                    'B': {0: 1, 1: 3, 2: 5},\n",
      " |      ...                    'C': {0: 2, 1: 4, 2: 6}})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      3  a        C      2\n",
      " |      4  b        C      4\n",
      " |      5  c        C      6\n",
      " |      \n",
      " |      The names of 'variable' and 'value' columns can be customized:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'],\n",
      " |      ...         var_name='myVarname', value_name='myValname')\n",
      " |         A myVarname  myValname\n",
      " |      0  a         B          1\n",
      " |      1  b         B          3\n",
      " |      2  c         B          5\n",
      " |      \n",
      " |      Original index values can be kept around:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      0  a        C      2\n",
      " |      1  b        C      4\n",
      " |      2  c        C      6\n",
      " |      \n",
      " |      If you have multi-index columns:\n",
      " |      \n",
      " |      >>> df.columns = [list('ABC'), list('DEF')]\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |         D  E  F\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])\n",
      " |        (A, D) variable_0 variable_1  value\n",
      " |      0      a          B          E      1\n",
      " |      1      b          B          E      3\n",
      " |      2      c          B          E      5\n",
      " |  \n",
      " |  memory_usage(self, index: 'bool' = True, deep: 'bool' = False) -> 'Series'\n",
      " |      Return the memory usage of each column in bytes.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and elements of `object` dtype.\n",
      " |      \n",
      " |      This value is displayed in `DataFrame.info` by default. This can be\n",
      " |      suppressed by setting ``pandas.options.display.memory_usage`` to False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the DataFrame's\n",
      " |          index in returned Series. If ``index=True``, the memory usage of\n",
      " |          the index is the first item in the output.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A Series whose index is the original column names and whose values\n",
      " |          is the memory usage of each column in bytes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n",
      " |          ndarray.\n",
      " |      Series.memory_usage : Bytes consumed by a Series.\n",
      " |      Categorical : Memory-efficient array for string values with\n",
      " |          many repeated values.\n",
      " |      DataFrame.info : Concise summary of a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the :ref:`Frequently Asked Questions <df-memory-usage>` for more\n",
      " |      details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n",
      " |      >>> data = dict([(t, np.ones(shape=5000, dtype=int).astype(t))\n",
      " |      ...              for t in dtypes])\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df.head()\n",
      " |         int64  float64            complex128  object  bool\n",
      " |      0      1      1.0              1.0+0.0j       1  True\n",
      " |      1      1      1.0              1.0+0.0j       1  True\n",
      " |      2      1      1.0              1.0+0.0j       1  True\n",
      " |      3      1      1.0              1.0+0.0j       1  True\n",
      " |      4      1      1.0              1.0+0.0j       1  True\n",
      " |      \n",
      " |      >>> df.memory_usage()\n",
      " |      Index           128\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.memory_usage(index=False)\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The memory footprint of `object` dtype columns is ignored by default:\n",
      " |      \n",
      " |      >>> df.memory_usage(deep=True)\n",
      " |      Index            128\n",
      " |      int64          40000\n",
      " |      float64        40000\n",
      " |      complex128     80000\n",
      " |      object        180000\n",
      " |      bool            5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a Categorical for efficient storage of an object-dtype column with\n",
      " |      many repeated values.\n",
      " |      \n",
      " |      >>> df['object'].astype('category').memory_usage(deep=True)\n",
      " |      5244\n",
      " |  \n",
      " |  merge(self, right: 'DataFrame | Series', how: 'str' = 'inner', on: 'IndexLabel | None' = None, left_on: 'IndexLabel | None' = None, right_on: 'IndexLabel | None' = None, left_index: 'bool' = False, right_index: 'bool' = False, sort: 'bool' = False, suffixes: 'Suffixes' = ('_x', '_y'), copy: 'bool' = True, indicator: 'bool' = False, validate: 'str | None' = None) -> 'DataFrame'\n",
      " |      Merge DataFrame or named Series objects with a database-style join.\n",
      " |      \n",
      " |      A named Series object is treated as a DataFrame with a single named column.\n",
      " |      \n",
      " |      The join is done on columns or indexes. If joining columns on\n",
      " |      columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      " |      on indexes or indexes on a column or columns, the index will be passed on.\n",
      " |      When performing a cross merge, no column specifications to merge on are\n",
      " |      allowed.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          If both key columns contain rows where the key is a null value, those\n",
      " |          rows will be matched against each other. This is different from usual SQL\n",
      " |          join behaviour and can lead to unexpected results.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : DataFrame or named Series\n",
      " |          Object to merge with.\n",
      " |      how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
      " |          Type of merge to be performed.\n",
      " |      \n",
      " |          * left: use only keys from left frame, similar to a SQL left outer join;\n",
      " |            preserve key order.\n",
      " |          * right: use only keys from right frame, similar to a SQL right outer join;\n",
      " |            preserve key order.\n",
      " |          * outer: use union of keys from both frames, similar to a SQL full outer\n",
      " |            join; sort keys lexicographically.\n",
      " |          * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      " |            join; preserve the order of the left keys.\n",
      " |          * cross: creates the cartesian product from both frames, preserves the order\n",
      " |            of the left keys.\n",
      " |      \n",
      " |            .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      on : label or list\n",
      " |          Column or index level names to join on. These must be found in both\n",
      " |          DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      " |          to the intersection of the columns in both DataFrames.\n",
      " |      left_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the left DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the left DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      right_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the right DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the right DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      left_index : bool, default False\n",
      " |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      " |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      " |          or a number of columns) must match the number of levels.\n",
      " |      right_index : bool, default False\n",
      " |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      " |          left_index.\n",
      " |      sort : bool, default False\n",
      " |          Sort the join keys lexicographically in the result DataFrame. If False,\n",
      " |          the order of the join keys depends on the join type (how keyword).\n",
      " |      suffixes : list-like, default is (\"_x\", \"_y\")\n",
      " |          A length-2 sequence where each element is optionally a string\n",
      " |          indicating the suffix to add to overlapping column names in\n",
      " |          `left` and `right` respectively. Pass a value of `None` instead\n",
      " |          of a string to indicate that the column name from `left` or\n",
      " |          `right` should be left as-is, with no suffix. At least one of the\n",
      " |          values must not be None.\n",
      " |      copy : bool, default True\n",
      " |          If False, avoid copy if possible.\n",
      " |      indicator : bool or str, default False\n",
      " |          If True, adds a column to the output DataFrame called \"_merge\" with\n",
      " |          information on the source of each row. The column can be given a different\n",
      " |          name by providing a string argument. The column will have a Categorical\n",
      " |          type with the value of \"left_only\" for observations whose merge key only\n",
      " |          appears in the left DataFrame, \"right_only\" for observations\n",
      " |          whose merge key only appears in the right DataFrame, and \"both\"\n",
      " |          if the observation's merge key is found in both DataFrames.\n",
      " |      \n",
      " |      validate : str, optional\n",
      " |          If specified, checks if merge is of specified type.\n",
      " |      \n",
      " |          * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      " |            left and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      " |            dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      " |            dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame of the two merged objects.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_ordered : Merge with optional filling/interpolation.\n",
      " |      merge_asof : Merge on nearest keys.\n",
      " |      DataFrame.join : Similar method using indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Support for specifying index levels as the `on`, `left_on`, and\n",
      " |      `right_on` parameters was added in version 0.23.0\n",
      " |      Support for merging named Series objects was added in version 0.24.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [1, 2, 3, 5]})\n",
      " |      >>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [5, 6, 7, 8]})\n",
      " |      >>> df1\n",
      " |          lkey value\n",
      " |      0   foo      1\n",
      " |      1   bar      2\n",
      " |      2   baz      3\n",
      " |      3   foo      5\n",
      " |      >>> df2\n",
      " |          rkey value\n",
      " |      0   foo      5\n",
      " |      1   bar      6\n",
      " |      2   baz      7\n",
      " |      3   foo      8\n",
      " |      \n",
      " |      Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      " |      the default suffixes, _x and _y, appended.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      " |        lkey  value_x rkey  value_y\n",
      " |      0  foo        1  foo        5\n",
      " |      1  foo        1  foo        8\n",
      " |      2  foo        5  foo        5\n",
      " |      3  foo        5  foo        8\n",
      " |      4  bar        2  bar        6\n",
      " |      5  baz        3  baz        7\n",
      " |      \n",
      " |      Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      " |      appended to any overlapping columns.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      " |      ...           suffixes=('_left', '_right'))\n",
      " |        lkey  value_left rkey  value_right\n",
      " |      0  foo           1  foo            5\n",
      " |      1  foo           1  foo            8\n",
      " |      2  foo           5  foo            5\n",
      " |      3  foo           5  foo            8\n",
      " |      4  bar           2  bar            6\n",
      " |      5  baz           3  baz            7\n",
      " |      \n",
      " |      Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      " |      any overlapping columns.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: columns overlap but no suffix specified:\n",
      " |          Index(['value'], dtype='object')\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
      " |      >>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
      " |      >>> df1\n",
      " |            a  b\n",
      " |      0   foo  1\n",
      " |      1   bar  2\n",
      " |      >>> df2\n",
      " |            a  c\n",
      " |      0   foo  3\n",
      " |      1   baz  4\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='inner', on='a')\n",
      " |            a  b  c\n",
      " |      0   foo  1  3\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='left', on='a')\n",
      " |            a  b  c\n",
      " |      0   foo  1  3.0\n",
      " |      1   bar  2  NaN\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
      " |      >>> df2 = pd.DataFrame({'right': [7, 8]})\n",
      " |      >>> df1\n",
      " |          left\n",
      " |      0   foo\n",
      " |      1   bar\n",
      " |      >>> df2\n",
      " |          right\n",
      " |      0   7\n",
      " |      1   8\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='cross')\n",
      " |         left  right\n",
      " |      0   foo      7\n",
      " |      1   foo      8\n",
      " |      2   bar      7\n",
      " |      3   bar      8\n",
      " |  \n",
      " |  min(self, axis: 'int | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the minimum of the values over the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the minimum, use ``idxmin``. This is the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.min()\n",
      " |      0\n",
      " |  \n",
      " |  mod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmod`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  mode(self, axis: 'Axis' = 0, numeric_only: 'bool' = False, dropna: 'bool' = True) -> 'DataFrame'\n",
      " |      Get the mode(s) of each element along the selected axis.\n",
      " |      \n",
      " |      The mode of a set of values is the value that appears most often.\n",
      " |      It can be multiple values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to iterate over while searching for the mode:\n",
      " |      \n",
      " |          * 0 or 'index' : get mode of each column\n",
      " |          * 1 or 'columns' : get mode of each row.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          If True, only apply to numeric columns.\n",
      " |      dropna : bool, default True\n",
      " |          Don't consider counts of NaN/NaT.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The modes of each column or row.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mode : Return the highest frequency value in a Series.\n",
      " |      Series.value_counts : Return the counts of values in a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 2, 2),\n",
      " |      ...                    ('mammal', 4, np.nan),\n",
      " |      ...                    ('arthropod', 8, 0),\n",
      " |      ...                    ('bird', 2, np.nan)],\n",
      " |      ...                   index=('falcon', 'horse', 'spider', 'ostrich'),\n",
      " |      ...                   columns=('species', 'legs', 'wings'))\n",
      " |      >>> df\n",
      " |                 species  legs  wings\n",
      " |      falcon        bird     2    2.0\n",
      " |      horse       mammal     4    NaN\n",
      " |      spider   arthropod     8    0.0\n",
      " |      ostrich       bird     2    NaN\n",
      " |      \n",
      " |      By default, missing values are not considered, and the mode of wings\n",
      " |      are both 0 and 2. Because the resulting DataFrame has two rows,\n",
      " |      the second row of ``species`` and ``legs`` contains ``NaN``.\n",
      " |      \n",
      " |      >>> df.mode()\n",
      " |        species  legs  wings\n",
      " |      0    bird   2.0    0.0\n",
      " |      1     NaN   NaN    2.0\n",
      " |      \n",
      " |      Setting ``dropna=False`` ``NaN`` values are considered and they can be\n",
      " |      the mode (like for wings).\n",
      " |      \n",
      " |      >>> df.mode(dropna=False)\n",
      " |        species  legs  wings\n",
      " |      0    bird     2    NaN\n",
      " |      \n",
      " |      Setting ``numeric_only=True``, only the mode of numeric columns is\n",
      " |      computed, and columns of other types are ignored.\n",
      " |      \n",
      " |      >>> df.mode(numeric_only=True)\n",
      " |         legs  wings\n",
      " |      0   2.0    0.0\n",
      " |      1   NaN    2.0\n",
      " |      \n",
      " |      To compute the mode over columns and not rows, use the axis parameter:\n",
      " |      \n",
      " |      >>> df.mode(axis='columns', numeric_only=True)\n",
      " |                 0    1\n",
      " |      falcon   2.0  NaN\n",
      " |      horse    4.0  NaN\n",
      " |      spider   0.0  8.0\n",
      " |      ostrich  2.0  NaN\n",
      " |  \n",
      " |  mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmul`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  multiply = mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  ne(self, other, axis='columns', level=None)\n",
      " |      Get Not equal to of dataframe and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  nlargest(self, n: 'int', columns: 'IndexLabel', keep: 'str' = 'first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in descending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the largest values in `columns`, in\n",
      " |      descending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=False).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of rows to return.\n",
      " |      columns : label or list of labels\n",
      " |          Column label(s) to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - ``first`` : prioritize the first occurrence(s)\n",
      " |          - ``last`` : prioritize the last occurrence(s)\n",
      " |          - ``all`` : do not drop any duplicates, even it means\n",
      " |            selecting more than `n` items.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The first `n` rows ordered by the given columns in descending\n",
      " |          order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\n",
      " |          ascending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function cannot be used with all column types. For example, when\n",
      " |      specifying columns with `object` or `category` dtypes, ``TypeError`` is\n",
      " |      raised.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 11300,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru          11300      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |      \n",
      " |      In the following example, we will use ``nlargest`` to select the three\n",
      " |      rows having the largest values in column \"population\".\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Malta       434000    12011      MT\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population', keep='last')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |      \n",
      " |      When using ``keep='all'``, all duplicate items are maintained:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population', keep='all')\n",
      " |                population      GDP alpha-2\n",
      " |      France      65000000  2583560      FR\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      \n",
      " |      To order by the largest values in column \"population\" and then \"GDP\",\n",
      " |      we can specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nlargest(3, ['population', 'GDP'])\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |  \n",
      " |  notna(self) -> 'DataFrame'\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self) -> 'DataFrame'\n",
      " |      DataFrame.notnull is an alias for DataFrame.notna.\n",
      " |      \n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n: 'int', columns: 'IndexLabel', keep: 'str' = 'first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in ascending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the smallest values in `columns`, in\n",
      " |      ascending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=True).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of items to retrieve.\n",
      " |      columns : list or str\n",
      " |          Column name or names to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |          - ``all`` : do not drop any duplicates, even it means\n",
      " |            selecting more than `n` items.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nlargest : Return the first `n` rows ordered by `columns` in\n",
      " |          descending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 337000,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru         337000      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |      \n",
      " |      In the following example, we will use ``nsmallest`` to select the\n",
      " |      three rows having the smallest values in column \"population\".\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population', keep='last')\n",
      " |                population  GDP alpha-2\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Nauru         337000  182      NR\n",
      " |      \n",
      " |      When using ``keep='all'``, all duplicate items are maintained:\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population', keep='all')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      Nauru         337000    182      NR\n",
      " |      \n",
      " |      To order by the smallest values in column \"population\" and then \"GDP\", we can\n",
      " |      specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nsmallest(3, ['population', 'GDP'])\n",
      " |                population  GDP alpha-2\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Nauru         337000  182      NR\n",
      " |  \n",
      " |  nunique(self, axis: 'Axis' = 0, dropna: 'bool' = True) -> 'Series'\n",
      " |      Count number of distinct elements in specified axis.\n",
      " |      \n",
      " |      Return Series with number of distinct elements. Can ignore NaN\n",
      " |      values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nunique: Method nunique for Series.\n",
      " |      DataFrame.count: Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]})\n",
      " |      >>> df.nunique()\n",
      " |      A    3\n",
      " |      B    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.nunique(axis=1)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  pivot(self, *, index=None, columns=None, values=None) -> 'DataFrame'\n",
      " |      Return reshaped DataFrame organized by given index / column values.\n",
      " |      \n",
      " |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      " |      unique values from specified `index` / `columns` to form axes of the\n",
      " |      resulting DataFrame. This function does not support data\n",
      " |      aggregation, multiple values will result in a MultiIndex in the\n",
      " |      columns. See the :ref:`User Guide <reshaping>` for more on reshaping.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : str or object or a list of str, optional\n",
      " |          Column to use to make new frame's index. If None, uses\n",
      " |          existing index.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |             Also accept list of index names.\n",
      " |      \n",
      " |      columns : str or object or a list of str\n",
      " |          Column to use to make new frame's columns.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |             Also accept list of columns names.\n",
      " |      \n",
      " |      values : str, object or a list of the previous, optional\n",
      " |          Column(s) to use for populating new frame's values. If not\n",
      " |          specified, all remaining columns will be used and the result will\n",
      " |          have hierarchically indexed columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Returns reshaped DataFrame.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError:\n",
      " |          When there are any `index`, `columns` combinations with multiple\n",
      " |          values. `DataFrame.pivot_table` when you need to aggregate.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot_table : Generalization of pivot that can handle\n",
      " |          duplicate values for one index/column pair.\n",
      " |      DataFrame.unstack : Pivot based on the index values instead of a\n",
      " |          column.\n",
      " |      wide_to_long : Wide panel to long format. Less flexible but more\n",
      " |          user-friendly than melt.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For finer-tuned control, see hierarchical indexing documentation along\n",
      " |      with the related stack/unstack methods.\n",
      " |      \n",
      " |      Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n",
      " |      ...                            'two'],\n",
      " |      ...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
      " |      ...                    'baz': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n",
      " |      >>> df\n",
      " |          foo   bar  baz  zoo\n",
      " |      0   one   A    1    x\n",
      " |      1   one   B    2    y\n",
      " |      2   one   C    3    z\n",
      " |      3   two   A    4    q\n",
      " |      4   two   B    5    w\n",
      " |      5   two   C    6    t\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar')['baz']\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])\n",
      " |            baz       zoo\n",
      " |      bar   A  B  C   A  B  C\n",
      " |      foo\n",
      " |      one   1  2  3   x  y  z\n",
      " |      two   4  5  6   q  w  t\n",
      " |      \n",
      " |      You could also assign a list of column names or a list of index names.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...        \"lev1\": [1, 1, 1, 2, 2, 2],\n",
      " |      ...        \"lev2\": [1, 1, 2, 1, 1, 2],\n",
      " |      ...        \"lev3\": [1, 2, 1, 2, 1, 2],\n",
      " |      ...        \"lev4\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...        \"values\": [0, 1, 2, 3, 4, 5]})\n",
      " |      >>> df\n",
      " |          lev1 lev2 lev3 lev4 values\n",
      " |      0   1    1    1    1    0\n",
      " |      1   1    1    2    2    1\n",
      " |      2   1    2    1    3    2\n",
      " |      3   2    1    2    4    3\n",
      " |      4   2    1    1    5    4\n",
      " |      5   2    2    2    6    5\n",
      " |      \n",
      " |      >>> df.pivot(index=\"lev1\", columns=[\"lev2\", \"lev3\"],values=\"values\")\n",
      " |      lev2    1         2\n",
      " |      lev3    1    2    1    2\n",
      " |      lev1\n",
      " |      1     0.0  1.0  2.0  NaN\n",
      " |      2     4.0  3.0  NaN  5.0\n",
      " |      \n",
      " |      >>> df.pivot(index=[\"lev1\", \"lev2\"], columns=[\"lev3\"],values=\"values\")\n",
      " |            lev3    1    2\n",
      " |      lev1  lev2\n",
      " |         1     1  0.0  1.0\n",
      " |               2  2.0  NaN\n",
      " |         2     1  4.0  3.0\n",
      " |               2  NaN  5.0\n",
      " |      \n",
      " |      A ValueError is raised if there are any duplicates.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"foo\": ['one', 'one', 'two', 'two'],\n",
      " |      ...                    \"bar\": ['A', 'A', 'B', 'C'],\n",
      " |      ...                    \"baz\": [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         foo bar  baz\n",
      " |      0  one   A    1\n",
      " |      1  one   A    2\n",
      " |      2  two   B    3\n",
      " |      3  two   C    4\n",
      " |      \n",
      " |      Notice that the first two rows are the same for our `index`\n",
      " |      and `columns` arguments.\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      Traceback (most recent call last):\n",
      " |         ...\n",
      " |      ValueError: Index contains duplicate entries, cannot reshape\n",
      " |  \n",
      " |  pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False, sort=True) -> 'DataFrame'\n",
      " |      Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      \n",
      " |      The levels in the pivot table will be stored in MultiIndex objects\n",
      " |      (hierarchical indexes) on the index and columns of the result DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : column to aggregate, optional\n",
      " |      index : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table index.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      columns : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table column.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      aggfunc : function, list of functions, dict, default numpy.mean\n",
      " |          If list of functions passed, the resulting pivot table will have\n",
      " |          hierarchical columns whose top level are the function names\n",
      " |          (inferred from the function objects themselves)\n",
      " |          If dict is passed, the key is column to aggregate and value\n",
      " |          is function or list of functions.\n",
      " |      fill_value : scalar, default None\n",
      " |          Value to replace missing values with (in the resulting pivot table,\n",
      " |          after aggregation).\n",
      " |      margins : bool, default False\n",
      " |          Add all row / columns (e.g. for subtotal / grand totals).\n",
      " |      dropna : bool, default True\n",
      " |          Do not include columns whose entries are all NaN. If True,\n",
      " |          rows with a NaN value in any column will be omitted before\n",
      " |          computing margins.\n",
      " |      margins_name : str, default 'All'\n",
      " |          Name of the row / column that will contain the totals\n",
      " |          when margins is True.\n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      sort : bool, default True\n",
      " |          Specifies if the result should be sorted.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          An Excel style pivot table.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot without aggregation that can handle\n",
      " |          non-numeric data.\n",
      " |      DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
      " |          optionally leaving identifiers set.\n",
      " |      wide_to_long : Wide panel to long format. Less flexible but more\n",
      " |          user-friendly than melt.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      " |      ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      " |      ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      " |      ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      " |      ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      " |      ...                          \"small\", \"large\", \"small\", \"small\",\n",
      " |      ...                          \"large\"],\n",
      " |      ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      " |      ...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      " |      >>> df\n",
      " |           A    B      C  D  E\n",
      " |      0  foo  one  small  1  2\n",
      " |      1  foo  one  large  2  4\n",
      " |      2  foo  one  large  2  5\n",
      " |      3  foo  two  small  3  5\n",
      " |      4  foo  two  small  3  6\n",
      " |      5  bar  one  large  4  6\n",
      " |      6  bar  one  small  5  8\n",
      " |      7  bar  two  small  6  9\n",
      " |      8  bar  two  large  7  9\n",
      " |      \n",
      " |      This first example aggregates values by taking the sum.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one    4.0    5.0\n",
      " |          two    7.0    6.0\n",
      " |      foo one    4.0    1.0\n",
      " |          two    NaN    6.0\n",
      " |      \n",
      " |      We can also fill missing values using the `fill_value` parameter.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum, fill_value=0)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one      4      5\n",
      " |          two      7      6\n",
      " |      foo one      4      1\n",
      " |          two      0      6\n",
      " |      \n",
      " |      The next example aggregates by taking the mean across multiple columns.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                     aggfunc={'D': np.mean,\n",
      " |      ...                              'E': np.mean})\n",
      " |      >>> table\n",
      " |                      D         E\n",
      " |      A   C\n",
      " |      bar large  5.500000  7.500000\n",
      " |          small  5.500000  8.500000\n",
      " |      foo large  2.000000  4.500000\n",
      " |          small  2.333333  4.333333\n",
      " |      \n",
      " |      We can also calculate multiple types of aggregations for any given\n",
      " |      value column.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                     aggfunc={'D': np.mean,\n",
      " |      ...                              'E': [min, max, np.mean]})\n",
      " |      >>> table\n",
      " |                        D   E\n",
      " |                     mean max      mean  min\n",
      " |      A   C\n",
      " |      bar large  5.500000   9  7.500000    6\n",
      " |          small  5.500000   9  8.500000    8\n",
      " |      foo large  2.000000   5  4.500000    4\n",
      " |          small  2.333333   6  4.333333    2\n",
      " |  \n",
      " |  pop(self, item: 'Hashable') -> 'Series'\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : label\n",
      " |          Label of column to be popped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  pow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rpow`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=True, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=True, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |  \n",
      " |  quantile(self, q: 'float | AnyArrayLike | Sequence[float]' = 0.5, axis: 'Axis' = 0, numeric_only: 'bool | lib.NoDefault' = <no_default>, interpolation: 'QuantileInterpolation' = 'linear', method: \"Literal['single', 'table']\" = 'single') -> 'Series | DataFrame'\n",
      " |      Return values at the given quantile over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value between 0 <= q <= 1, the quantile(s) to compute.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      numeric_only : bool, default True\n",
      " |          If False, the quantile of datetime and timedelta data will be\n",
      " |          computed as well.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              The default value of ``numeric_only`` will be ``False`` in a future\n",
      " |              version of pandas.\n",
      " |      \n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      method : {'single', 'table'}, default 'single'\n",
      " |          Whether to compute quantiles per-column ('single') or over all columns\n",
      " |          ('table'). When 'table', the only allowed interpolation methods are\n",
      " |          'nearest', 'lower', and 'higher'.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |          If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.rolling.Rolling.quantile: Rolling quantile.\n",
      " |      numpy.percentile: Numpy function to compute the percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      Name: 0.1, dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |      \n",
      " |      Specifying `method='table'` will compute the quantile over all columns.\n",
      " |      \n",
      " |      >>> df.quantile(.1, method=\"table\", interpolation=\"nearest\")\n",
      " |      a    1\n",
      " |      b    1\n",
      " |      Name: 0.1, dtype: int64\n",
      " |      >>> df.quantile([.1, .5], method=\"table\", interpolation=\"nearest\")\n",
      " |           a    b\n",
      " |      0.1  1    1\n",
      " |      0.5  3  100\n",
      " |      \n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |      ...                    'B': [pd.Timestamp('2010'),\n",
      " |      ...                          pd.Timestamp('2011')],\n",
      " |      ...                    'C': [pd.Timedelta('1 days'),\n",
      " |      ...                          pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |  \n",
      " |  query(self, expr: 'str', *, inplace: 'bool' = False, **kwargs) -> 'DataFrame | None'\n",
      " |      Query the columns of a DataFrame with a boolean expression.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The query string to evaluate.\n",
      " |      \n",
      " |          You can refer to variables\n",
      " |          in the environment by prefixing them with an '@' character like\n",
      " |          ``@a + b``.\n",
      " |      \n",
      " |          You can refer to column names that are not valid Python variable names\n",
      " |          by surrounding them in backticks. Thus, column names containing spaces\n",
      " |          or punctuations (besides underscores) or starting with digits must be\n",
      " |          surrounded by backticks. (For example, a column named \"Area (cm^2)\" would\n",
      " |          be referenced as ```Area (cm^2)```). Column names which are Python keywords\n",
      " |          (like \"list\", \"for\", \"import\", etc) cannot be used.\n",
      " |      \n",
      " |          For example, if one of your columns is called ``a a`` and you want\n",
      " |          to sum it with ``b``, your query should be ```a a` + b``.\n",
      " |      \n",
      " |          .. versionadded:: 0.25.0\n",
      " |              Backtick quoting introduced.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |              Expanding functionality of backtick quoting for more than only spaces.\n",
      " |      \n",
      " |      inplace : bool\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame resulting from the provided query expression or\n",
      " |          None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      DataFrame.eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The result of the evaluation of this expression is first passed to\n",
      " |      :attr:`DataFrame.loc` and if that fails because of a\n",
      " |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      " |      to :meth:`DataFrame.__getitem__`.\n",
      " |      \n",
      " |      This method uses the top-level :func:`eval` function to\n",
      " |      evaluate the passed query.\n",
      " |      \n",
      " |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      " |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      " |      (bitwise) operators have the precedence of their boolean cousins,\n",
      " |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      " |      however the semantics are different.\n",
      " |      \n",
      " |      You can change the semantics of the expression by passing the keyword\n",
      " |      argument ``parser='python'``. This enforces the same semantics as\n",
      " |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      " |      to evaluate an expression using Python itself as a backend. This is not\n",
      " |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      " |      engine.\n",
      " |      \n",
      " |      The :attr:`DataFrame.index` and\n",
      " |      :attr:`DataFrame.columns` attributes of the\n",
      " |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      " |      by default, which allows you to treat both the index and columns of the\n",
      " |      frame as a column in the frame.\n",
      " |      The identifier ``index`` is used for the frame index; you can also\n",
      " |      use the name of the index to identify it in a query. Please note that\n",
      " |      Python keywords may not be used as identifiers.\n",
      " |      \n",
      " |      For further details and examples see the ``query`` documentation in\n",
      " |      :ref:`indexing <indexing.query>`.\n",
      " |      \n",
      " |      *Backtick quoted variables*\n",
      " |      \n",
      " |      Backtick quoted variables are parsed as literal Python code and\n",
      " |      are converted internally to a Python valid identifier.\n",
      " |      This can lead to the following problems.\n",
      " |      \n",
      " |      During parsing a number of disallowed characters inside the backtick\n",
      " |      quoted string are replaced by strings that are allowed as a Python identifier.\n",
      " |      These characters include all operators in Python, the space character, the\n",
      " |      question mark, the exclamation mark, the dollar sign, and the euro sign.\n",
      " |      For other characters that fall outside the ASCII range (U+0001..U+007F)\n",
      " |      and those that are not further specified in PEP 3131,\n",
      " |      the query parser will raise an error.\n",
      " |      This excludes whitespace different than the space character,\n",
      " |      but also the hashtag (as it is used for comments) and the backtick\n",
      " |      itself (backtick can also not be escaped).\n",
      " |      \n",
      " |      In a special case, quotes that make a pair around a backtick can\n",
      " |      confuse the parser.\n",
      " |      For example, ```it's` > `that's``` will raise an error,\n",
      " |      as it forms a quoted string (``'s > `that'``) with a backtick inside.\n",
      " |      \n",
      " |      See also the Python documentation about lexical analysis\n",
      " |      (https://docs.python.org/3/reference/lexical_analysis.html)\n",
      " |      in combination with the source code in :mod:`pandas.core.computation.parsing`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6),\n",
      " |      ...                    'B': range(10, 0, -2),\n",
      " |      ...                    'C C': range(10, 5, -1)})\n",
      " |      >>> df\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      1  2   8    9\n",
      " |      2  3   6    8\n",
      " |      3  4   4    7\n",
      " |      4  5   2    6\n",
      " |      >>> df.query('A > B')\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |      \n",
      " |      The previous expression is equivalent to\n",
      " |      \n",
      " |      >>> df[df.A > df.B]\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |      \n",
      " |      For columns with spaces in their name, you can use backtick quoting.\n",
      " |      \n",
      " |      >>> df.query('B == `C C`')\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      \n",
      " |      The previous expression is equivalent to\n",
      " |      \n",
      " |      >>> df[df.B == df['C C']]\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |  \n",
      " |  radd(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `add`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  reindex(self, labels=None, index=None, columns=None, axis=None, method=None, copy=None, level=None, fill_value=nan, limit=None, tolerance=None)\n",
      " |      Conform Series/DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Places NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      ``copy=False``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      keywords for axes : array-like, optional\n",
      " |          New labels / index to conform to, should be specified using\n",
      " |          keywords. Preferably an Index object to avoid duplicating data.\n",
      " |      \n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: Propagate last valid observation forward to next\n",
      " |            valid.\n",
      " |          * backfill / bfill: Use next valid observation to fill gap.\n",
      " |          * nearest: Use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame with changed index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
      " |      ...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...              'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to back-propagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29   100.0\n",
      " |      2009-12-30   100.0\n",
      " |      2009-12-31   100.0\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |  \n",
      " |  rename(self, mapper: 'Renamer | None' = None, *, index: 'Renamer | None' = None, columns: 'Renamer | None' = None, axis: 'Axis | None' = None, copy: 'bool | None' = None, inplace: 'bool' = False, level: 'Level' = None, errors: 'IgnoreRaise' = 'ignore') -> 'DataFrame | None'\n",
      " |      Alter axes labels.\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : dict-like or function\n",
      " |          Dict-like or function transformations to apply to\n",
      " |          that axis' values. Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index`` and\n",
      " |          ``columns``.\n",
      " |      index : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=0``\n",
      " |          is equivalent to ``index=mapper``).\n",
      " |      columns : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=1``\n",
      " |          is equivalent to ``columns=mapper``).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to target with ``mapper``. Can be either the axis name\n",
      " |          ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |          If True then value of copy is ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      errors : {'ignore', 'raise'}, default 'ignore'\n",
      " |          If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n",
      " |          or `columns` contains labels that are not present in the Index\n",
      " |          being transformed.\n",
      " |          If 'ignore', existing keys will be renamed and extra keys will be\n",
      " |          ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the renamed axis labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis and\n",
      " |          \"errors='raise'\".\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Set the name of the axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.rename`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Rename columns using a mapping:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
      " |         a  c\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      Rename index using a mapping:\n",
      " |      \n",
      " |      >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
      " |         A  B\n",
      " |      x  1  4\n",
      " |      y  2  5\n",
      " |      z  3  6\n",
      " |      \n",
      " |      Cast index labels to a different type:\n",
      " |      \n",
      " |      >>> df.index\n",
      " |      RangeIndex(start=0, stop=3, step=1)\n",
      " |      >>> df.rename(index=str).index\n",
      " |      Index(['0', '1', '2'], dtype='object')\n",
      " |      \n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n",
      " |      Traceback (most recent call last):\n",
      " |      KeyError: ['C'] not found in axis\n",
      " |      \n",
      " |      Using axis-style parameters:\n",
      " |      \n",
      " |      >>> df.rename(str.lower, axis='columns')\n",
      " |         a  b\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      2  2  5\n",
      " |      4  3  6\n",
      " |  \n",
      " |  reorder_levels(self, order: 'Sequence[Axis]', axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      Rearrange index levels using input order. May not drop or duplicate levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int or list of str\n",
      " |          List representing new level order. Reference level by number\n",
      " |          (position) or by key (label).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Where to reorder levels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {\n",
      " |      ...     \"class\": [\"Mammals\", \"Mammals\", \"Reptiles\"],\n",
      " |      ...     \"diet\": [\"Omnivore\", \"Carnivore\", \"Carnivore\"],\n",
      " |      ...     \"species\": [\"Humans\", \"Dogs\", \"Snakes\"],\n",
      " |      ... }\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"class\", \"diet\", \"species\"])\n",
      " |      >>> df = df.set_index([\"class\", \"diet\"])\n",
      " |      >>> df\n",
      " |                                        species\n",
      " |      class      diet\n",
      " |      Mammals    Omnivore                Humans\n",
      " |                 Carnivore                 Dogs\n",
      " |      Reptiles   Carnivore               Snakes\n",
      " |      \n",
      " |      Let's reorder the levels of the index:\n",
      " |      \n",
      " |      >>> df.reorder_levels([\"diet\", \"class\"])\n",
      " |                                        species\n",
      " |      diet      class\n",
      " |      Omnivore  Mammals                  Humans\n",
      " |      Carnivore Mammals                    Dogs\n",
      " |                Reptiles                 Snakes\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=<no_default>, *, inplace: 'bool' = False, limit: 'int | None' = None, regex: 'bool' = False, method: \"Literal['pad', 'ffill', 'bfill'] | lib.NoDefault\" = <no_default>) -> 'DataFrame | None'\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the DataFrame are replaced with other values dynamically.\n",
      " |      \n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way, the optional `value`\n",
      " |                parameter should not be given.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The optional `value`\n",
      " |                parameter should not be specified to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill'}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |      \n",
      " |      TypeError\n",
      " |          * If `to_replace` is not a scalar, array-like, ``dict``, or ``None``\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |      \n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.fillna : Fill NA values.\n",
      " |      DataFrame.where : Replace values based on boolean condition.\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5])\n",
      " |      >>> s.replace(1, 5)\n",
      " |      0    5\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |          A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    3\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |              A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |              A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |              A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the peculiarities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value`` is not explicitly passed and `to_replace` is a scalar, list\n",
      " |      or tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      \n",
      " |      >>> s.replace('a')\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |      \n",
      " |      On the other hand, if ``None`` is explicitly passed for ``value``, it will\n",
      " |      be respected:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |              Previously the explicit ``None`` was silently ignored.\n",
      " |  \n",
      " |  resample(self, rule, axis: 'Axis' = 0, closed: 'str | None' = None, label: 'str | None' = None, convention: 'str' = 'start', kind: 'str | None' = None, loffset=None, base: 'int | None' = None, on: 'Level' = None, level: 'Level' = None, origin: 'str | TimestampConvertibleTypes' = 'start_day', offset: 'TimedeltaConvertibleTypes | None' = None, group_keys: 'bool | lib.NoDefault' = <no_default>) -> 'Resampler'\n",
      " |      Resample time-series data.\n",
      " |      \n",
      " |      Convenience method for frequency conversion and resampling of time series.\n",
      " |      The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,\n",
      " |      or `TimedeltaIndex`), or the caller must pass the label of a datetime-like\n",
      " |      series/index to the ``on``/``level`` keyword parameter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : DateOffset, Timedelta or str\n",
      " |          The offset string or object representing target conversion.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Which axis to use for up- or down-sampling. For `Series` this parameter\n",
      " |          is unused and defaults to 0. Must be\n",
      " |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      " |      closed : {'right', 'left'}, default None\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}, default None\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      " |          For `PeriodIndex` only, controls whether to use the start or\n",
      " |          end of `rule`.\n",
      " |      kind : {'timestamp', 'period'}, optional, default None\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta, default None\n",
      " |          Adjust the resampled time labels.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |              You should add the loffset to the `df.index` after the resample.\n",
      " |              See below.\n",
      " |      \n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |              The new arguments that you should use are 'offset' or 'origin'.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      level : str or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling. `level` must be datetime-like.\n",
      " |      origin : Timestamp or str, default 'start_day'\n",
      " |          The timestamp on which to adjust the grouping. The timezone of origin\n",
      " |          must match the timezone of the index.\n",
      " |          If string, must be one of the following:\n",
      " |      \n",
      " |          - 'epoch': `origin` is 1970-01-01\n",
      " |          - 'start': `origin` is the first value of the timeseries\n",
      " |          - 'start_day': `origin` is the first day at midnight of the timeseries\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          - 'end': `origin` is the last value of the timeseries\n",
      " |          - 'end_day': `origin` is the ceiling midnight of the last day\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      offset : Timedelta or str, default is None\n",
      " |          An offset timedelta added to the origin.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      group_keys : bool, optional\n",
      " |          Whether to include the group keys in the result index when using\n",
      " |          ``.apply()`` on the resampled object. Not specifying ``group_keys``\n",
      " |          will retain values-dependent behavior from pandas 1.4\n",
      " |          and earlier (see :ref:`pandas 1.5.0 Release notes\n",
      " |          <whatsnew_150.enhancements.resample_group_keys>`\n",
      " |          for examples). In a future version of pandas, the behavior will\n",
      " |          default to the same as specifying ``group_keys=False``.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.core.Resampler\n",
      " |          :class:`~pandas.core.Resampler` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.resample : Resample a Series.\n",
      " |      DataFrame.resample : Resample a DataFrame.\n",
      " |      groupby : Group DataFrame by mapping, function, label, or list of labels.\n",
      " |      asfreq : Reindex a DataFrame with the given frequency without grouping.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`__\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``ffill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').ffill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(arraylike):\n",
      " |      ...     return np.sum(arraylike) + 5\n",
      " |      ...\n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      Resample a year by quarter using 'start' `convention`. Values are\n",
      " |      assigned to the first quarter of the period.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |      ...                                             freq='A',\n",
      " |      ...                                             periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      >>> s.resample('Q', convention='start').asfreq()\n",
      " |      2012Q1    1.0\n",
      " |      2012Q2    NaN\n",
      " |      2012Q3    NaN\n",
      " |      2012Q4    NaN\n",
      " |      2013Q1    2.0\n",
      " |      2013Q2    NaN\n",
      " |      2013Q3    NaN\n",
      " |      2013Q4    NaN\n",
      " |      Freq: Q-DEC, dtype: float64\n",
      " |      \n",
      " |      Resample quarters by month using 'end' `convention`. Values are\n",
      " |      assigned to the last month of the period.\n",
      " |      \n",
      " |      >>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',\n",
      " |      ...                                                   freq='Q',\n",
      " |      ...                                                   periods=4))\n",
      " |      >>> q\n",
      " |      2018Q1    1\n",
      " |      2018Q2    2\n",
      " |      2018Q3    3\n",
      " |      2018Q4    4\n",
      " |      Freq: Q-DEC, dtype: int64\n",
      " |      >>> q.resample('M', convention='end').asfreq()\n",
      " |      2018-03    1.0\n",
      " |      2018-04    NaN\n",
      " |      2018-05    NaN\n",
      " |      2018-06    2.0\n",
      " |      2018-07    NaN\n",
      " |      2018-08    NaN\n",
      " |      2018-09    3.0\n",
      " |      2018-10    NaN\n",
      " |      2018-11    NaN\n",
      " |      2018-12    4.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword `on` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      " |      ...                                     periods=8,\n",
      " |      ...                                     freq='W')\n",
      " |      >>> df\n",
      " |         price  volume week_starting\n",
      " |      0     10      50    2018-01-07\n",
      " |      1     11      60    2018-01-14\n",
      " |      2      9      40    2018-01-21\n",
      " |      3     13     100    2018-01-28\n",
      " |      4     14      50    2018-02-04\n",
      " |      5     18     100    2018-02-11\n",
      " |      6     17      40    2018-02-18\n",
      " |      7     19      50    2018-02-25\n",
      " |      >>> df.resample('M', on='week_starting').mean()\n",
      " |                     price  volume\n",
      " |      week_starting\n",
      " |      2018-01-31     10.75    62.5\n",
      " |      2018-02-28     17.00    60.0\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      " |      specify on which level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      " |      >>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df2 = pd.DataFrame(\n",
      " |      ...     d2,\n",
      " |      ...     index=pd.MultiIndex.from_product(\n",
      " |      ...         [days, ['morning', 'afternoon']]\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |      >>> df2\n",
      " |                            price  volume\n",
      " |      2000-01-01 morning       10      50\n",
      " |                 afternoon     11      60\n",
      " |      2000-01-02 morning        9      40\n",
      " |                 afternoon     13     100\n",
      " |      2000-01-03 morning       14      50\n",
      " |                 afternoon     18     100\n",
      " |      2000-01-04 morning       17      40\n",
      " |                 afternoon     19      50\n",
      " |      >>> df2.resample('D', level=0).sum()\n",
      " |                  price  volume\n",
      " |      2000-01-01     21     110\n",
      " |      2000-01-02     22     140\n",
      " |      2000-01-03     32     150\n",
      " |      2000-01-04     36      90\n",
      " |      \n",
      " |      If you want to adjust the start of the bins based on a fixed timestamp:\n",
      " |      \n",
      " |      >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n",
      " |      >>> rng = pd.date_range(start, end, freq='7min')\n",
      " |      >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n",
      " |      >>> ts\n",
      " |      2000-10-01 23:30:00     0\n",
      " |      2000-10-01 23:37:00     3\n",
      " |      2000-10-01 23:44:00     6\n",
      " |      2000-10-01 23:51:00     9\n",
      " |      2000-10-01 23:58:00    12\n",
      " |      2000-10-02 00:05:00    15\n",
      " |      2000-10-02 00:12:00    18\n",
      " |      2000-10-02 00:19:00    21\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 7T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min').sum()\n",
      " |      2000-10-01 23:14:00     0\n",
      " |      2000-10-01 23:31:00     9\n",
      " |      2000-10-01 23:48:00    21\n",
      " |      2000-10-02 00:05:00    54\n",
      " |      2000-10-02 00:22:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='epoch').sum()\n",
      " |      2000-10-01 23:18:00     0\n",
      " |      2000-10-01 23:35:00    18\n",
      " |      2000-10-01 23:52:00    27\n",
      " |      2000-10-02 00:09:00    39\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='2000-01-01').sum()\n",
      " |      2000-10-01 23:24:00     3\n",
      " |      2000-10-01 23:41:00    15\n",
      " |      2000-10-01 23:58:00    45\n",
      " |      2000-10-02 00:15:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to adjust the start of the bins with an `offset` Timedelta, the two\n",
      " |      following lines are equivalent:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='start').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='23h30min').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to take the largest Timestamp as the end of the bins:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='end').sum()\n",
      " |      2000-10-01 23:35:00     0\n",
      " |      2000-10-01 23:52:00    18\n",
      " |      2000-10-02 00:09:00    27\n",
      " |      2000-10-02 00:26:00    63\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      In contrast with the `start_day`, you can use `end_day` to take the ceiling\n",
      " |      midnight of the largest Timestamp as the end of the bins and drop the bins\n",
      " |      not containing data:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='end_day').sum()\n",
      " |      2000-10-01 23:38:00     3\n",
      " |      2000-10-01 23:55:00    15\n",
      " |      2000-10-02 00:12:00    45\n",
      " |      2000-10-02 00:29:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      To replace the use of the deprecated `base` argument, you can now use `offset`,\n",
      " |      in this example it is equivalent to have `base=2`:\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='2min').sum()\n",
      " |      2000-10-01 23:16:00     0\n",
      " |      2000-10-01 23:33:00     9\n",
      " |      2000-10-01 23:50:00    36\n",
      " |      2000-10-02 00:07:00    39\n",
      " |      2000-10-02 00:24:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      To replace the use of the deprecated `loffset` argument:\n",
      " |      \n",
      " |      >>> from pandas.tseries.frequencies import to_offset\n",
      " |      >>> loffset = '19min'\n",
      " |      >>> ts_out = ts.resample('17min').sum()\n",
      " |      >>> ts_out.index = ts_out.index + to_offset(loffset)\n",
      " |      >>> ts_out\n",
      " |      2000-10-01 23:33:00     0\n",
      " |      2000-10-01 23:50:00     9\n",
      " |      2000-10-02 00:07:00    21\n",
      " |      2000-10-02 00:24:00    54\n",
      " |      2000-10-02 00:41:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |  \n",
      " |  reset_index(self, level: 'IndexLabel' = None, *, drop: 'bool' = False, inplace: 'bool' = False, col_level: 'Hashable' = 0, col_fill: 'Hashable' = '', allow_duplicates: 'bool | lib.NoDefault' = <no_default>, names: 'Hashable | Sequence[Hashable]' = None) -> 'DataFrame | None'\n",
      " |      Reset the index, or a level of it.\n",
      " |      \n",
      " |      Reset the index of the DataFrame, and use the default one instead.\n",
      " |      If the DataFrame has a MultiIndex, this method can remove one or more\n",
      " |      levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default.\n",
      " |      drop : bool, default False\n",
      " |          Do not try to insert index into dataframe columns. This resets\n",
      " |          the index to the default integer index.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      col_level : int or str, default 0\n",
      " |          If the columns have multiple levels, determines which level the\n",
      " |          labels are inserted into. By default it is inserted into the first\n",
      " |          level.\n",
      " |      col_fill : object, default ''\n",
      " |          If the columns have multiple levels, determines how the other\n",
      " |          levels are named. If None then the index name is repeated.\n",
      " |      allow_duplicates : bool, optional, default lib.no_default\n",
      " |          Allow duplicate column labels to be created.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      names : int, str or 1-dimensional list, default None\n",
      " |          Using the given string, rename the DataFrame column which contains the\n",
      " |          index data. If the DataFrame has a MultiIndex, this has to be a list or\n",
      " |          tuple with length equal to the number of levels.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the new index or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Opposite of reset_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 389.0),\n",
      " |      ...                    ('bird', 24.0),\n",
      " |      ...                    ('mammal', 80.5),\n",
      " |      ...                    ('mammal', np.nan)],\n",
      " |      ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
      " |      ...                   columns=('class', 'max_speed'))\n",
      " |      >>> df\n",
      " |               class  max_speed\n",
      " |      falcon    bird      389.0\n",
      " |      parrot    bird       24.0\n",
      " |      lion    mammal       80.5\n",
      " |      monkey  mammal        NaN\n",
      " |      \n",
      " |      When we reset the index, the old index is added as a column, and a\n",
      " |      new sequential index is used:\n",
      " |      \n",
      " |      >>> df.reset_index()\n",
      " |          index   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      We can use the `drop` parameter to avoid the old index being added as\n",
      " |      a column:\n",
      " |      \n",
      " |      >>> df.reset_index(drop=True)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      1    bird       24.0\n",
      " |      2  mammal       80.5\n",
      " |      3  mammal        NaN\n",
      " |      \n",
      " |      You can also use `reset_index` with `MultiIndex`.\n",
      " |      \n",
      " |      >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n",
      " |      ...                                    ('bird', 'parrot'),\n",
      " |      ...                                    ('mammal', 'lion'),\n",
      " |      ...                                    ('mammal', 'monkey')],\n",
      " |      ...                                   names=['class', 'name'])\n",
      " |      >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n",
      " |      ...                                      ('species', 'type')])\n",
      " |      >>> df = pd.DataFrame([(389.0, 'fly'),\n",
      " |      ...                    ( 24.0, 'fly'),\n",
      " |      ...                    ( 80.5, 'run'),\n",
      " |      ...                    (np.nan, 'jump')],\n",
      " |      ...                   index=index,\n",
      " |      ...                   columns=columns)\n",
      " |      >>> df\n",
      " |                     speed species\n",
      " |                       max    type\n",
      " |      class  name\n",
      " |      bird   falcon  389.0     fly\n",
      " |             parrot   24.0     fly\n",
      " |      mammal lion     80.5     run\n",
      " |             monkey    NaN    jump\n",
      " |      \n",
      " |      Using the `names` parameter, choose a name for the index column:\n",
      " |      \n",
      " |      >>> df.reset_index(names=['classes', 'names'])\n",
      " |        classes   names  speed species\n",
      " |                           max    type\n",
      " |      0    bird  falcon  389.0     fly\n",
      " |      1    bird  parrot   24.0     fly\n",
      " |      2  mammal    lion   80.5     run\n",
      " |      3  mammal  monkey    NaN    jump\n",
      " |      \n",
      " |      If the index has multiple levels, we can reset a subset of them:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class')\n",
      " |               class  speed species\n",
      " |                        max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      If we are not dropping the index, by default, it is placed in the top\n",
      " |      level. We can place it in another level:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1)\n",
      " |                      speed species\n",
      " |               class    max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      When the index is inserted under another level, we can specify under\n",
      " |      which one with the parameter `col_fill`:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='species')\n",
      " |                    species  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |      \n",
      " |      If we specify a nonexistent level for `col_fill`, it is created:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n",
      " |                      genus  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |  \n",
      " |  rfloordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `floordiv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rmod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mod`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rmul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mul`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  round(self, decimals: 'int | dict[IndexLabel, int] | Series' = 0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Round a DataFrame to a variable number of decimal places.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, dict, Series\n",
      " |          Number of decimal places to round each column to. If an int is\n",
      " |          given, round each column to the same number of places.\n",
      " |          Otherwise dict and Series round to variable numbers of places.\n",
      " |          Column names should be in the keys if `decimals` is a\n",
      " |          dict-like, or in the index if `decimals` is a Series. Any\n",
      " |          columns not included in `decimals` will be left as is. Elements\n",
      " |          of `decimals` which are not columns of the input will be\n",
      " |          ignored.\n",
      " |      *args\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame with the affected columns rounded to the specified\n",
      " |          number of decimal places.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : Round a numpy array to the given number of decimals.\n",
      " |      Series.round : Round a Series to the given number of decimals.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df\n",
      " |          dogs  cats\n",
      " |      0  0.21  0.32\n",
      " |      1  0.01  0.67\n",
      " |      2  0.66  0.03\n",
      " |      3  0.21  0.18\n",
      " |      \n",
      " |      By providing an integer each column is rounded to the same number\n",
      " |      of decimal places\n",
      " |      \n",
      " |      >>> df.round(1)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.3\n",
      " |      1   0.0   0.7\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.2\n",
      " |      \n",
      " |      With a dict, the number of places for specific columns can be\n",
      " |      specified with the column names as key and the number of decimal\n",
      " |      places as value\n",
      " |      \n",
      " |      >>> df.round({'dogs': 1, 'cats': 0})\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |      \n",
      " |      Using a Series, the number of places for specific columns can be\n",
      " |      specified with the column names as index and the number of\n",
      " |      decimal places as value\n",
      " |      \n",
      " |      >>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])\n",
      " |      >>> df.round(decimals)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |  \n",
      " |  rpow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `pow`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rsub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `sub`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `truediv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  select_dtypes(self, include=None, exclude=None) -> 'DataFrame'\n",
      " |      Return a subset of the DataFrame's columns based on the column dtypes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      include, exclude : scalar or list-like\n",
      " |          A selection of dtypes or strings to be included/excluded. At least\n",
      " |          one of these parameters must be supplied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The subset of the frame including the dtypes in ``include`` and\n",
      " |          excluding the dtypes in ``exclude``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If both of ``include`` and ``exclude`` are empty\n",
      " |          * If ``include`` and ``exclude`` have overlapping elements\n",
      " |          * If any kind of string dtype is passed in.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.dtypes: Return Series with the data type of each column.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * To select all *numeric* types, use ``np.number`` or ``'number'``\n",
      " |      * To select strings you must use the ``object`` dtype, but note that\n",
      " |        this will return *all* object dtype columns\n",
      " |      * See the `numpy dtype hierarchy\n",
      " |        <https://numpy.org/doc/stable/reference/arrays.scalars.html>`__\n",
      " |      * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n",
      " |        ``'datetime64'``\n",
      " |      * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n",
      " |        ``'timedelta64'``\n",
      " |      * To select Pandas categorical dtypes, use ``'category'``\n",
      " |      * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in\n",
      " |        0.20.0) or ``'datetime64[ns, tz]'``\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2] * 3,\n",
      " |      ...                    'b': [True, False] * 3,\n",
      " |      ...                    'c': [1.0, 2.0] * 3})\n",
      " |      >>> df\n",
      " |              a      b  c\n",
      " |      0       1   True  1.0\n",
      " |      1       2  False  2.0\n",
      " |      2       1   True  1.0\n",
      " |      3       2  False  2.0\n",
      " |      4       1   True  1.0\n",
      " |      5       2  False  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(include='bool')\n",
      " |         b\n",
      " |      0  True\n",
      " |      1  False\n",
      " |      2  True\n",
      " |      3  False\n",
      " |      4  True\n",
      " |      5  False\n",
      " |      \n",
      " |      >>> df.select_dtypes(include=['float64'])\n",
      " |         c\n",
      " |      0  1.0\n",
      " |      1  2.0\n",
      " |      2  1.0\n",
      " |      3  2.0\n",
      " |      4  1.0\n",
      " |      5  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(exclude=['int64'])\n",
      " |             b    c\n",
      " |      0   True  1.0\n",
      " |      1  False  2.0\n",
      " |      2   True  1.0\n",
      " |      3  False  2.0\n",
      " |      4   True  1.0\n",
      " |      5  False  2.0\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=True, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  set_axis(self, labels, *, axis: 'Axis' = 0, inplace: 'bool | lib.NoDefault' = <no_default>, copy: 'bool | lib.NoDefault' = <no_default>)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Whether to return a new DataFrame instance.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Whether to make a copy of the underlying data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : DataFrame or None\n",
      " |          An object of type DataFrame or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |              Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |              Change the row labels.\n",
      " |      \n",
      " |              >>> df.set_axis(['a', 'b', 'c'], axis='index')\n",
      " |                 A  B\n",
      " |              a  1  4\n",
      " |              b  2  5\n",
      " |              c  3  6\n",
      " |      \n",
      " |              Change the column labels.\n",
      " |      \n",
      " |              >>> df.set_axis(['I', 'II'], axis='columns')\n",
      " |                 I  II\n",
      " |              0  1   4\n",
      " |              1  2   5\n",
      " |              2  3   6\n",
      " |      \n",
      " |              Now, update the labels without copying the underlying data.\n",
      " |      \n",
      " |              >>> df.set_axis(['i', 'ii'], axis='columns', copy=False)\n",
      " |                 i  ii\n",
      " |              0  1   4\n",
      " |              1  2   5\n",
      " |              2  3   6\n",
      " |  \n",
      " |  set_index(self, keys, *, drop: 'bool' = True, append: 'bool' = False, inplace: 'bool' = False, verify_integrity: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Set the DataFrame index using existing columns.\n",
      " |      \n",
      " |      Set the DataFrame index (row labels) using one or more existing\n",
      " |      columns or arrays (of the correct length). The index can replace the\n",
      " |      existing index or expand on it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keys : label or array-like or list of labels/arrays\n",
      " |          This parameter can be either a single column key, a single array of\n",
      " |          the same length as the calling DataFrame, or a list containing an\n",
      " |          arbitrary combination of column keys and arrays. Here, \"array\"\n",
      " |          encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and\n",
      " |          instances of :class:`~collections.abc.Iterator`.\n",
      " |      drop : bool, default True\n",
      " |          Delete columns to be used as the new index.\n",
      " |      append : bool, default False\n",
      " |          Whether to append columns to existing index.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      verify_integrity : bool, default False\n",
      " |          Check the new index for duplicates. Otherwise defer the check until\n",
      " |          necessary. Setting to False will improve the performance of this\n",
      " |          method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Changed row labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index : Opposite of set_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
      " |      ...                    'year': [2012, 2014, 2013, 2014],\n",
      " |      ...                    'sale': [55, 40, 84, 31]})\n",
      " |      >>> df\n",
      " |         month  year  sale\n",
      " |      0      1  2012    55\n",
      " |      1      4  2014    40\n",
      " |      2      7  2013    84\n",
      " |      3     10  2014    31\n",
      " |      \n",
      " |      Set the index to become the 'month' column:\n",
      " |      \n",
      " |      >>> df.set_index('month')\n",
      " |             year  sale\n",
      " |      month\n",
      " |      1      2012    55\n",
      " |      4      2014    40\n",
      " |      7      2013    84\n",
      " |      10     2014    31\n",
      " |      \n",
      " |      Create a MultiIndex using columns 'year' and 'month':\n",
      " |      \n",
      " |      >>> df.set_index(['year', 'month'])\n",
      " |                  sale\n",
      " |      year  month\n",
      " |      2012  1     55\n",
      " |      2014  4     40\n",
      " |      2013  7     84\n",
      " |      2014  10    31\n",
      " |      \n",
      " |      Create a MultiIndex using an Index and a column:\n",
      " |      \n",
      " |      >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])\n",
      " |               month  sale\n",
      " |         year\n",
      " |      1  2012  1      55\n",
      " |      2  2014  4      40\n",
      " |      3  2013  7      84\n",
      " |      4  2014  10     31\n",
      " |      \n",
      " |      Create a MultiIndex using two Series:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> df.set_index([s, s**2])\n",
      " |            month  year  sale\n",
      " |      1 1       1  2012    55\n",
      " |      2 4       4  2014    40\n",
      " |      3 9       7  2013    84\n",
      " |      4 16     10  2014    31\n",
      " |  \n",
      " |  shift(self, periods: 'int' = 1, freq: 'Frequency | None' = None, axis: 'Axis' = 0, fill_value: 'Hashable' = <no_default>) -> 'DataFrame'\n",
      " |      Shift index by desired number of periods with an optional time `freq`.\n",
      " |      \n",
      " |      When `freq` is not passed, shift the index without realigning the data.\n",
      " |      If `freq` is passed (in this case, the index must be date or datetime,\n",
      " |      or it will raise a `NotImplementedError`), the index will be\n",
      " |      increased using the periods and the `freq`. `freq` can be inferred\n",
      " |      when specified as \"infer\" as long as either freq or inferred_freq\n",
      " |      attribute is set in the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to shift. Can be positive or negative.\n",
      " |      freq : DateOffset, tseries.offsets, timedelta, or str, optional\n",
      " |          Offset to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          If `freq` is specified then the index values are shifted but the\n",
      " |          data is not realigned. That is, use `freq` if you would like to\n",
      " |          extend the index when shifting and preserve the original data.\n",
      " |          If `freq` is specified as \"infer\" then it will be inferred from\n",
      " |          the freq or inferred_freq attributes of the index. If neither of\n",
      " |          those attributes exist, a ValueError is thrown.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Shift direction. For `Series` this parameter is unused and defaults to 0.\n",
      " |      fill_value : object, optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |          the default depends on the dtype of `self`.\n",
      " |          For numeric data, ``np.nan`` is used.\n",
      " |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.\n",
      " |          For extension dtypes, ``self.dtype.na_value`` is used.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Copy of input object, shifted.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      DatetimeIndex.shift : Shift values of DatetimeIndex.\n",
      " |      PeriodIndex.shift : Shift values of PeriodIndex.\n",
      " |      tshift : Shift the time index, using the index's frequency if\n",
      " |          available.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n",
      " |      ...                    \"Col2\": [13, 23, 18, 33, 48],\n",
      " |      ...                    \"Col3\": [17, 27, 22, 37, 52]},\n",
      " |      ...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n",
      " |      >>> df\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01    10    13    17\n",
      " |      2020-01-02    20    23    27\n",
      " |      2020-01-03    15    18    22\n",
      " |      2020-01-04    30    33    37\n",
      " |      2020-01-05    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN   NaN   NaN\n",
      " |      2020-01-02   NaN   NaN   NaN\n",
      " |      2020-01-03   NaN   NaN   NaN\n",
      " |      2020-01-04  10.0  13.0  17.0\n",
      " |      2020-01-05  20.0  23.0  27.0\n",
      " |      \n",
      " |      >>> df.shift(periods=1, axis=\"columns\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN    10    13\n",
      " |      2020-01-02   NaN    20    23\n",
      " |      2020-01-03   NaN    15    18\n",
      " |      2020-01-04   NaN    30    33\n",
      " |      2020-01-05   NaN    45    48\n",
      " |      \n",
      " |      >>> df.shift(periods=3, fill_value=0)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01     0     0     0\n",
      " |      2020-01-02     0     0     0\n",
      " |      2020-01-03     0     0     0\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"D\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"infer\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |  \n",
      " |  skew(self, axis: 'int | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sort_index(self, *, axis: 'Axis' = 0, level: 'IndexLabel' = None, ascending: 'bool | Sequence[bool]' = True, inplace: 'bool' = False, kind: 'SortKind' = 'quicksort', na_position: 'NaPosition' = 'last', sort_remaining: 'bool' = True, ignore_index: 'bool' = False, key: 'IndexKeyFunc' = None) -> 'DataFrame | None'\n",
      " |      Sort object by labels (along an axis).\n",
      " |      \n",
      " |      Returns a new DataFrame sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original DataFrame and returns None.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis along which to sort.  The value 0 identifies the rows,\n",
      " |          and 1 identifies the columns.\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool or list-like of bools, default True\n",
      " |          Sort ascending vs. descending. When the index is a MultiIndex the\n",
      " |          sort direction can be controlled for each level individually.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. `mergesort` and `stable` are the only stable algorithms. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If True and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the index values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect an\n",
      " |          ``Index`` and return an ``Index`` of the same shape. For MultiIndex\n",
      " |          inputs, the key is applied *per level*.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          The original DataFrame sorted by the labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort Series by the index.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the value.\n",
      " |      Series.sort_values : Sort Series by the value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df.sort_index()\n",
      " |           A\n",
      " |      1    4\n",
      " |      29   2\n",
      " |      100  1\n",
      " |      150  5\n",
      " |      234  3\n",
      " |      \n",
      " |      By default, it sorts in ascending order, to sort in descending order,\n",
      " |      use ``ascending=False``\n",
      " |      \n",
      " |      >>> df.sort_index(ascending=False)\n",
      " |           A\n",
      " |      234  3\n",
      " |      150  5\n",
      " |      100  1\n",
      " |      29   2\n",
      " |      1    4\n",
      " |      \n",
      " |      A key function can be specified which is applied to the index before\n",
      " |      sorting. For a ``MultiIndex`` this is applied to each level separately.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"a\": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])\n",
      " |      >>> df.sort_index(key=lambda x: x.str.lower())\n",
      " |         a\n",
      " |      A  1\n",
      " |      b  2\n",
      " |      C  3\n",
      " |      d  4\n",
      " |  \n",
      " |  sort_values(self, by: 'IndexLabel', *, axis: 'Axis' = 0, ascending: 'bool | list[bool] | tuple[bool, ...]' = True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', ignore_index: 'bool' = False, key: 'ValueKeyFunc' = None) -> 'DataFrame | None'\n",
      " |      Sort by the values along either axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |              by : str or list of str\n",
      " |                  Name or list of names to sort by.\n",
      " |      \n",
      " |                  - if `axis` is 0 or `'index'` then `by` may contain index\n",
      " |                    levels and/or column labels.\n",
      " |                  - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      " |                    levels and/or index labels.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |           Axis to be sorted.\n",
      " |      ascending : bool or list of bool, default True\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort\n",
      " |           orders.  If this is a list of bools, must match the length of\n",
      " |           the by.\n",
      " |      inplace : bool, default False\n",
      " |           If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |           information. `mergesort` and `stable` are the only stable algorithms. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           Puts NaNs at the beginning if `first`; `last` puts NaNs at the\n",
      " |           end.\n",
      " |      ignore_index : bool, default False\n",
      " |           If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |           .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      key : callable, optional\n",
      " |          Apply the key function to the values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect a\n",
      " |          ``Series`` and return a Series with the same shape as the input.\n",
      " |          It will be applied to each column in `by` independently.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with sorted values or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index : Sort a DataFrame by the index.\n",
      " |      Series.sort_values : Similar method for a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      " |      ...     'col2': [2, 1, 9, 8, 7, 4],\n",
      " |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      " |      ...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      \n",
      " |      Sort by col1\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1'])\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Sort by multiple columns\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1', 'col2'])\n",
      " |        col1  col2  col3 col4\n",
      " |      1    A     1     1    B\n",
      " |      0    A     2     0    a\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False)\n",
      " |        col1  col2  col3 col4\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Putting NAs first\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      " |        col1  col2  col3 col4\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      \n",
      " |      Sorting with a key function\n",
      " |      \n",
      " |      >>> df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
      " |         col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      \n",
      " |      Natural sort with the key argument,\n",
      " |      using the `natsort <https://github.com/SethMMorton/natsort>` package.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...    \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\n",
      " |      ...    \"value\": [10, 20, 30, 40, 50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          time  value\n",
      " |      0    0hr     10\n",
      " |      1  128hr     20\n",
      " |      2   72hr     30\n",
      " |      3   48hr     40\n",
      " |      4   96hr     50\n",
      " |      >>> from natsort import index_natsorted\n",
      " |      >>> df.sort_values(\n",
      " |      ...    by=\"time\",\n",
      " |      ...    key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\n",
      " |      ... )\n",
      " |          time  value\n",
      " |      0    0hr     10\n",
      " |      3   48hr     40\n",
      " |      2   72hr     30\n",
      " |      4   96hr     50\n",
      " |      1  128hr     20\n",
      " |  \n",
      " |  stack(self, level: 'Level' = -1, dropna: 'bool' = True)\n",
      " |      Stack the prescribed level(s) from columns to index.\n",
      " |      \n",
      " |      Return a reshaped DataFrame or Series having a multi-level\n",
      " |      index with one or more new inner-most levels compared to the current\n",
      " |      DataFrame. The new inner-most levels are created by pivoting the\n",
      " |      columns of the current dataframe:\n",
      " |      \n",
      " |        - if the columns have a single level, the output is a Series;\n",
      " |        - if the columns have multiple levels, the new index\n",
      " |          level(s) is (are) taken from the prescribed level(s) and\n",
      " |          the output is a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, list, default -1\n",
      " |          Level(s) to stack from the column axis onto the index\n",
      " |          axis, defined as one index or label, or a list of indices\n",
      " |          or labels.\n",
      " |      dropna : bool, default True\n",
      " |          Whether to drop rows in the resulting Frame/Series with\n",
      " |          missing values. Stacking a column level onto the index\n",
      " |          axis can create combinations of index and column values\n",
      " |          that are missing from the original dataframe. See Examples\n",
      " |          section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Stacked dataframe or series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Unstack prescribed level(s) from index axis\n",
      " |           onto column axis.\n",
      " |      DataFrame.pivot : Reshape dataframe from long format to wide\n",
      " |           format.\n",
      " |      DataFrame.pivot_table : Create a spreadsheet-style pivot table\n",
      " |           as a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function is named by analogy with a collection of books\n",
      " |      being reorganized from being side by side on a horizontal\n",
      " |      position (the columns of the dataframe) to being stacked\n",
      " |      vertically on top of each other (in the index of the\n",
      " |      dataframe).\n",
      " |      \n",
      " |      Reference :ref:`the user guide <reshaping.stacking>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Single level columns**\n",
      " |      \n",
      " |      >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=['weight', 'height'])\n",
      " |      \n",
      " |      Stacking a dataframe with a single level column axis returns a Series:\n",
      " |      \n",
      " |      >>> df_single_level_cols\n",
      " |           weight height\n",
      " |      cat       0      1\n",
      " |      dog       2      3\n",
      " |      >>> df_single_level_cols.stack()\n",
      " |      cat  weight    0\n",
      " |           height    1\n",
      " |      dog  weight    2\n",
      " |           height    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Multi level columns: simple case**\n",
      " |      \n",
      " |      >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('weight', 'pounds')])\n",
      " |      >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol1)\n",
      " |      \n",
      " |      Stacking a dataframe with a multi-level column axis:\n",
      " |      \n",
      " |      >>> df_multi_level_cols1\n",
      " |           weight\n",
      " |               kg    pounds\n",
      " |      cat       1        2\n",
      " |      dog       2        4\n",
      " |      >>> df_multi_level_cols1.stack()\n",
      " |                  weight\n",
      " |      cat kg           1\n",
      " |          pounds       2\n",
      " |      dog kg           2\n",
      " |          pounds       4\n",
      " |      \n",
      " |      **Missing values**\n",
      " |      \n",
      " |      >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('height', 'm')])\n",
      " |      >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      It is common to have missing values when stacking a dataframe\n",
      " |      with multi-level columns, as the stacked dataframe typically\n",
      " |      has more values than the original dataframe. Missing values\n",
      " |      are filled with NaNs:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    1.0    2.0\n",
      " |      dog    3.0    4.0\n",
      " |      >>> df_multi_level_cols2.stack()\n",
      " |              height  weight\n",
      " |      cat kg     NaN     1.0\n",
      " |          m      2.0     NaN\n",
      " |      dog kg     NaN     3.0\n",
      " |          m      4.0     NaN\n",
      " |      \n",
      " |      **Prescribing the level(s) to be stacked**\n",
      " |      \n",
      " |      The first parameter controls which level or levels are stacked:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2.stack(0)\n",
      " |                   kg    m\n",
      " |      cat height  NaN  2.0\n",
      " |          weight  1.0  NaN\n",
      " |      dog height  NaN  4.0\n",
      " |          weight  3.0  NaN\n",
      " |      >>> df_multi_level_cols2.stack([0, 1])\n",
      " |      cat  height  m     2.0\n",
      " |           weight  kg    1.0\n",
      " |      dog  height  m     4.0\n",
      " |           weight  kg    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **Dropping missing values**\n",
      " |      \n",
      " |      >>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      Note that rows where all values are missing are dropped by\n",
      " |      default but this behaviour can be controlled via the dropna\n",
      " |      keyword parameter:\n",
      " |      \n",
      " |      >>> df_multi_level_cols3\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    NaN    1.0\n",
      " |      dog    2.0    3.0\n",
      " |      >>> df_multi_level_cols3.stack(dropna=False)\n",
      " |              height  weight\n",
      " |      cat kg     NaN     NaN\n",
      " |          m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |      >>> df_multi_level_cols3.stack(dropna=True)\n",
      " |              height  weight\n",
      " |      cat m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |  \n",
      " |  std(self, axis=None, skipna=True, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified) \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      " |      ...                   'age': [21, 25, 62, 43],\n",
      " |      ...                   'height': [1.61, 1.87, 1.49, 2.01]}\n",
      " |      ...                  ).set_index('person_id')\n",
      " |      >>> df\n",
      " |                 age  height\n",
      " |      person_id\n",
      " |      0           21    1.61\n",
      " |      1           25    1.87\n",
      " |      2           62    1.49\n",
      " |      3           43    2.01\n",
      " |      \n",
      " |      The standard deviation of the columns can be found as follows:\n",
      " |      \n",
      " |      >>> df.std()\n",
      " |      age       18.786076\n",
      " |      height     0.237417\n",
      " |      \n",
      " |      Alternatively, `ddof=0` can be set to normalize by N instead of N-1:\n",
      " |      \n",
      " |      >>> df.std(ddof=0)\n",
      " |      age       16.269219\n",
      " |      height     0.205609\n",
      " |  \n",
      " |  sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rsub`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  subtract = sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=True, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values over the requested axis.\n",
      " |      \n",
      " |      This is equivalent to the method ``numpy.sum``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.sum()\n",
      " |      14\n",
      " |      \n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i: 'Axis' = -2, j: 'Axis' = -1, axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      Swap levels i and j in a :class:`MultiIndex`.\n",
      " |      \n",
      " |      Default is to swap the two innermost levels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int or str\n",
      " |          Levels of the indices to be swapped. Can pass level name as string.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |                  The axis to swap levels on. 0 or 'index' for row-wise, 1 or\n",
      " |                  'columns' for column-wise.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with levels swapped in MultiIndex.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\"Grade\": [\"A\", \"B\", \"A\", \"C\"]},\n",
      " |      ...     index=[\n",
      " |      ...         [\"Final exam\", \"Final exam\", \"Coursework\", \"Coursework\"],\n",
      " |      ...         [\"History\", \"Geography\", \"History\", \"Geography\"],\n",
      " |      ...         [\"January\", \"February\", \"March\", \"April\"],\n",
      " |      ...     ],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |                                          Grade\n",
      " |      Final exam  History     January      A\n",
      " |                  Geography   February     B\n",
      " |      Coursework  History     March        A\n",
      " |                  Geography   April        C\n",
      " |      \n",
      " |      In the following example, we will swap the levels of the indices.\n",
      " |      Here, we will swap the levels column-wise, but levels can be swapped row-wise\n",
      " |      in a similar manner. Note that column-wise is the default behaviour.\n",
      " |      By not supplying any arguments for i and j, we swap the last and second to\n",
      " |      last indices.\n",
      " |      \n",
      " |      >>> df.swaplevel()\n",
      " |                                          Grade\n",
      " |      Final exam  January     History         A\n",
      " |                  February    Geography       B\n",
      " |      Coursework  March       History         A\n",
      " |                  April       Geography       C\n",
      " |      \n",
      " |      By supplying one argument, we can choose which index to swap the last\n",
      " |      index with. We can for example swap the first index with the last one as\n",
      " |      follows.\n",
      " |      \n",
      " |      >>> df.swaplevel(0)\n",
      " |                                          Grade\n",
      " |      January     History     Final exam      A\n",
      " |      February    Geography   Final exam      B\n",
      " |      March       History     Coursework      A\n",
      " |      April       Geography   Coursework      C\n",
      " |      \n",
      " |      We can also define explicitly which indices we want to swap by supplying values\n",
      " |      for both i and j. Here, we for example swap the first and second indices.\n",
      " |      \n",
      " |      >>> df.swaplevel(0, 1)\n",
      " |                                          Grade\n",
      " |      History     Final exam  January         A\n",
      " |      Geography   Final exam  February        B\n",
      " |      History     Coursework  March           A\n",
      " |      Geography   Coursework  April           C\n",
      " |  \n",
      " |  to_dict(self, orient: \"Literal['dict', 'list', 'series', 'split', 'tight', 'records', 'index']\" = 'dict', into: 'type[dict]' = <class 'dict'>) -> 'dict | list[dict]'\n",
      " |      Convert the DataFrame to a dictionary.\n",
      " |      \n",
      " |      The type of the key-value pairs can be customized with the parameters\n",
      " |      (see below).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      orient : str {'dict', 'list', 'series', 'split', 'tight', 'records', 'index'}\n",
      " |          Determines the type of the values of the dictionary.\n",
      " |      \n",
      " |          - 'dict' (default) : dict like {column -> {index -> value}}\n",
      " |          - 'list' : dict like {column -> [values]}\n",
      " |          - 'series' : dict like {column -> Series(values)}\n",
      " |          - 'split' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
      " |          - 'tight' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values],\n",
      " |            'index_names' -> [index.names], 'column_names' -> [column.names]}\n",
      " |          - 'records' : list like\n",
      " |            [{column -> value}, ... , {column -> value}]\n",
      " |          - 'index' : dict like {index -> {column -> value}}\n",
      " |      \n",
      " |          Abbreviations are allowed. `s` indicates `series` and `sp`\n",
      " |          indicates `split`.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |              'tight' as an allowed value for the ``orient`` argument\n",
      " |      \n",
      " |      into : class, default dict\n",
      " |          The collections.abc.Mapping subclass used for all Mappings\n",
      " |          in the return value.  Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict, list or collections.abc.Mapping\n",
      " |          Return a collections.abc.Mapping object representing the DataFrame.\n",
      " |          The resulting transformation depends on the `orient` parameter.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict: Create a DataFrame from a dictionary.\n",
      " |      DataFrame.to_json: Convert a DataFrame to JSON format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2],\n",
      " |      ...                    'col2': [0.5, 0.75]},\n",
      " |      ...                   index=['row1', 'row2'])\n",
      " |      >>> df\n",
      " |            col1  col2\n",
      " |      row1     1  0.50\n",
      " |      row2     2  0.75\n",
      " |      >>> df.to_dict()\n",
      " |      {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\n",
      " |      \n",
      " |      You can specify the return orientation.\n",
      " |      \n",
      " |      >>> df.to_dict('series')\n",
      " |      {'col1': row1    1\n",
      " |               row2    2\n",
      " |      Name: col1, dtype: int64,\n",
      " |      'col2': row1    0.50\n",
      " |              row2    0.75\n",
      " |      Name: col2, dtype: float64}\n",
      " |      \n",
      " |      >>> df.to_dict('split')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]]}\n",
      " |      \n",
      " |      >>> df.to_dict('records')\n",
      " |      [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\n",
      " |      \n",
      " |      >>> df.to_dict('index')\n",
      " |      {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\n",
      " |      \n",
      " |      >>> df.to_dict('tight')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]], 'index_names': [None], 'column_names': [None]}\n",
      " |      \n",
      " |      You can also specify the mapping type.\n",
      " |      \n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> df.to_dict(into=OrderedDict)\n",
      " |      OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\n",
      " |                   ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\n",
      " |      \n",
      " |      If you want a `defaultdict`, you need to initialize it:\n",
      " |      \n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> df.to_dict('records', into=dd)\n",
      " |      [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\n",
      " |       defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n",
      " |  \n",
      " |  to_feather(self, path: 'FilePath | WriteBuffer[bytes]', **kwargs) -> 'None'\n",
      " |      Write a DataFrame to the binary Feather format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, file-like object\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. If a string or a path,\n",
      " |          it will be used as Root Directory path when writing a partitioned dataset.\n",
      " |      **kwargs :\n",
      " |          Additional keywords passed to :func:`pyarrow.feather.write_feather`.\n",
      " |          Starting with pyarrow 0.17, this includes the `compression`,\n",
      " |          `compression_level`, `chunksize` and `version` keywords.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function writes the dataframe as a `feather file\n",
      " |      <https://arrow.apache.org/docs/python/feather.html>`_. Requires a default\n",
      " |      index. For saving the DataFrame with your custom index use a method that\n",
      " |      supports custom indices e.g. `to_parquet`.\n",
      " |  \n",
      " |  to_gbq(self, destination_table: 'str', project_id: 'str | None' = None, chunksize: 'int | None' = None, reauth: 'bool' = False, if_exists: 'str' = 'fail', auth_local_webserver: 'bool' = True, table_schema: 'list[dict[str, str]] | None' = None, location: 'str | None' = None, progress_bar: 'bool' = True, credentials=None) -> 'None'\n",
      " |      Write a DataFrame to a Google BigQuery table.\n",
      " |      \n",
      " |      This function requires the `pandas-gbq package\n",
      " |      <https://pandas-gbq.readthedocs.io>`__.\n",
      " |      \n",
      " |      See the `How to authenticate with Google BigQuery\n",
      " |      <https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html>`__\n",
      " |      guide for authentication instructions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      destination_table : str\n",
      " |          Name of table to be written, in the form ``dataset.tablename``.\n",
      " |      project_id : str, optional\n",
      " |          Google BigQuery Account project ID. Optional when available from\n",
      " |          the environment.\n",
      " |      chunksize : int, optional\n",
      " |          Number of rows to be inserted in each chunk from the dataframe.\n",
      " |          Set to ``None`` to load the whole dataframe at once.\n",
      " |      reauth : bool, default False\n",
      " |          Force Google BigQuery to re-authenticate the user. This is useful\n",
      " |          if multiple accounts are used.\n",
      " |      if_exists : str, default 'fail'\n",
      " |          Behavior when the destination table exists. Value can be one of:\n",
      " |      \n",
      " |          ``'fail'``\n",
      " |              If table exists raise pandas_gbq.gbq.TableCreationError.\n",
      " |          ``'replace'``\n",
      " |              If table exists, drop it, recreate it, and insert data.\n",
      " |          ``'append'``\n",
      " |              If table exists, insert data. Create if does not exist.\n",
      " |      auth_local_webserver : bool, default True\n",
      " |          Use the `local webserver flow`_ instead of the `console flow`_\n",
      " |          when getting user credentials.\n",
      " |      \n",
      " |          .. _local webserver flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\n",
      " |          .. _console flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\n",
      " |      \n",
      " |          *New in version 0.2.0 of pandas-gbq*.\n",
      " |      \n",
      " |          .. versionchanged:: 1.5.0\n",
      " |             Default value is changed to ``True``. Google has deprecated the\n",
      " |             ``auth_local_webserver = False`` `\"out of band\" (copy-paste)\n",
      " |             flow\n",
      " |             <https://developers.googleblog.com/2022/02/making-oauth-flows-safer.html?m=1#disallowed-oob>`_.\n",
      " |      table_schema : list of dicts, optional\n",
      " |          List of BigQuery table fields to which according DataFrame\n",
      " |          columns conform to, e.g. ``[{'name': 'col1', 'type':\n",
      " |          'STRING'},...]``. If schema is not provided, it will be\n",
      " |          generated according to dtypes of DataFrame columns. See\n",
      " |          BigQuery API documentation on available names of a field.\n",
      " |      \n",
      " |          *New in version 0.3.1 of pandas-gbq*.\n",
      " |      location : str, optional\n",
      " |          Location where the load job should run. See the `BigQuery locations\n",
      " |          documentation\n",
      " |          <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\n",
      " |          list of available locations. The location must match that of the\n",
      " |          target dataset.\n",
      " |      \n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      progress_bar : bool, default True\n",
      " |          Use the library `tqdm` to show the progress bar for the upload,\n",
      " |          chunk by chunk.\n",
      " |      \n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      credentials : google.auth.credentials.Credentials, optional\n",
      " |          Credentials for accessing Google APIs. Use this parameter to\n",
      " |          override default credentials, such as to use Compute Engine\n",
      " |          :class:`google.auth.compute_engine.Credentials` or Service\n",
      " |          Account :class:`google.oauth2.service_account.Credentials`\n",
      " |          directly.\n",
      " |      \n",
      " |          *New in version 0.8.0 of pandas-gbq*.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas_gbq.to_gbq : This function in the pandas-gbq library.\n",
      " |      read_gbq : Read a DataFrame from Google BigQuery.\n",
      " |  \n",
      " |  to_html(self, buf: 'FilePath | WriteBuffer[str] | None' = None, columns: 'Sequence[Level] | None' = None, col_space: 'ColspaceArgType | None' = None, header: 'bool | Sequence[str]' = True, index: 'bool' = True, na_rep: 'str' = 'NaN', formatters: 'FormattersType | None' = None, float_format: 'FloatFormatType | None' = None, sparsify: 'bool | None' = None, index_names: 'bool' = True, justify: 'str | None' = None, max_rows: 'int | None' = None, max_cols: 'int | None' = None, show_dimensions: 'bool | str' = False, decimal: 'str' = '.', bold_rows: 'bool' = True, classes: 'str | list | tuple | None' = None, escape: 'bool' = True, notebook: 'bool' = False, border: 'int | bool | None' = None, table_id: 'str | None' = None, render_links: 'bool' = False, encoding: 'str | None' = None) -> 'str | None'\n",
      " |      Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : sequence, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : str or int, list or dict of int or str, optional\n",
      " |          The minimum width of each column in CSS length units.  An int is assumed to be px units.\n",
      " |      \n",
      " |          .. versionadded:: 0.25.0\n",
      " |              Ability to use str.\n",
      " |      header : bool, optional\n",
      " |          Whether to print column labels, default True.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of ``NaN`` to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. This function must return a unicode string and will be\n",
      " |          applied only to the non-``NaN`` elements, with ``NaN`` being\n",
      " |          handled by ``na_rep``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |      bold_rows : bool, default True\n",
      " |          Make the row labels bold in the output.\n",
      " |      classes : str or list or tuple, default None\n",
      " |          CSS class(es) to apply to the resulting html table.\n",
      " |      escape : bool, default True\n",
      " |          Convert the characters <, >, and & to HTML-safe sequences.\n",
      " |      notebook : {True, False}, default False\n",
      " |          Whether the generated HTML is for IPython Notebook.\n",
      " |      border : int\n",
      " |          A ``border=border`` attribute is included in the opening\n",
      " |          `<table>` tag. Default ``pd.options.display.html.border``.\n",
      " |      table_id : str, optional\n",
      " |          A css id is included in the opening `<table>` tag if specified.\n",
      " |      render_links : bool, default False\n",
      " |          Convert URLs to HTML links.\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_string : Convert DataFrame to a string.\n",
      " |  \n",
      " |  to_markdown(self, buf: 'FilePath | WriteBuffer[str] | None' = None, mode: 'str' = 'wt', index: 'bool' = True, storage_options: 'StorageOptions' = None, **kwargs) -> 'str | None'\n",
      " |      Print DataFrame in Markdown-friendly format.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      mode : str, optional\n",
      " |          Mode in which file is opened, \"wt\" by default.\n",
      " |      index : bool, optional, default True\n",
      " |          Add index (row) labels.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          These parameters will be passed to `tabulate                 <https://pypi.org/project/tabulate>`_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          DataFrame in Markdown-friendly format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requires the `tabulate <https://pypi.org/project/tabulate>`_ package.\n",
      " |      \n",
      " |      Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame(\n",
      " |              ...     data={\"animal_1\": [\"elk\", \"pig\"], \"animal_2\": [\"dog\", \"quetzal\"]}\n",
      " |              ... )\n",
      " |              >>> print(df.to_markdown())\n",
      " |              |    | animal_1   | animal_2   |\n",
      " |              |---:|:-----------|:-----------|\n",
      " |              |  0 | elk        | dog        |\n",
      " |              |  1 | pig        | quetzal    |\n",
      " |      \n",
      " |              Output markdown with a tabulate option.\n",
      " |      \n",
      " |              >>> print(df.to_markdown(tablefmt=\"grid\"))\n",
      " |              +----+------------+------------+\n",
      " |              |    | animal_1   | animal_2   |\n",
      " |              +====+============+============+\n",
      " |              |  0 | elk        | dog        |\n",
      " |              +----+------------+------------+\n",
      " |              |  1 | pig        | quetzal    |\n",
      " |              +----+------------+------------+\n",
      " |  \n",
      " |  to_numpy(self, dtype: 'npt.DTypeLike | None' = None, copy: 'bool' = False, na_value: 'object' = <no_default>) -> 'np.ndarray'\n",
      " |      Convert the DataFrame to a NumPy array.\n",
      " |      \n",
      " |      By default, the dtype of the returned array will be the common NumPy\n",
      " |      dtype of all types in the DataFrame. For example, if the dtypes are\n",
      " |      ``float16`` and ``float32``, the results dtype will be ``float32``.\n",
      " |      This may require copying data and coercing values, which may be\n",
      " |      expensive.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to pass to :meth:`numpy.asarray`.\n",
      " |      copy : bool, default False\n",
      " |          Whether to ensure that the returned value is not a view on\n",
      " |          another array. Note that ``copy=False`` does not *ensure* that\n",
      " |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n",
      " |          a copy is made, even if not strictly necessary.\n",
      " |      na_value : Any, optional\n",
      " |          The value to use for missing values. The default value depends\n",
      " |          on `dtype` and the dtypes of the DataFrame columns.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.to_numpy : Similar method for Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\n",
      " |      array([[1, 3],\n",
      " |             [2, 4]])\n",
      " |      \n",
      " |      With heterogeneous data, the lowest common type will have to\n",
      " |      be used.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1. , 3. ],\n",
      " |             [2. , 4.5]])\n",
      " |      \n",
      " |      For a mix of numeric and non-numeric types, the output array will\n",
      " |      have object dtype.\n",
      " |      \n",
      " |      >>> df['C'] = pd.date_range('2000', periods=2)\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\n",
      " |             [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\n",
      " |  \n",
      " |  to_orc(self, path: 'FilePath | WriteBuffer[bytes] | None' = None, *, engine: \"Literal['pyarrow']\" = 'pyarrow', index: 'bool | None' = None, engine_kwargs: 'dict[str, Any] | None' = None) -> 'bytes | None'\n",
      " |      Write a DataFrame to the ORC format.\n",
      " |      \n",
      " |      .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, file-like object or None, default None\n",
      " |          If a string, it will be used as Root Directory path\n",
      " |          when writing a partitioned dataset. By file-like object,\n",
      " |          we refer to objects with a write() method, such as a file handle\n",
      " |          (e.g. via builtin open function). If path is None,\n",
      " |          a bytes object is returned.\n",
      " |      engine : str, default 'pyarrow'\n",
      " |          ORC library to use. Pyarrow must be >= 7.0.0.\n",
      " |      index : bool, optional\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``infer`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      engine_kwargs : dict[str, Any] or None, default None\n",
      " |          Additional keyword arguments passed to :func:`pyarrow.orc.write_table`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes if no path argument is provided else None\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          Dtype of one or more columns is category, unsigned integers, interval,\n",
      " |          period or sparse.\n",
      " |      ValueError\n",
      " |          engine is not pyarrow.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_orc : Read a ORC file.\n",
      " |      DataFrame.to_parquet : Write a parquet file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Before using this function you should read the :ref:`user guide about\n",
      " |        ORC <io.orc>` and :ref:`install optional dependencies <install.warn_orc>`.\n",
      " |      * This function requires `pyarrow <https://arrow.apache.org/docs/python/>`_\n",
      " |        library.\n",
      " |      * For supported dtypes please refer to `supported ORC features in Arrow\n",
      " |        <https://arrow.apache.org/docs/cpp/orc.html#data-types>`__.\n",
      " |      * Currently timezones in datetime columns are not preserved when a\n",
      " |        dataframe is converted into ORC files.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})\n",
      " |      >>> df.to_orc('df.orc')  # doctest: +SKIP\n",
      " |      >>> pd.read_orc('df.orc')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     4\n",
      " |      1     2     3\n",
      " |      \n",
      " |      If you want to get a buffer to the orc content you can write it to io.BytesIO\n",
      " |      >>> import io\n",
      " |      >>> b = io.BytesIO(df.to_orc())  # doctest: +SKIP\n",
      " |      >>> b.seek(0)  # doctest: +SKIP\n",
      " |      0\n",
      " |      >>> content = b.read()  # doctest: +SKIP\n",
      " |  \n",
      " |  to_parquet(self, path: 'FilePath | WriteBuffer[bytes] | None' = None, engine: 'str' = 'auto', compression: 'str | None' = 'snappy', index: 'bool | None' = None, partition_cols: 'list[str] | None' = None, storage_options: 'StorageOptions' = None, **kwargs) -> 'bytes | None'\n",
      " |      Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      This function writes the dataframe as a `parquet file\n",
      " |      <https://parquet.apache.org/>`_. You can choose different parquet\n",
      " |      backends, and have the option of compression. See\n",
      " |      :ref:`the user guide <io.parquet>` for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. If None, the result is\n",
      " |          returned as bytes. If a string or path, it will be used as Root Directory\n",
      " |          path when writing a partitioned dataset.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |          Previously this was \"fname\"\n",
      " |      \n",
      " |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      " |          Parquet library to use. If 'auto', then the option\n",
      " |          ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
      " |          behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
      " |          'pyarrow' is unavailable.\n",
      " |      compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'\n",
      " |          Name of the compression to use. Use ``None`` for no compression.\n",
      " |      index : bool, default None\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``True`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      partition_cols : list, optional, default None\n",
      " |          Column names by which to partition the dataset.\n",
      " |          Columns are partitioned in the order they are given.\n",
      " |          Must be None if path is not a string.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional arguments passed to the parquet library. See\n",
      " |          :ref:`pandas io <io.parquet>` for more details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes if no path argument is provided else None\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_parquet : Read a parquet file.\n",
      " |      DataFrame.to_orc : Write an orc file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function requires either the `fastparquet\n",
      " |      <https://pypi.org/project/fastparquet>`_ or `pyarrow\n",
      " |      <https://arrow.apache.org/docs/python/>`_ library.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.to_parquet('df.parquet.gzip',\n",
      " |      ...               compression='gzip')  # doctest: +SKIP\n",
      " |      >>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      If you want to get a buffer to the parquet content you can use a io.BytesIO\n",
      " |      object, as long as you don't use partition_cols, which creates multiple files.\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> f = io.BytesIO()\n",
      " |      >>> df.to_parquet(f)\n",
      " |      >>> f.seek(0)\n",
      " |      0\n",
      " |      >>> content = f.read()\n",
      " |  \n",
      " |  to_period(self, freq: 'Frequency | None' = None, axis: 'Axis' = 0, copy: 'bool' = True) -> 'DataFrame'\n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex.\n",
      " |      \n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default\n",
      " |          Frequency of the PeriodIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with PeriodIndex\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.to_datetime(\n",
      " |      ...     [\n",
      " |      ...         \"2001-03-31 00:00:00\",\n",
      " |      ...         \"2002-05-31 00:00:00\",\n",
      " |      ...         \"2003-08-31 00:00:00\",\n",
      " |      ...     ]\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2001-03-31', '2002-05-31', '2003-08-31'],\n",
      " |      dtype='datetime64[ns]', freq=None)\n",
      " |      \n",
      " |      >>> idx.to_period(\"M\")\n",
      " |      PeriodIndex(['2001-03', '2002-05', '2003-08'], dtype='period[M]')\n",
      " |      \n",
      " |      For the yearly frequency\n",
      " |      \n",
      " |      >>> idx.to_period(\"Y\")\n",
      " |      PeriodIndex(['2001', '2002', '2003'], dtype='period[A-DEC]')\n",
      " |  \n",
      " |  to_records(self, index: 'bool' = True, column_dtypes=None, index_dtypes=None) -> 'np.recarray'\n",
      " |      Convert DataFrame to a NumPy record array.\n",
      " |      \n",
      " |      Index will be included as the first field of the record array if\n",
      " |      requested.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Include index in resulting record array, stored in 'index'\n",
      " |          field or using the index label, if set.\n",
      " |      column_dtypes : str, type, dict, default None\n",
      " |          If a string or type, the data type to store all columns. If\n",
      " |          a dictionary, a mapping of column names and indices (zero-indexed)\n",
      " |          to specific data types.\n",
      " |      index_dtypes : str, type, dict, default None\n",
      " |          If a string or type, the data type to store all index levels. If\n",
      " |          a dictionary, a mapping of index level names and indices\n",
      " |          (zero-indexed) to specific data types.\n",
      " |      \n",
      " |          This mapping is applied only if `index=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.recarray\n",
      " |          NumPy ndarray with the DataFrame labels as fields and each row\n",
      " |          of the DataFrame as entries.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records: Convert structured or record ndarray\n",
      " |          to DataFrame.\n",
      " |      numpy.recarray: An ndarray that allows field access using\n",
      " |          attributes, analogous to typed columns in a\n",
      " |          spreadsheet.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n",
      " |      ...                   index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         A     B\n",
      " |      a  1  0.50\n",
      " |      b  2  0.75\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      If the DataFrame index has no label then the recarray field name\n",
      " |      is set to 'index'. If the index has a label then this is used as the\n",
      " |      field name:\n",
      " |      \n",
      " |      >>> df.index = df.index.rename(\"I\")\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      The index can be excluded from the record array:\n",
      " |      \n",
      " |      >>> df.to_records(index=False)\n",
      " |      rec.array([(1, 0.5 ), (2, 0.75)],\n",
      " |                dtype=[('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      Data types can be specified for the columns:\n",
      " |      \n",
      " |      >>> df.to_records(column_dtypes={\"A\": \"int32\"})\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i4'), ('B', '<f8')])\n",
      " |      \n",
      " |      As well as for the index:\n",
      " |      \n",
      " |      >>> df.to_records(index_dtypes=\"<S2\")\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S2'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      >>> index_dtypes = f\"<S{df.index.str.len().max()}\"\n",
      " |      >>> df.to_records(index_dtypes=index_dtypes)\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S1'), ('A', '<i8'), ('B', '<f8')])\n",
      " |  \n",
      " |  to_stata(self, path: 'FilePath | WriteBuffer[bytes]', *, convert_dates: 'dict[Hashable, str] | None' = None, write_index: 'bool' = True, byteorder: 'str | None' = None, time_stamp: 'datetime.datetime | None' = None, data_label: 'str | None' = None, variable_labels: 'dict[Hashable, str] | None' = None, version: 'int | None' = 114, convert_strl: 'Sequence[Hashable] | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions' = None, value_labels: 'dict[Hashable, dict[float, str]] | None' = None) -> 'None'\n",
      " |      Export DataFrame object to Stata dta format.\n",
      " |      \n",
      " |      Writes the DataFrame to a Stata dataset file.\n",
      " |      \"dta\" files contain a Stata dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, or buffer\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |          Previously this was \"fname\"\n",
      " |      \n",
      " |      convert_dates : dict\n",
      " |          Dictionary mapping columns containing datetime types to stata\n",
      " |          internal format to use when writing the dates. Options are 'tc',\n",
      " |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      " |          or a name. Datetime columns that do not have a conversion type\n",
      " |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      " |          a datetime column has timezone information.\n",
      " |      write_index : bool\n",
      " |          Write the index to Stata dataset.\n",
      " |      byteorder : str\n",
      " |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n",
      " |      time_stamp : datetime\n",
      " |          A datetime to use as file creation date.  Default is the current\n",
      " |          time.\n",
      " |      data_label : str, optional\n",
      " |          A label for the data set.  Must be 80 characters or smaller.\n",
      " |      variable_labels : dict\n",
      " |          Dictionary containing columns as keys and variable labels as\n",
      " |          values. Each label must be 80 characters or smaller.\n",
      " |      version : {114, 117, 118, 119, None}, default 114\n",
      " |          Version to use in the output dta file. Set to None to let pandas\n",
      " |          decide between 118 or 119 formats depending on the number of\n",
      " |          columns in the frame. Version 114 can be read by Stata 10 and\n",
      " |          later. Version 117 can be read by Stata 13 or later. Version 118\n",
      " |          is supported in Stata 14 and later. Version 119 is supported in\n",
      " |          Stata 15 and later. Version 114 limits string variables to 244\n",
      " |          characters or fewer while versions 117 and later allow strings\n",
      " |          with lengths up to 2,000,000 characters. Versions 118 and 119\n",
      " |          support Unicode characters, and version 119 supports more than\n",
      " |          32,767 variables.\n",
      " |      \n",
      " |          Version 119 should usually only be used when the number of\n",
      " |          variables exceeds the capacity of dta format 118. Exporting\n",
      " |          smaller datasets in format 119 may have unintended consequences,\n",
      " |          and, as of November 2020, Stata SE cannot read version 119 files.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |              Added support for formats 118 and 119.\n",
      " |      \n",
      " |      convert_strl : list, optional\n",
      " |          List of column names to convert to string columns to Stata StrL\n",
      " |          format. Only available if version is 117.  Storing strings in the\n",
      " |          StrL format can produce smaller dta files if strings have more than\n",
      " |          8 characters and values are repeated.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      " |          key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |              .. versionadded:: 1.5.0\n",
      " |                  Added support for `.tar` files.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      value_labels : dict of dicts\n",
      " |          Dictionary containing columns as keys and dictionaries of column value\n",
      " |          to labels as values. Labels for a single variable must be 32,000\n",
      " |          characters or smaller.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          * If datetimes contain timezone information\n",
      " |          * Column dtype is not representable in Stata\n",
      " |      ValueError\n",
      " |          * Columns listed in convert_dates are neither datetime64[ns]\n",
      " |            or datetime.datetime\n",
      " |          * Column listed in convert_dates is not in DataFrame\n",
      " |          * Categorical label contains more than 32,000 characters\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_stata : Import Stata data files.\n",
      " |      io.stata.StataWriter : Low-level writer for Stata data files.\n",
      " |      io.stata.StataWriter117 : Low-level writer for version 117 files.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',\n",
      " |      ...                               'parrot'],\n",
      " |      ...                    'speed': [350, 18, 361, 15]})\n",
      " |      >>> df.to_stata('animals.dta')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_string(self, buf: 'FilePath | WriteBuffer[str] | None' = None, columns: 'Sequence[str] | None' = None, col_space: 'int | list[int] | dict[Hashable, int] | None' = None, header: 'bool | Sequence[str]' = True, index: 'bool' = True, na_rep: 'str' = 'NaN', formatters: 'fmt.FormattersType | None' = None, float_format: 'fmt.FloatFormatType | None' = None, sparsify: 'bool | None' = None, index_names: 'bool' = True, justify: 'str | None' = None, max_rows: 'int | None' = None, max_cols: 'int | None' = None, show_dimensions: 'bool' = False, decimal: 'str' = '.', line_width: 'int | None' = None, min_rows: 'int | None' = None, max_colwidth: 'int | None' = None, encoding: 'str | None' = None) -> 'str | None'\n",
      " |      Render a DataFrame to a console-friendly tabular output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : sequence, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, list or dict of int, optional\n",
      " |          The minimum width of each column. If a list of ints is given every integers corresponds with one column. If a dict is given, the key references the column, while the value defines the space to use..\n",
      " |      header : bool or sequence of str, optional\n",
      " |          Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of ``NaN`` to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. This function must return a unicode string and will be\n",
      " |          applied only to the non-``NaN`` elements, with ``NaN`` being\n",
      " |          handled by ``na_rep``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |      line_width : int, optional\n",
      " |          Width to wrap a line in characters.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in the console in a truncated repr\n",
      " |          (when number of rows is above `max_rows`).\n",
      " |      max_colwidth : int, optional\n",
      " |          Max width to truncate each column in characters. By default, no limit.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_html : Convert DataFrame to HTML.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> print(df.to_string())\n",
      " |         col1  col2\n",
      " |      0     1     4\n",
      " |      1     2     5\n",
      " |      2     3     6\n",
      " |  \n",
      " |  to_timestamp(self, freq: 'Frequency | None' = None, how: 'str' = 'start', axis: 'Axis' = 0, copy: 'bool' = True) -> 'DataFrame'\n",
      " |      Cast to DatetimeIndex of timestamps, at *beginning* of period.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default frequency of PeriodIndex\n",
      " |          Desired frequency.\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with DatetimeIndex\n",
      " |  \n",
      " |  to_xml(self, path_or_buffer: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, index: 'bool' = True, root_name: 'str | None' = 'data', row_name: 'str | None' = 'row', na_rep: 'str | None' = None, attr_cols: 'list[str] | None' = None, elem_cols: 'list[str] | None' = None, namespaces: 'dict[str | None, str] | None' = None, prefix: 'str | None' = None, encoding: 'str' = 'utf-8', xml_declaration: 'bool | None' = True, pretty_print: 'bool | None' = True, parser: 'str | None' = 'lxml', stylesheet: 'FilePath | ReadBuffer[str] | ReadBuffer[bytes] | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Render a DataFrame to an XML document.\n",
      " |      \n",
      " |      .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buffer : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a ``write()`` function. If None, the result is returned\n",
      " |          as a string.\n",
      " |      index : bool, default True\n",
      " |          Whether to include index in XML document.\n",
      " |      root_name : str, default 'data'\n",
      " |          The name of root element in XML document.\n",
      " |      row_name : str, default 'row'\n",
      " |          The name of row element in XML document.\n",
      " |      na_rep : str, optional\n",
      " |          Missing data representation.\n",
      " |      attr_cols : list-like, optional\n",
      " |          List of columns to write as attributes in row element.\n",
      " |          Hierarchical columns will be flattened with underscore\n",
      " |          delimiting the different levels.\n",
      " |      elem_cols : list-like, optional\n",
      " |          List of columns to write as children in row element. By default,\n",
      " |          all columns output as children of row element. Hierarchical\n",
      " |          columns will be flattened with underscore delimiting the\n",
      " |          different levels.\n",
      " |      namespaces : dict, optional\n",
      " |          All namespaces to be defined in root element. Keys of dict\n",
      " |          should be prefix names and values of dict corresponding URIs.\n",
      " |          Default namespaces should be given empty string key. For\n",
      " |          example, ::\n",
      " |      \n",
      " |              namespaces = {\"\": \"https://example.com\"}\n",
      " |      \n",
      " |      prefix : str, optional\n",
      " |          Namespace prefix to be used for every element and/or attribute\n",
      " |          in document. This should be one of the keys in ``namespaces``\n",
      " |          dict.\n",
      " |      encoding : str, default 'utf-8'\n",
      " |          Encoding of the resulting document.\n",
      " |      xml_declaration : bool, default True\n",
      " |          Whether to include the XML declaration at start of document.\n",
      " |      pretty_print : bool, default True\n",
      " |          Whether output should be pretty printed with indentation and\n",
      " |          line breaks.\n",
      " |      parser : {'lxml','etree'}, default 'lxml'\n",
      " |          Parser module to use for building of tree. Only 'lxml' and\n",
      " |          'etree' are supported. With 'lxml', the ability to use XSLT\n",
      " |          stylesheet is supported.\n",
      " |      stylesheet : str, path object or file-like object, optional\n",
      " |          A URL, file-like object, or a raw string containing an XSLT\n",
      " |          script used to transform the raw XML output. Script should use\n",
      " |          layout of elements and attributes from original output. This\n",
      " |          argument requires ``lxml`` to be installed. Only XSLT 1.0\n",
      " |          scripts and not later versions is currently supported.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buffer' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      " |          key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |              .. versionadded:: 1.5.0\n",
      " |                  Added support for `.tar` files.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If ``io`` is None, returns the resulting XML format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_json : Convert the pandas object to a JSON string.\n",
      " |      to_html : Convert DataFrame to a html.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'shape': ['square', 'circle', 'triangle'],\n",
      " |      ...                    'degrees': [360, 360, 180],\n",
      " |      ...                    'sides': [4, np.nan, 3]})\n",
      " |      \n",
      " |      >>> df.to_xml()  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row>\n",
      " |          <index>0</index>\n",
      " |          <shape>square</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides>4.0</sides>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>1</index>\n",
      " |          <shape>circle</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides/>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>2</index>\n",
      " |          <shape>triangle</shape>\n",
      " |          <degrees>180</degrees>\n",
      " |          <sides>3.0</sides>\n",
      " |        </row>\n",
      " |      </data>\n",
      " |      \n",
      " |      >>> df.to_xml(attr_cols=[\n",
      " |      ...           'index', 'shape', 'degrees', 'sides'\n",
      " |      ...           ])  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row index=\"0\" shape=\"square\" degrees=\"360\" sides=\"4.0\"/>\n",
      " |        <row index=\"1\" shape=\"circle\" degrees=\"360\"/>\n",
      " |        <row index=\"2\" shape=\"triangle\" degrees=\"180\" sides=\"3.0\"/>\n",
      " |      </data>\n",
      " |      \n",
      " |      >>> df.to_xml(namespaces={\"doc\": \"https://example.com\"},\n",
      " |      ...           prefix=\"doc\")  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <doc:data xmlns:doc=\"https://example.com\">\n",
      " |        <doc:row>\n",
      " |          <doc:index>0</doc:index>\n",
      " |          <doc:shape>square</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides>4.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>1</doc:index>\n",
      " |          <doc:shape>circle</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides/>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>2</doc:index>\n",
      " |          <doc:shape>triangle</doc:shape>\n",
      " |          <doc:degrees>180</doc:degrees>\n",
      " |          <doc:sides>3.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |      </doc:data>\n",
      " |  \n",
      " |  transform(self, func: 'AggFuncType', axis: 'Axis' = 0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Call ``func`` on self producing a DataFrame with the same axis shape as self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list-like or dict-like\n",
      " |          Function to use for transforming the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply. If func\n",
      " |          is both list-like and dict-like, dict-like behavior takes precedence.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list-like of functions and/or function names, e.g. ``[np.exp, 'sqrt']``\n",
      " |          - dict-like of axis labels -> functions, function names or list-like of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame that must have the same length as self.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError : If the returned DataFrame has a different length than self.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.agg : Only perform aggregating type operations.\n",
      " |      DataFrame.apply : Invoke function on a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  1  2\n",
      " |      2  2  3\n",
      " |      >>> df.transform(lambda x: x + 1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  2  3\n",
      " |      2  3  4\n",
      " |      \n",
      " |      Even though the resulting DataFrame must have the same length as the\n",
      " |      input DataFrame, it is possible to provide several input functions:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |      >>> s.transform([np.sqrt, np.exp])\n",
      " |             sqrt        exp\n",
      " |      0  0.000000   1.000000\n",
      " |      1  1.000000   2.718282\n",
      " |      2  1.414214   7.389056\n",
      " |      \n",
      " |      You can call transform on a GroupBy object:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"Date\": [\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\",\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
      " |      ...     \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |               Date  Data\n",
      " |      0  2015-05-08     5\n",
      " |      1  2015-05-07     8\n",
      " |      2  2015-05-06     6\n",
      " |      3  2015-05-05     1\n",
      " |      4  2015-05-08    50\n",
      " |      5  2015-05-07   100\n",
      " |      6  2015-05-06    60\n",
      " |      7  2015-05-05   120\n",
      " |      >>> df.groupby('Date')['Data'].transform('sum')\n",
      " |      0     55\n",
      " |      1    108\n",
      " |      2     66\n",
      " |      3    121\n",
      " |      4     55\n",
      " |      5    108\n",
      " |      6     66\n",
      " |      7    121\n",
      " |      Name: Data, dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
      " |      ...     \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |         c type\n",
      " |      0  1    m\n",
      " |      1  1    n\n",
      " |      2  1    o\n",
      " |      3  2    m\n",
      " |      4  2    m\n",
      " |      5  2    n\n",
      " |      6  2    n\n",
      " |      >>> df['size'] = df.groupby('c')['type'].transform(len)\n",
      " |      >>> df\n",
      " |         c type size\n",
      " |      0  1    m    3\n",
      " |      1  1    n    3\n",
      " |      2  1    o    3\n",
      " |      3  2    m    4\n",
      " |      4  2    m    4\n",
      " |      5  2    n    4\n",
      " |      6  2    n    4\n",
      " |  \n",
      " |  transpose(self, *args, copy: 'bool' = False) -> 'DataFrame'\n",
      " |      Transpose index and columns.\n",
      " |      \n",
      " |      Reflect the DataFrame over its main diagonal by writing rows as columns\n",
      " |      and vice-versa. The property :attr:`.T` is an accessor to the method\n",
      " |      :meth:`transpose`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *args : tuple, optional\n",
      " |          Accepted for compatibility with NumPy.\n",
      " |      copy : bool, default False\n",
      " |          Whether to copy the data after transposing, even for DataFrames\n",
      " |          with a single dtype.\n",
      " |      \n",
      " |          Note that a copy is always required for mixed dtype DataFrames,\n",
      " |          or for DataFrames with any extension types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose : Permute the dimensions of a given array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Transposing a DataFrame with mixed dtypes will result in a homogeneous\n",
      " |      DataFrame with the `object` dtype. In such a case, a copy of the data\n",
      " |      is always made.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Square DataFrame with homogeneous dtype**\n",
      " |      \n",
      " |      >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d1)\n",
      " |      >>> df1\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      >>> df1_transposed = df1.T # or df1.transpose()\n",
      " |      >>> df1_transposed\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |      \n",
      " |      When the dtype is homogeneous in the original DataFrame, we get a\n",
      " |      transposed DataFrame with the same dtype:\n",
      " |      \n",
      " |      >>> df1.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      >>> df1_transposed.dtypes\n",
      " |      0    int64\n",
      " |      1    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **Non-square DataFrame with mixed dtypes**\n",
      " |      \n",
      " |      >>> d2 = {'name': ['Alice', 'Bob'],\n",
      " |      ...       'score': [9.5, 8],\n",
      " |      ...       'employed': [False, True],\n",
      " |      ...       'kids': [0, 0]}\n",
      " |      >>> df2 = pd.DataFrame(data=d2)\n",
      " |      >>> df2\n",
      " |          name  score  employed  kids\n",
      " |      0  Alice    9.5     False     0\n",
      " |      1    Bob    8.0      True     0\n",
      " |      \n",
      " |      >>> df2_transposed = df2.T # or df2.transpose()\n",
      " |      >>> df2_transposed\n",
      " |                    0     1\n",
      " |      name      Alice   Bob\n",
      " |      score       9.5   8.0\n",
      " |      employed  False  True\n",
      " |      kids          0     0\n",
      " |      \n",
      " |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n",
      " |      the `object` dtype:\n",
      " |      \n",
      " |      >>> df2.dtypes\n",
      " |      name         object\n",
      " |      score       float64\n",
      " |      employed       bool\n",
      " |      kids          int64\n",
      " |      dtype: object\n",
      " |      >>> df2_transposed.dtypes\n",
      " |      0    object\n",
      " |      1    object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rtruediv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles      degrees\n",
      " |      circle           0          720\n",
      " |      triangle             0      360\n",
      " |      rectangle            0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles      degrees\n",
      " |      circle               0        0\n",
      " |      triangle             6      360\n",
      " |      rectangle           12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  unstack(self, level: 'Level' = -1, fill_value=None)\n",
      " |      Pivot a level of the (necessarily hierarchical) index labels.\n",
      " |      \n",
      " |      Returns a DataFrame having a new level of column labels whose inner-most level\n",
      " |      consists of the pivoted index labels.\n",
      " |      \n",
      " |      If the index is not a MultiIndex, the output will be a Series\n",
      " |      (the analogue of stack when the columns are not a MultiIndex).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list of these, default -1 (last level)\n",
      " |          Level(s) of index to unstack, can pass level name.\n",
      " |      fill_value : int, str or dict\n",
      " |          Replace NaN with this value if the unstack produces missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot a table based on column values.\n",
      " |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      " |          from `unstack`).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.stacking>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      " |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      " |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      " |      >>> s\n",
      " |      one  a   1.0\n",
      " |           b   2.0\n",
      " |      two  a   3.0\n",
      " |           b   4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a   b\n",
      " |      one  1.0  2.0\n",
      " |      two  3.0  4.0\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a  1.0   3.0\n",
      " |      b  2.0   4.0\n",
      " |      \n",
      " |      >>> df = s.unstack(level=0)\n",
      " |      >>> df.unstack()\n",
      " |      one  a  1.0\n",
      " |           b  2.0\n",
      " |      two  a  3.0\n",
      " |           b  4.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  update(self, other, join: 'str' = 'left', overwrite: 'bool' = True, filter_func=None, errors: 'str' = 'ignore') -> 'None'\n",
      " |      Modify in place using non-NA values from another DataFrame.\n",
      " |      \n",
      " |      Aligns on indices. There is no return value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, or object coercible into a DataFrame\n",
      " |          Should have at least one matching index/column label\n",
      " |          with the original DataFrame. If a Series is passed,\n",
      " |          its name attribute must be set, and that will be\n",
      " |          used as the column name to align with the original DataFrame.\n",
      " |      join : {'left'}, default 'left'\n",
      " |          Only left join is implemented, keeping the index and columns of the\n",
      " |          original object.\n",
      " |      overwrite : bool, default True\n",
      " |          How to handle non-NA values for overlapping keys:\n",
      " |      \n",
      " |          * True: overwrite original DataFrame's values\n",
      " |            with values from `other`.\n",
      " |          * False: only update values that are NA in\n",
      " |            the original DataFrame.\n",
      " |      \n",
      " |      filter_func : callable(1d-array) -> bool 1d-array, optional\n",
      " |          Can choose to replace values other than NA. Return True for values\n",
      " |          that should be updated.\n",
      " |      errors : {'raise', 'ignore'}, default 'ignore'\n",
      " |          If 'raise', will raise a ValueError if the DataFrame and `other`\n",
      " |          both contain non-NA data in the same place.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None : method directly changes calling object\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * When `errors='raise'` and there's overlapping non-NA data.\n",
      " |          * When `errors` is not either `'ignore'` or `'raise'`\n",
      " |      NotImplementedError\n",
      " |          * If `join != 'left'`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dict.update : Similar method for dictionaries.\n",
      " |      DataFrame.merge : For column(s)-on-column(s) operations.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n",
      " |      ...                        'C': [7, 8, 9]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      The DataFrame's length does not increase as a result of the update,\n",
      " |      only values at matching index/column labels are updated.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  e\n",
      " |      2  c  f\n",
      " |      \n",
      " |      For Series, its name attribute must be set.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n",
      " |      >>> df.update(new_column)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  y\n",
      " |      2  c  e\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  x\n",
      " |      1  b  d\n",
      " |      2  c  e\n",
      " |      \n",
      " |      If `other` contains NaNs the corresponding values are not updated\n",
      " |      in the original dataframe.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A      B\n",
      " |      0  1    4.0\n",
      " |      1  2  500.0\n",
      " |      2  3    6.0\n",
      " |  \n",
      " |  value_counts(self, subset: 'Sequence[Hashable] | None' = None, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, dropna: 'bool' = True) -> 'Series'\n",
      " |      Return a Series containing counts of unique rows in the DataFrame.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : list-like, optional\n",
      " |          Columns to use when counting unique combinations.\n",
      " |      normalize : bool, default False\n",
      " |          Return proportions rather than frequencies.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      dropna : bool, default True\n",
      " |          Don’t include counts of rows that contain NA values.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.value_counts: Equivalent method on Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The returned Series will have a MultiIndex with one level per input\n",
      " |      column. By default, rows that contain any NA values are omitted from\n",
      " |      the result. By default, the resulting Series will be in descending\n",
      " |      order so that the first element is the most frequently-occurring row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0]},\n",
      " |      ...                   index=['falcon', 'dog', 'cat', 'ant'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      cat            4          0\n",
      " |      ant            6          0\n",
      " |      \n",
      " |      >>> df.value_counts()\n",
      " |      num_legs  num_wings\n",
      " |      4         0            2\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(sort=False)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      4         0            2\n",
      " |      6         0            1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(ascending=True)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      4         0            2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(normalize=True)\n",
      " |      num_legs  num_wings\n",
      " |      4         0            0.50\n",
      " |      2         2            0.25\n",
      " |      6         0            0.25\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      With `dropna` set to `False` we can also count rows with NA values.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'],\n",
      " |      ...                    'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']})\n",
      " |      >>> df\n",
      " |        first_name middle_name\n",
      " |      0       John       Smith\n",
      " |      1       Anne        <NA>\n",
      " |      2       John        <NA>\n",
      " |      3       Beth      Louise\n",
      " |      \n",
      " |      >>> df.value_counts()\n",
      " |      first_name  middle_name\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(dropna=False)\n",
      " |      first_name  middle_name\n",
      " |      Anne        NaN            1\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |                  NaN            1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  var(self, axis=None, skipna=True, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              The level keyword is deprecated. Use groupby instead.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              Specifying ``numeric_only=None`` is deprecated. The default value will be\n",
      " |              ``False`` in a future version of pandas.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified) \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      " |      ...                   'age': [21, 25, 62, 43],\n",
      " |      ...                   'height': [1.61, 1.87, 1.49, 2.01]}\n",
      " |      ...                  ).set_index('person_id')\n",
      " |      >>> df\n",
      " |                 age  height\n",
      " |      person_id\n",
      " |      0           21    1.61\n",
      " |      1           25    1.87\n",
      " |      2           62    1.49\n",
      " |      3           43    2.01\n",
      " |      \n",
      " |      >>> df.var()\n",
      " |      age       352.916667\n",
      " |      height      0.056367\n",
      " |      \n",
      " |      Alternatively, ``ddof=0`` can be set to normalize by N instead of N-1:\n",
      " |      \n",
      " |      >>> df.var(ddof=0)\n",
      " |      age       264.687500\n",
      " |      height      0.042275\n",
      " |  \n",
      " |  where(self, cond, other=<no_default>, *, inplace: 'bool' = False, axis: 'Axis | None' = None, level: 'Level' = None, errors: 'IgnoreRaise | lib.NoDefault' = 'raise', try_cast: 'bool | lib.NoDefault' = <no_default>) -> 'DataFrame | None'\n",
      " |      Replace values where the condition is False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed. For `Series` this parameter is\n",
      " |          unused and defaults to 0.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |             This argument had no effect.\n",
      " |      \n",
      " |      try_cast : bool, default None\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              Manually cast back if necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used. If the axis of ``other`` does not align with axis of\n",
      " |      ``cond`` Series/DataFrame, the misaligned index positions will be filled with\n",
      " |      False.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      The dtype of the object takes precedence. The fill value is casted to\n",
      " |      the object's dtype, if this can be done losslessly.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> t = pd.Series([True, False])\n",
      " |      >>> s.where(t, 99)\n",
      " |      0     0\n",
      " |      1    99\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(t, 99)\n",
      " |      0    99\n",
      " |      1     1\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pandas.core.frame.DataFrame:\n",
      " |  \n",
      " |  from_dict(data: 'dict', orient: 'str' = 'columns', dtype: 'Dtype | None' = None, columns: 'Axes | None' = None) -> 'DataFrame' from builtins.type\n",
      " |      Construct DataFrame from dict of array-like or dicts.\n",
      " |      \n",
      " |      Creates DataFrame object from dictionary by columns or by index\n",
      " |      allowing dtype specification.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : dict\n",
      " |          Of the form {field : array-like} or {field : dict}.\n",
      " |      orient : {'columns', 'index', 'tight'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the passed dict\n",
      " |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      " |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      " |          If 'tight', assume a dict with keys ['index', 'columns', 'data',\n",
      " |          'index_names', 'column_names'].\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |             'tight' as an allowed value for the ``orient`` argument\n",
      " |      \n",
      " |      dtype : dtype, default None\n",
      " |          Data type to force, otherwise infer.\n",
      " |      columns : list, default None\n",
      " |          Column labels to use when ``orient='index'``. Raises a ValueError\n",
      " |          if used with ``orient='columns'`` or ``orient='tight'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records : DataFrame from structured ndarray, sequence\n",
      " |          of tuples or dicts, or DataFrame.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      DataFrame.to_dict : Convert the DataFrame to a dictionary.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default the keys of the dict become the DataFrame columns:\n",
      " |      \n",
      " |      >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Specify ``orient='index'`` to create the DataFrame using dictionary\n",
      " |      keys as rows:\n",
      " |      \n",
      " |      >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index')\n",
      " |             0  1  2  3\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |      \n",
      " |      When using the 'index' orientation, the column names can be\n",
      " |      specified manually:\n",
      " |      \n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index',\n",
      " |      ...                        columns=['A', 'B', 'C', 'D'])\n",
      " |             A  B  C  D\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |      \n",
      " |      Specify ``orient='tight'`` to create the DataFrame using a 'tight'\n",
      " |      format:\n",
      " |      \n",
      " |      >>> data = {'index': [('a', 'b'), ('a', 'c')],\n",
      " |      ...         'columns': [('x', 1), ('y', 2)],\n",
      " |      ...         'data': [[1, 3], [2, 4]],\n",
      " |      ...         'index_names': ['n1', 'n2'],\n",
      " |      ...         'column_names': ['z1', 'z2']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='tight')\n",
      " |      z1     x  y\n",
      " |      z2     1  2\n",
      " |      n1 n2\n",
      " |      a  b   1  3\n",
      " |         c   2  4\n",
      " |  \n",
      " |  from_records(data, index=None, exclude=None, columns=None, coerce_float: 'bool' = False, nrows: 'int | None' = None) -> 'DataFrame' from builtins.type\n",
      " |      Convert structured or record ndarray to DataFrame.\n",
      " |      \n",
      " |      Creates a DataFrame object from a structured ndarray, sequence of\n",
      " |      tuples or dicts, or DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : structured ndarray, sequence of tuples or dicts, or DataFrame\n",
      " |          Structured input data.\n",
      " |      index : str, list of fields, array-like\n",
      " |          Field of array to use as the index, alternately a specific set of\n",
      " |          input labels to use.\n",
      " |      exclude : sequence, default None\n",
      " |          Columns or fields to exclude.\n",
      " |      columns : sequence, default None\n",
      " |          Column names to use. If the passed data do not have names\n",
      " |          associated with them, this argument provides names for the\n",
      " |          columns. Otherwise this argument indicates the order of the columns\n",
      " |          in the result (any names not found in the data will become all-NA\n",
      " |          columns).\n",
      " |      coerce_float : bool, default False\n",
      " |          Attempt to convert values of non-string, non-numeric objects (like\n",
      " |          decimal.Decimal) to floating point, useful for SQL result sets.\n",
      " |      nrows : int, default None\n",
      " |          Number of rows to read if data is an iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict : DataFrame from dict of array-like or dicts.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Data can be provided as a structured ndarray:\n",
      " |      \n",
      " |      >>> data = np.array([(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')],\n",
      " |      ...                 dtype=[('col_1', 'i4'), ('col_2', 'U1')])\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Data can be provided as a list of dicts:\n",
      " |      \n",
      " |      >>> data = [{'col_1': 3, 'col_2': 'a'},\n",
      " |      ...         {'col_1': 2, 'col_2': 'b'},\n",
      " |      ...         {'col_1': 1, 'col_2': 'c'},\n",
      " |      ...         {'col_1': 0, 'col_2': 'd'}]\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Data can be provided as a list of tuples with corresponding columns:\n",
      " |      \n",
      " |      >>> data = [(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')]\n",
      " |      >>> pd.DataFrame.from_records(data, columns=['col_1', 'col_2'])\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.frame.DataFrame:\n",
      " |  \n",
      " |  T\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list representing the axes of the DataFrame.\n",
      " |      \n",
      " |      It has the row axis labels and column axis labels as the only members.\n",
      " |      They are returned in that order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.axes\n",
      " |      [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\n",
      " |      dtype='object')]\n",
      " |  \n",
      " |  shape\n",
      " |      Return a tuple representing the dimensionality of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.shape : Tuple of array dimensions.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.shape\n",
      " |      (2, 2)\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n",
      " |      ...                    'col3': [5, 6]})\n",
      " |      >>> df.shape\n",
      " |      (2, 3)\n",
      " |  \n",
      " |  style\n",
      " |      Returns a Styler object.\n",
      " |      \n",
      " |      Contains methods for building a styled HTML representation of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      io.formats.style.Styler : Helps style a DataFrame or Series according to the\n",
      " |          data with HTML and CSS.\n",
      " |  \n",
      " |  values\n",
      " |      Return a Numpy representation of the DataFrame.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         We recommend using :meth:`DataFrame.to_numpy` instead.\n",
      " |      \n",
      " |      Only the values in the DataFrame will be returned, the axes labels\n",
      " |      will be removed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_numpy : Recommended alternative to this method.\n",
      " |      DataFrame.index : Retrieve the index labels.\n",
      " |      DataFrame.columns : Retrieving the column names.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcast to\n",
      " |      int32. By :func:`numpy.find_common_type` convention, mixing int64\n",
      " |      and uint64 will result in a float64 dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A DataFrame where all columns are the same type (e.g., int64) results\n",
      " |      in an array of the same type.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age':    [ 3,  29],\n",
      " |      ...                    'height': [94, 170],\n",
      " |      ...                    'weight': [31, 115]})\n",
      " |      >>> df\n",
      " |         age  height  weight\n",
      " |      0    3      94      31\n",
      " |      1   29     170     115\n",
      " |      >>> df.dtypes\n",
      " |      age       int64\n",
      " |      height    int64\n",
      " |      weight    int64\n",
      " |      dtype: object\n",
      " |      >>> df.values\n",
      " |      array([[  3,  94,  31],\n",
      " |             [ 29, 170, 115]])\n",
      " |      \n",
      " |      A DataFrame with mixed type columns(e.g., str/object, int64, float32)\n",
      " |      results in an ndarray of the broadest type that accommodates these\n",
      " |      mixed types (e.g., object).\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),\n",
      " |      ...                     ('lion',     80.5, 1),\n",
      " |      ...                     ('monkey', np.nan, None)],\n",
      " |      ...                   columns=('name', 'max_speed', 'rank'))\n",
      " |      >>> df2.dtypes\n",
      " |      name          object\n",
      " |      max_speed    float64\n",
      " |      rank          object\n",
      " |      dtype: object\n",
      " |      >>> df2.values\n",
      " |      array([['parrot', 24.0, 'second'],\n",
      " |             ['lion', 80.5, 1],\n",
      " |             ['monkey', nan, None]], dtype=object)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.frame.DataFrame:\n",
      " |  \n",
      " |  columns\n",
      " |      The column labels of the DataFrame.\n",
      " |  \n",
      " |  index\n",
      " |      The index (row labels) of the DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.frame.DataFrame:\n",
      " |  \n",
      " |  __annotations__ = {'_AXIS_TO_AXIS_NUMBER': 'dict[Axis, int]', '_access...\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.PlotAccessor'>\n",
      " |      Make plots of Series or DataFrame.\n",
      " |      \n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |      \n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot (DataFrame only)\n",
      " |          - 'hexbin' : hexbin plot (DataFrame only)\n",
      " |      ax : matplotlib axes object, default None\n",
      " |          An axes of the current figure.\n",
      " |      subplots : bool or sequence of iterables, default False\n",
      " |          Whether to group columns into subplots:\n",
      " |      \n",
      " |          - ``False`` : No subplots will be used\n",
      " |          - ``True`` : Make separate subplots for each column.\n",
      " |          - sequence of iterables of column labels: Create a subplot for each\n",
      " |            group of columns. For example `[('a', 'c'), ('b', 'd')]` will\n",
      " |            create 2 subplots: one with columns 'a' and 'c', and one\n",
      " |            with columns 'b' and 'd'. Remaining columns that aren't specified\n",
      " |            will be plotted in additional subplots (one per column).\n",
      " |            .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case ``subplots=True``, share x axis and set some x axis labels\n",
      " |          to invisible; defaults to True if ax is None otherwise False if\n",
      " |          an ax is passed in; Be aware, that passing in both an ax and\n",
      " |          ``sharex=True`` will alter all x axis labels for all axis in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.\n",
      " |      layout : tuple, optional\n",
      " |          (rows, columns) for the layout of subplots.\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |          Size of a figure object.\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |          Set the x limits of the current axes.\n",
      " |      ylim : 2-tuple/list\n",
      " |          Set the y limits of the current axes.\n",
      " |      xlabel : label, optional\n",
      " |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\n",
      " |          x-column name for planar plots.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |      ylabel : label, optional\n",
      " |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the\n",
      " |          y-column name for planar plots.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |      rot : int, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : int, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      stacked : bool, default False in line and bar plots, and True in area plot\n",
      " |          If True, create stacked plot.\n",
      " |      sort_columns : bool, default False\n",
      " |          Sort column names to determine plot ordering.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |              The `sort_columns` arguments is deprecated and will be removed in a\n",
      " |              future version.\n",
      " |      \n",
      " |      secondary_y : bool or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis if a list/tuple, which\n",
      " |          columns to plot on secondary y-axis.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |  \n",
      " |  \n",
      " |  sparse = <class 'pandas.core.arrays.sparse.accessor.SparseFrameAccesso...\n",
      " |      DataFrame accessor for sparse data.\n",
      " |      \n",
      " |      .. versionadded:: 0.25.0\n",
      " |  \n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |  \n",
      " |  __array__(self, dtype: 'npt.DTypeLike | None' = None) -> 'np.ndarray'\n",
      " |  \n",
      " |  __array_ufunc__(self, ufunc: 'np.ufunc', method: 'str', *inputs: 'Any', **kwargs: 'Any')\n",
      " |  \n",
      " |  __array_wrap__(self, result: 'np.ndarray', context: 'tuple[Callable, tuple[Any, ...], int] | None' = None)\n",
      " |      Gets called after a ufunc and other functions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      result: np.ndarray\n",
      " |          The result of the ufunc or other function called on the NumPy array\n",
      " |          returned by __array__\n",
      " |      context: tuple of (func, tuple, int)\n",
      " |          This parameter is returned by ufuncs as a 3-element tuple: (name of the\n",
      " |          ufunc, arguments of the ufunc, domain of the ufunc), but is not set by\n",
      " |          other numpy functions.q\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Series implements __array_ufunc_ so this not called for ufunc on Series.\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self) -> 'NoReturn'\n",
      " |  \n",
      " |  __contains__(self, key) -> 'bool_t'\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self: 'NDFrameT', deep: 'bool_t' = True) -> 'NDFrameT'\n",
      " |  \n",
      " |  __deepcopy__(self: 'NDFrameT', memo=None) -> 'NDFrameT'\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo, default None\n",
      " |          Standard signature. Unused\n",
      " |  \n",
      " |  __delitem__(self, key) -> 'None'\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self: 'NDFrameT', other, method: 'str | None' = None, **kwargs) -> 'NDFrameT'\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : str, optional\n",
      " |          A passed method name providing context on where ``__finalize__``\n",
      " |          was called.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             The value passed as `method` are not currently considered\n",
      " |             stable across pandas releases.\n",
      " |  \n",
      " |  __getattr__(self, name: 'str')\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self) -> 'dict[str, Any]'\n",
      " |  \n",
      " |  __iadd__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __iand__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __ifloordiv__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __imod__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __imul__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __invert__(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |  \n",
      " |  __ior__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __ipow__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __isub__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over info axis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          Info axis as iterator.\n",
      " |  \n",
      " |  __itruediv__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __ixor__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __neg__(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |  \n",
      " |  __nonzero__(self) -> 'NoReturn'\n",
      " |  \n",
      " |  __pos__(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |  \n",
      " |  __round__(self: 'NDFrameT', decimals: 'int' = 0) -> 'NDFrameT'\n",
      " |  \n",
      " |  __setattr__(self, name: 'str', value) -> 'None'\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state) -> 'None'\n",
      " |  \n",
      " |  abs(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : Calculate the absolute value element-wise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |  \n",
      " |  add_prefix(self: 'NDFrameT', prefix: 'str') -> 'NDFrameT'\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self: 'NDFrameT', suffix: 'str') -> 'NDFrameT'\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      Return the last row(s) without any NaNs before `where`.\n",
      " |      \n",
      " |      The last row (for each element in `where`, if list) without any\n",
      " |      NaN is taken.\n",
      " |      In case of a :class:`~pandas.DataFrame`, the last row without NaN\n",
      " |      considering only the subset of columns (if not `None`)\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series or\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array-like of dates\n",
      " |          Date(s) before which the last row(s) are returned.\n",
      " |      subset : str or array-like of str, default `None`\n",
      " |          For DataFrame, if not `None`, only use these columns to\n",
      " |          check for NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series, or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when `self` is a Series and `where` is a scalar\n",
      " |          * Series: when `self` is a Series and `where` is an array-like,\n",
      " |            or when `self` is a DataFrame and `where` is a scalar\n",
      " |          * DataFrame : when `self` is a DataFrame and `where` is an\n",
      " |            array-like\n",
      " |      \n",
      " |          Return scalar, Series, or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof : Perform an asof merge. Similar to left join.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted. Raises if this is not the case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A Series and a scalar `where`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n",
      " |      >>> s\n",
      " |      10    1.0\n",
      " |      20    2.0\n",
      " |      30    NaN\n",
      " |      40    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.asof(20)\n",
      " |      2.0\n",
      " |      \n",
      " |      For a sequence `where`, a Series is returned. The first value is\n",
      " |      NaN, because the first element of `where` is before the first\n",
      " |      index value.\n",
      " |      \n",
      " |      >>> s.asof([5, 20])\n",
      " |      5     NaN\n",
      " |      20    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Missing values are not considered. The following is ``2.0``, not\n",
      " |      NaN, even though NaN is at the index location for ``30``.\n",
      " |      \n",
      " |      >>> s.asof(30)\n",
      " |      2.0\n",
      " |      \n",
      " |      Take all columns into consideration\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [10, 20, 30, 40, 50],\n",
      " |      ...                    'b': [None, None, None, None, 500]},\n",
      " |      ...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',\n",
      " |      ...                                           '2018-02-27 09:02:00',\n",
      " |      ...                                           '2018-02-27 09:03:00',\n",
      " |      ...                                           '2018-02-27 09:04:00',\n",
      " |      ...                                           '2018-02-27 09:05:00']))\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']))\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30 NaN NaN\n",
      " |      2018-02-27 09:04:30 NaN NaN\n",
      " |      \n",
      " |      Take a single column into consideration\n",
      " |      \n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']),\n",
      " |      ...         subset=['a'])\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30  30 NaN\n",
      " |      2018-02-27 09:04:30  40 NaN\n",
      " |  \n",
      " |  astype(self: 'NDFrameT', dtype, copy: 'bool_t' = True, errors: 'IgnoreRaise' = 'raise') -> 'NDFrameT'\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. deprecated:: 1.3.0\n",
      " |      \n",
      " |          Using ``astype`` to convert from timezone-naive dtype to\n",
      " |          timezone-aware dtype is deprecated and will raise in a\n",
      " |          future version.  Use :meth:`Series.dt.tz_localize` instead.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a DataFrame:\n",
      " |      \n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast all columns to int32:\n",
      " |      \n",
      " |      >>> df.astype('int32').dtypes\n",
      " |      col1    int32\n",
      " |      col2    int32\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast col1 to int32 using a dictionary:\n",
      " |      \n",
      " |      >>> df.astype({'col1': 'int32'}).dtypes\n",
      " |      col1    int32\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Create a series:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> from pandas.api.types import CategoricalDtype\n",
      " |      >>> cat_dtype = CategoricalDtype(\n",
      " |      ...     categories=[2, 1], ordered=True)\n",
      " |      >>> ser.astype(cat_dtype)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1, 2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Create a series of dates:\n",
      " |      \n",
      " |      >>> ser_date = pd.Series(pd.date_range('20200101', periods=3))\n",
      " |      >>> ser_date\n",
      " |      0   2020-01-01\n",
      " |      1   2020-01-02\n",
      " |      2   2020-01-03\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  at_time(self: 'NDFrameT', time, asof: 'bool_t' = False, axis=None) -> 'NDFrameT'\n",
      " |      Select values at particular time of day (e.g., 9:30AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or str\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |  \n",
      " |  backfill = bfill(self: 'NDFrameT', *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast: 'dict | None' = None) -> 'NDFrameT | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  between_time(self: 'NDFrameT', start_time, end_time, include_start: 'bool_t | lib.NoDefault' = <no_default>, include_end: 'bool_t | lib.NoDefault' = <no_default>, inclusive: 'IntervalClosedType | None' = None, axis=None) -> 'NDFrameT'\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or str\n",
      " |          Initial time as a time filter limit.\n",
      " |      end_time : datetime.time or str\n",
      " |          End time as a time filter limit.\n",
      " |      include_start : bool, default True\n",
      " |          Whether the start time needs to be included in the result.\n",
      " |      \n",
      " |          .. deprecated:: 1.4.0\n",
      " |             Arguments `include_start` and `include_end` have been deprecated\n",
      " |             to standardize boundary inputs. Use `inclusive` instead, to set\n",
      " |             each bound as closed or open.\n",
      " |      include_end : bool, default True\n",
      " |          Whether the end time needs to be included in the result.\n",
      " |      \n",
      " |          .. deprecated:: 1.4.0\n",
      " |             Arguments `include_start` and `include_end` have been deprecated\n",
      " |             to standardize boundary inputs. Use `inclusive` instead, to set\n",
      " |             each bound as closed or open.\n",
      " |      inclusive : {\"both\", \"neither\", \"left\", \"right\"}, default \"both\"\n",
      " |          Include boundaries; whether to set each bound as closed or open.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine range time on index or columns value.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Data from the original object filtered to the specified dates range.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |  \n",
      " |  bool(self) -> 'bool_t'\n",
      " |      Return the bool of a single element Series or DataFrame.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False. It will raise a\n",
      " |      ValueError if the Series or DataFrame does not have exactly 1 element, or that\n",
      " |      element is not boolean (integer values 0 and 1 will also raise an exception).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          The value in the Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.astype : Change the data type of a Series, including to boolean.\n",
      " |      DataFrame.astype : Change the data type of a DataFrame, including to boolean.\n",
      " |      numpy.bool_ : NumPy boolean data type, used by pandas for boolean values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The method will only work for single element objects with a boolean value:\n",
      " |      \n",
      " |      >>> pd.Series([True]).bool()\n",
      " |      True\n",
      " |      >>> pd.Series([False]).bool()\n",
      " |      False\n",
      " |      \n",
      " |      >>> pd.DataFrame({'col': [True]}).bool()\n",
      " |      True\n",
      " |      >>> pd.DataFrame({'col': [False]}).bool()\n",
      " |      False\n",
      " |  \n",
      " |  convert_dtypes(self: 'NDFrameT', infer_objects: 'bool_t' = True, convert_string: 'bool_t' = True, convert_integer: 'bool_t' = True, convert_boolean: 'bool_t' = True, convert_floating: 'bool_t' = True) -> 'NDFrameT'\n",
      " |      Convert columns to best possible dtypes using dtypes supporting ``pd.NA``.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      infer_objects : bool, default True\n",
      " |          Whether object dtypes should be converted to the best possible types.\n",
      " |      convert_string : bool, default True\n",
      " |          Whether object dtypes should be converted to ``StringDtype()``.\n",
      " |      convert_integer : bool, default True\n",
      " |          Whether, if possible, conversion can be done to integer extension types.\n",
      " |      convert_boolean : bool, defaults True\n",
      " |          Whether object dtypes should be converted to ``BooleanDtypes()``.\n",
      " |      convert_floating : bool, defaults True\n",
      " |          Whether, if possible, conversion can be done to floating extension types.\n",
      " |          If `convert_integer` is also True, preference will be give to integer\n",
      " |          dtypes if the floats can be faithfully casted to integers.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Copy of input object with new dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      infer_objects : Infer dtypes of objects.\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, ``convert_dtypes`` will attempt to convert a Series (or each\n",
      " |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options\n",
      " |      ``convert_string``, ``convert_integer``, ``convert_boolean`` and\n",
      " |      ``convert_boolean``, it is possible to turn off individual conversions\n",
      " |      to ``StringDtype``, the integer extension types, ``BooleanDtype``\n",
      " |      or floating extension types, respectively.\n",
      " |      \n",
      " |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference\n",
      " |      rules as during normal Series/DataFrame construction.  Then, if possible,\n",
      " |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer\n",
      " |      or floating extension type, otherwise leave as ``object``.\n",
      " |      \n",
      " |      If the dtype is integer, convert to an appropriate integer extension type.\n",
      " |      \n",
      " |      If the dtype is numeric, and consists of all integers, convert to an\n",
      " |      appropriate integer extension type. Otherwise, convert to an\n",
      " |      appropriate floating extension type.\n",
      " |      \n",
      " |      .. versionchanged:: 1.2\n",
      " |          Starting with pandas 1.2, this method also converts float columns\n",
      " |          to the nullable floating extension type.\n",
      " |      \n",
      " |      In the future, as new dtypes are added that support ``pd.NA``, the results\n",
      " |      of this method will change to support those new dtypes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
      " |      ...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
      " |      ...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Start with a DataFrame with default dtypes.\n",
      " |      \n",
      " |      >>> df\n",
      " |         a  b      c    d     e      f\n",
      " |      0  1  x   True    h  10.0    NaN\n",
      " |      1  2  y  False    i   NaN  100.5\n",
      " |      2  3  z    NaN  NaN  20.0  200.0\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      a      int32\n",
      " |      b     object\n",
      " |      c     object\n",
      " |      d     object\n",
      " |      e    float64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Convert the DataFrame to use best possible dtypes.\n",
      " |      \n",
      " |      >>> dfn = df.convert_dtypes()\n",
      " |      >>> dfn\n",
      " |         a  b      c     d     e      f\n",
      " |      0  1  x   True     h    10   <NA>\n",
      " |      1  2  y  False     i  <NA>  100.5\n",
      " |      2  3  z   <NA>  <NA>    20  200.0\n",
      " |      \n",
      " |      >>> dfn.dtypes\n",
      " |      a      Int32\n",
      " |      b     string\n",
      " |      c    boolean\n",
      " |      d     string\n",
      " |      e      Int64\n",
      " |      f    Float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Start with a Series of strings and missing data represented by ``np.nan``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\", np.nan])\n",
      " |      >>> s\n",
      " |      0      a\n",
      " |      1      b\n",
      " |      2    NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Obtain a Series with dtype ``StringDtype``.\n",
      " |      \n",
      " |      >>> s.convert_dtypes()\n",
      " |      0       a\n",
      " |      1       b\n",
      " |      2    <NA>\n",
      " |      dtype: string\n",
      " |  \n",
      " |  copy(self: 'NDFrameT', deep: 'bool_t | None' = True) -> 'NDFrameT'\n",
      " |      Make a copy of this object's indices and data.\n",
      " |      \n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |      \n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : Series or DataFrame\n",
      " |          Object type matches caller.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |      \n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |      \n",
      " |      Since pandas is not thread safe, see the\n",
      " |      :ref:`gotchas <gotchas.thread-safety>` when copying in a threading\n",
      " |      environment.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |      \n",
      " |      Shallow copy shares data and index with original.\n",
      " |      \n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |      \n",
      " |      Deep copy has own copy of data and index.\n",
      " |      \n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |      \n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both; deep copy remains unchanged.\n",
      " |      \n",
      " |      >>> s[0] = 3\n",
      " |      >>> shallow[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |      \n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |  \n",
      " |  describe(self: 'NDFrameT', percentiles=None, include=None, exclude=None, datetime_is_numeric: 'bool_t' = False) -> 'NDFrameT'\n",
      " |      Generate descriptive statistics.\n",
      " |      \n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(exclude=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      datetime_is_numeric : bool, default False\n",
      " |          Whether to treat datetime dtypes as numeric. This affects statistics\n",
      " |          calculated for the column. For DataFrame input, this also\n",
      " |          controls whether datetime columns are included by default.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe(datetime_is_numeric=True)\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              d\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  droplevel(self: 'NDFrameT', level: 'IndexLabel', axis: 'Axis' = 0) -> 'NDFrameT'\n",
      " |      Return Series/DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list-like\n",
      " |          If a string is given, must be the name of a level\n",
      " |          If list-like, elements must be names or positional indexes\n",
      " |          of levels.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the level(s) is removed:\n",
      " |      \n",
      " |          * 0 or 'index': remove level(s) in column.\n",
      " |          * 1 or 'columns': remove level(s) in row.\n",
      " |      \n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Series/DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     [1, 2, 3, 4],\n",
      " |      ...     [5, 6, 7, 8],\n",
      " |      ...     [9, 10, 11, 12]\n",
      " |      ... ]).set_index([0, 1]).rename_axis(['a', 'b'])\n",
      " |      \n",
      " |      >>> df.columns = pd.MultiIndex.from_tuples([\n",
      " |      ...     ('c', 'e'), ('d', 'f')\n",
      " |      ... ], names=['level_1', 'level_2'])\n",
      " |      \n",
      " |      >>> df\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |      \n",
      " |      >>> df.droplevel('a')\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      b\n",
      " |      2        3   4\n",
      " |      6        7   8\n",
      " |      10      11  12\n",
      " |      \n",
      " |      >>> df.droplevel('level_2', axis=1)\n",
      " |      level_1   c   d\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |  \n",
      " |  equals(self, other: 'object') -> 'bool_t'\n",
      " |      Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      This function allows two Series or DataFrames to be compared against\n",
      " |      each other to see if they have the same shape and elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |      \n",
      " |      The row/column index do not need to have the same type, as long\n",
      " |      as the values are considered equal. Corresponding columns must be of\n",
      " |      the same dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |          The other Series or DataFrame to be compared with the first.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if all elements are the same in both objects, False\n",
      " |          otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.eq : Compare two Series objects of the same length\n",
      " |          and return a Series where each element is True if the element\n",
      " |          in each Series is equal, False otherwise.\n",
      " |      DataFrame.eq : Compare two DataFrame objects of the same shape and\n",
      " |          return a DataFrame where each element is True if the respective\n",
      " |          element in each DataFrame is equal, False otherwise.\n",
      " |      testing.assert_series_equal : Raises an AssertionError if left and\n",
      " |          right are not equal. Provides an easy interface to ignore\n",
      " |          inequality in dtypes, indexes and precision among others.\n",
      " |      testing.assert_frame_equal : Like assert_series_equal, but targets\n",
      " |          DataFrames.\n",
      " |      numpy.array_equal : Return True if two arrays have the same shape\n",
      " |          and elements, False otherwise.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> df\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      \n",
      " |      DataFrames df and exactly_equal have the same types and values for\n",
      " |      their elements and column labels, which will return True.\n",
      " |      \n",
      " |      >>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> exactly_equal\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      >>> df.equals(exactly_equal)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_column_type have the same element\n",
      " |      types and values, but have different types for the column labels,\n",
      " |      which will still return True.\n",
      " |      \n",
      " |      >>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})\n",
      " |      >>> different_column_type\n",
      " |         1.0  2.0\n",
      " |      0   10   20\n",
      " |      >>> df.equals(different_column_type)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_data_type have different types for the\n",
      " |      same values for their elements, and will return False even though\n",
      " |      their column labels are the same values and types.\n",
      " |      \n",
      " |      >>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})\n",
      " |      >>> different_data_type\n",
      " |            1     2\n",
      " |      0  10.0  20.0\n",
      " |      >>> df.equals(different_data_type)\n",
      " |      False\n",
      " |  \n",
      " |  ewm(self, com: 'float | None' = None, span: 'float | None' = None, halflife: 'float | TimedeltaConvertibleTypes | None' = None, alpha: 'float | None' = None, min_periods: 'int | None' = 0, adjust: 'bool_t' = True, ignore_na: 'bool_t' = False, axis: 'Axis' = 0, times: 'str | np.ndarray | DataFrame | Series | None' = None, method: 'str' = 'single') -> 'ExponentialMovingWindow'\n",
      " |      Provide exponentially weighted (EW) calculations.\n",
      " |      \n",
      " |      Exactly one of ``com``, ``span``, ``halflife``, or ``alpha`` must be\n",
      " |      provided if ``times`` is not provided. If ``times`` is provided,\n",
      " |      ``halflife`` and one of ``com``, ``span`` or ``alpha`` may be provided.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass\n",
      " |      \n",
      " |          :math:`\\alpha = 1 / (1 + com)`, for :math:`com \\geq 0`.\n",
      " |      \n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span\n",
      " |      \n",
      " |          :math:`\\alpha = 2 / (span + 1)`, for :math:`span \\geq 1`.\n",
      " |      \n",
      " |      halflife : float, str, timedelta, optional\n",
      " |          Specify decay in terms of half-life\n",
      " |      \n",
      " |          :math:`\\alpha = 1 - \\exp\\left(-\\ln(2) / halflife\\right)`, for\n",
      " |          :math:`halflife > 0`.\n",
      " |      \n",
      " |          If ``times`` is specified, a timedelta convertible unit over which an\n",
      " |          observation decays to half its value. Only applicable to ``mean()``,\n",
      " |          and halflife value will not apply to the other functions.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly\n",
      " |      \n",
      " |          :math:`0 < \\alpha \\leq 1`.\n",
      " |      \n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |      adjust : bool, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average).\n",
      " |      \n",
      " |          - When ``adjust=True`` (default), the EW function is calculated using weights\n",
      " |            :math:`w_i = (1 - \\alpha)^i`. For example, the EW moving average of the series\n",
      " |            [:math:`x_0, x_1, ..., x_t`] would be:\n",
      " |      \n",
      " |          .. math::\n",
      " |              y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ... + (1 -\n",
      " |              \\alpha)^t x_0}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^t}\n",
      " |      \n",
      " |          - When ``adjust=False``, the exponentially weighted function is calculated\n",
      " |            recursively:\n",
      " |      \n",
      " |          .. math::\n",
      " |              \\begin{split}\n",
      " |                  y_0 &= x_0\\\\\n",
      " |                  y_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\n",
      " |              \\end{split}\n",
      " |      ignore_na : bool, default False\n",
      " |          Ignore missing values when calculating weights.\n",
      " |      \n",
      " |          - When ``ignore_na=False`` (default), weights are based on absolute positions.\n",
      " |            For example, the weights of :math:`x_0` and :math:`x_2` used in calculating\n",
      " |            the final weighted average of [:math:`x_0`, None, :math:`x_2`] are\n",
      " |            :math:`(1-\\alpha)^2` and :math:`1` if ``adjust=True``, and\n",
      " |            :math:`(1-\\alpha)^2` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      \n",
      " |          - When ``ignore_na=True``, weights are based\n",
      " |            on relative positions. For example, the weights of :math:`x_0` and :math:`x_2`\n",
      " |            used in calculating the final weighted average of\n",
      " |            [:math:`x_0`, None, :math:`x_2`] are :math:`1-\\alpha` and :math:`1` if\n",
      " |            ``adjust=True``, and :math:`1-\\alpha` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          If ``0`` or ``'index'``, calculate across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, calculate across the columns.\n",
      " |      \n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      times : str, np.ndarray, Series, default None\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          Only applicable to ``mean()``.\n",
      " |      \n",
      " |          Times corresponding to the observations. Must be monotonically increasing and\n",
      " |          ``datetime64[ns]`` dtype.\n",
      " |      \n",
      " |          If 1-D array like, a sequence with the same shape as the observations.\n",
      " |      \n",
      " |          .. deprecated:: 1.4.0\n",
      " |              If str, the name of the column in the DataFrame representing the times.\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |          Only applicable to ``mean()``\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ``ExponentialMovingWindow`` subclass\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.exponentially_weighted>`\n",
      " |      for further usage details and examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      >>> df.ewm(alpha=2 / 3).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      **adjust**\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5, adjust=True).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      >>> df.ewm(com=0.5, adjust=False).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.666667\n",
      " |      2  1.555556\n",
      " |      3  1.555556\n",
      " |      4  3.650794\n",
      " |      \n",
      " |      **ignore_na**\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5, ignore_na=True).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.225000\n",
      " |      >>> df.ewm(com=0.5, ignore_na=False).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      **times**\n",
      " |      \n",
      " |      Exponentially weighted mean with weights calculated with a timedelta ``halflife``\n",
      " |      relative to ``times``.\n",
      " |      \n",
      " |      >>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
      " |      >>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.585786\n",
      " |      2  1.523889\n",
      " |      3  1.523889\n",
      " |      4  3.233686\n",
      " |  \n",
      " |  expanding(self, min_periods: 'int' = 1, center: 'bool_t | None' = None, axis: 'Axis' = 0, method: 'str' = 'single') -> 'Expanding'\n",
      " |      Provide expanding window calculations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |      center : bool, default False\n",
      " |          If False, set the window labels as the right edge of the window index.\n",
      " |      \n",
      " |          If True, set the window labels as the center of the window index.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |      \n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |      \n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ``Expanding`` subclass\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.expanding>` for further usage details\n",
      " |      and examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **min_periods**\n",
      " |      \n",
      " |      Expanding sum with 1 vs 3 observations needed to calculate a value.\n",
      " |      \n",
      " |      >>> df.expanding(1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      >>> df.expanding(3).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |  \n",
      " |  filter(self: 'NDFrameT', items=None, like: 'str | None' = None, regex: 'str | None' = None, axis=None) -> 'NDFrameT'\n",
      " |      Subset the dataframe rows or columns according to the specified index labels.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          Keep labels from axis which are in items.\n",
      " |      like : str\n",
      " |          Keep labels from axis for which \"like in label == True\".\n",
      " |      regex : str (regular expression)\n",
      " |          Keep labels from axis for which re.search(regex, label) == True.\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          The axis to filter on, expressed either as an index (int)\n",
      " |          or axis name (str). By default this is the info axis, 'columns' for\n",
      " |          DataFrame. For `Series` this parameter is unused and defaults to `None`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
      " |      ...                   index=['mouse', 'rabbit'],\n",
      " |      ...                   columns=['one', 'two', 'three'])\n",
      " |      >>> df\n",
      " |              one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |               one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |  \n",
      " |  first(self: 'NDFrameT', offset) -> 'NDFrameT'\n",
      " |      Select initial periods of time series data based on a date offset.\n",
      " |      \n",
      " |      When having a DataFrame with dates as index, this function can\n",
      " |      select the first few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset or dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '1M' will display all the rows having their index within the first month.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calendar days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  first_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for first non-NA value or None, if no non-NA value is found.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (ex: DataFrame column).\n",
      " |      \n",
      " |      Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : same type as items contained in object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [\n",
      " |      ...         [24.3, 75.7, \"high\"],\n",
      " |      ...         [31, 87.8, \"high\"],\n",
      " |      ...         [22, 71.6, \"medium\"],\n",
      " |      ...         [35, 95, \"medium\"],\n",
      " |      ...     ],\n",
      " |      ...     columns=[\"temp_celsius\", \"temp_fahrenheit\", \"windspeed\"],\n",
      " |      ...     index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"),\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> df\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |      \n",
      " |      >>> df.get([\"temp_celsius\", \"windspeed\"])\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          24.3      high\n",
      " |      2014-02-13          31.0      high\n",
      " |      2014-02-14          22.0    medium\n",
      " |      2014-02-15          35.0    medium\n",
      " |      \n",
      " |      If the key isn't found, the default value will be used.\n",
      " |      \n",
      " |      >>> df.get([\"temp_celsius\", \"temp_kelvin\"], default=\"default_value\")\n",
      " |      'default_value'\n",
      " |  \n",
      " |  head(self: 'NDFrameT', n: 'int' = 5) -> 'NDFrameT'\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the last `|n|` rows, equivalent to ``df[:n]``.\n",
      " |      \n",
      " |      If n is larger than the number of rows, this function returns all rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.head(-3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |  \n",
      " |  infer_objects(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to numeric type.\n",
      " |      convert_dtypes : Convert argument to best possible dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  keys(self) -> 'Index'\n",
      " |      Get the 'info axis' (see Indexing for more).\n",
      " |      \n",
      " |      This is index for Series, columns for DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Info axis.\n",
      " |  \n",
      " |  last(self: 'NDFrameT', offset) -> 'NDFrameT'\n",
      " |      Select final periods of time series data based on a date offset.\n",
      " |      \n",
      " |      For a DataFrame with a sorted DatetimeIndex, this function\n",
      " |      selects the last few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset, dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '3D' will display all the rows having their index within the last 3 days.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calendar days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  last_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for last non-NA value or None, if no non-NA value is found.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  pad = ffill(self: 'NDFrameT', *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast: 'dict | None' = None) -> 'NDFrameT | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  pct_change(self: 'NDFrameT', periods=1, fill_method='pad', limit=None, freq=None, **kwargs) -> 'NDFrameT'\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs **before** computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or str, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns', periods=-1)\n",
      " |                2016      2015  2014\n",
      " |      GOOG  0.179241  0.094112   NaN\n",
      " |      APPL -0.252395 -0.011860   NaN\n",
      " |  \n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply chainable functions that expect Series or DataFrames.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to the Series/DataFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the Series/DataFrame.\n",
      " |      args : iterable, optional\n",
      " |          Positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          A dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      Series.map : Apply a mapping correspondence on a\n",
      " |          :class:`~pandas.Series`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> func(g(h(df), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(func, arg2=b, arg3=c)\n",
      " |      ... )  # doctest: +SKIP\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((func, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )  # doctest: +SKIP\n",
      " |  \n",
      " |  rank(self: 'NDFrameT', axis=0, method: 'str' = 'average', numeric_only: 'bool_t | None | lib.NoDefault' = <no_default>, na_option: 'str' = 'keep', ascending: 'bool_t' = True, pct: 'bool_t' = False) -> 'NDFrameT'\n",
      " |      Compute numerical data ranks (1 through n) along axis.\n",
      " |      \n",
      " |      By default, equal values are assigned a rank that is the average of the\n",
      " |      ranks of those values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Index to direct ranking.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          How to rank the group of records that have the same value (i.e. ties):\n",
      " |      \n",
      " |          * average: average rank of the group\n",
      " |          * min: lowest rank in the group\n",
      " |          * max: highest rank in the group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |      \n",
      " |      numeric_only : bool, optional\n",
      " |          For DataFrame objects, rank only numeric columns if set to True.\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          How to rank NaN values:\n",
      " |      \n",
      " |          * keep: assign NaN rank to NaN values\n",
      " |          * top: assign lowest rank to NaN values\n",
      " |          * bottom: assign highest rank to NaN values\n",
      " |      \n",
      " |      ascending : bool, default True\n",
      " |          Whether or not the elements should be ranked in ascending order.\n",
      " |      pct : bool, default False\n",
      " |          Whether or not to display the returned rankings in percentile\n",
      " |          form.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          Return a Series or DataFrame with data ranks as values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.GroupBy.rank : Rank of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
      " |      ...                                    'spider', 'snake'],\n",
      " |      ...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n",
      " |      >>> df\n",
      " |          Animal  Number_legs\n",
      " |      0      cat          4.0\n",
      " |      1  penguin          2.0\n",
      " |      2      dog          4.0\n",
      " |      3   spider          8.0\n",
      " |      4    snake          NaN\n",
      " |      \n",
      " |      Ties are assigned the mean of the ranks (by default) for the group.\n",
      " |      \n",
      " |      >>> s = pd.Series(range(5), index=list(\"abcde\"))\n",
      " |      >>> s[\"d\"] = s[\"b\"]\n",
      " |      >>> s.rank()\n",
      " |      a    1.0\n",
      " |      b    2.5\n",
      " |      c    4.0\n",
      " |      d    2.5\n",
      " |      e    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      The following example shows how the method behaves with the above\n",
      " |      parameters:\n",
      " |      \n",
      " |      * default_rank: this is the default behaviour obtained without using\n",
      " |        any parameter.\n",
      " |      * max_rank: setting ``method = 'max'`` the records that have the\n",
      " |        same values are ranked using the highest rank (e.g.: since 'cat'\n",
      " |        and 'dog' are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
      " |      * NA_bottom: choosing ``na_option = 'bottom'``, if there are records\n",
      " |        with NaN values they are placed at the bottom of the ranking.\n",
      " |      * pct_rank: when setting ``pct = True``, the ranking is expressed as\n",
      " |        percentile rank.\n",
      " |      \n",
      " |      >>> df['default_rank'] = df['Number_legs'].rank()\n",
      " |      >>> df['max_rank'] = df['Number_legs'].rank(method='max')\n",
      " |      >>> df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
      " |      >>> df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
      " |      >>> df\n",
      " |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
      " |      0      cat          4.0           2.5       3.0        2.5     0.625\n",
      " |      1  penguin          2.0           1.0       1.0        1.0     0.250\n",
      " |      2      dog          4.0           2.5       3.0        2.5     0.625\n",
      " |      3   spider          8.0           4.0       4.0        4.0     1.000\n",
      " |      4    snake          NaN           NaN       NaN        5.0       NaN\n",
      " |  \n",
      " |  reindex_like(self: 'NDFrameT', other, method: 'str | None' = None, copy: 'bool_t' = True, limit=None, tolerance=None) -> 'NDFrameT'\n",
      " |      Return an object with matching indices as other object.\n",
      " |      \n",
      " |      Conform the object to the same index on all axes. Optional\n",
      " |      filling logic, placing NaN in locations having no value\n",
      " |      in the previous index. A new object is produced unless the\n",
      " |      new index is equivalent to the current one and copy=False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object of the same data type\n",
      " |          Its row and column indices are used to define the new indices\n",
      " |          of this object.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations must\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as caller, but with changed indices on each axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Same as calling\n",
      " |      ``.reindex(index=other.index, columns=other.columns,...)``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
      " |      ...                     [31, 87.8, 'high'],\n",
      " |      ...                     [22, 71.6, 'medium'],\n",
      " |      ...                     [35, 95, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'temp_fahrenheit',\n",
      " |      ...                             'windspeed'],\n",
      " |      ...                    index=pd.date_range(start='2014-02-12',\n",
      " |      ...                                        end='2014-02-15', freq='D'))\n",
      " |      \n",
      " |      >>> df1\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([[28, 'low'],\n",
      " |      ...                     [30, 'low'],\n",
      " |      ...                     [35.1, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'windspeed'],\n",
      " |      ...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
      " |      ...                                            '2014-02-15']))\n",
      " |      \n",
      " |      >>> df2\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          28.0       low\n",
      " |      2014-02-13          30.0       low\n",
      " |      2014-02-15          35.1    medium\n",
      " |      \n",
      " |      >>> df2.reindex_like(df1)\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          28.0              NaN       low\n",
      " |      2014-02-13          30.0              NaN       low\n",
      " |      2014-02-14           NaN              NaN       NaN\n",
      " |      2014-02-15          35.1              NaN    medium\n",
      " |  \n",
      " |  rename_axis(self: 'NDFrameT', mapper: 'IndexLabel | lib.NoDefault' = <no_default>, *, inplace: 'bool_t' = False, **kwargs) -> 'NDFrameT | None'\n",
      " |      Set the name of the axis for the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set the axis name attribute.\n",
      " |      index, columns : scalar, list-like, dict-like or function, optional\n",
      " |          A scalar, list-like, dict-like or functions transformations to\n",
      " |          apply to that axis' values.\n",
      " |          Note that the ``columns`` parameter is not allowed if the\n",
      " |          object is a Series. This parameter only apply for DataFrame\n",
      " |          type objects.\n",
      " |      \n",
      " |          Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index``\n",
      " |          and/or ``columns``.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to rename. For `Series` this parameter is unused and defaults to 0.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series, DataFrame, or None\n",
      " |          The same type as the caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Alter Series index labels or name.\n",
      " |      DataFrame.rename : Alter DataFrame index labels or name.\n",
      " |      Index.rename : Set new names on index.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``DataFrame.rename_axis`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      The first calling convention will only modify the names of\n",
      " |      the index and/or the names of the Index object that is the columns.\n",
      " |      In this case, the parameter ``copy`` is ignored.\n",
      " |      \n",
      " |      The second calling convention will modify the names of the\n",
      " |      corresponding index if mapper is a list or a scalar.\n",
      " |      However, if mapper is dict-like or a function, it will use the\n",
      " |      deprecated behavior of modifying the axis *labels*.\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> s\n",
      " |      0       dog\n",
      " |      1       cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      >>> s.rename_axis(\"animal\")\n",
      " |      animal\n",
      " |      0    dog\n",
      " |      1    cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"num_legs\": [4, 4, 2],\n",
      " |      ...                    \"num_arms\": [0, 0, 2]},\n",
      " |      ...                   [\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"animal\")\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
      " |      >>> df\n",
      " |      limbs   num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      \n",
      " |      **MultiIndex**\n",
      " |      \n",
      " |      >>> df.index = pd.MultiIndex.from_product([['mammal'],\n",
      " |      ...                                        ['dog', 'cat', 'monkey']],\n",
      " |      ...                                       names=['type', 'name'])\n",
      " |      >>> df\n",
      " |      limbs          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(index={'type': 'class'})\n",
      " |      limbs          num_legs  num_arms\n",
      " |      class  name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(columns=str.upper)\n",
      " |      LIMBS          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |  \n",
      " |  rolling(self, window: 'int | timedelta | BaseOffset | BaseIndexer', min_periods: 'int | None' = None, center: 'bool_t' = False, win_type: 'str | None' = None, on: 'str | None' = None, axis: 'Axis' = 0, closed: 'str | None' = None, step: 'int | None' = None, method: 'str' = 'single') -> 'Window | Rolling'\n",
      " |      Provide rolling window calculations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window.\n",
      " |      \n",
      " |          If an integer, the fixed number of observations used for\n",
      " |          each window.\n",
      " |      \n",
      " |          If an offset, the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |          To learn more about the offsets & frequency strings, please see `this link\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |          If a BaseIndexer subclass, the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely ``min_periods``, ``center``, ``closed`` and\n",
      " |          ``step`` will be passed to ``get_window_bounds``.\n",
      " |      \n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |          For a window that is specified by an offset, ``min_periods`` will default to 1.\n",
      " |      \n",
      " |          For a window that is specified by an integer, ``min_periods`` will default\n",
      " |          to the size of the window.\n",
      " |      \n",
      " |      center : bool, default False\n",
      " |          If False, set the window labels as the right edge of the window index.\n",
      " |      \n",
      " |          If True, set the window labels as the center of the window index.\n",
      " |      \n",
      " |      win_type : str, default None\n",
      " |          If ``None``, all points are evenly weighted.\n",
      " |      \n",
      " |          If a string, it must be a valid `scipy.signal window function\n",
      " |          <https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows>`__.\n",
      " |      \n",
      " |          Certain Scipy window types require additional parameters to be passed\n",
      " |          in the aggregation function. The additional parameters must match\n",
      " |          the keywords specified in the Scipy window type method signature.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a column label or Index level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |      \n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |      \n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |      \n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      closed : str, default None\n",
      " |          If ``'right'``, the first point in the window is excluded from calculations.\n",
      " |      \n",
      " |          If ``'left'``, the last point in the window is excluded from calculations.\n",
      " |      \n",
      " |          If ``'both'``, the no points in the window are excluded from calculations.\n",
      " |      \n",
      " |          If ``'neither'``, the first and last points in the window are excluded\n",
      " |          from calculations.\n",
      " |      \n",
      " |          Default ``None`` (``'right'``).\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              The closed parameter with fixed windows is now supported.\n",
      " |      \n",
      " |      step : int, default None\n",
      " |      \n",
      " |          ..versionadded:: 1.5.0\n",
      " |      \n",
      " |          Evaluate the window at every ``step`` result, equivalent to slicing as\n",
      " |          ``[::step]``. ``window`` must be an integer. Using a step argument other\n",
      " |          than None or 1 will produce a result with a different shape than the input.\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ``Window`` subclass if a ``win_type`` is passed\n",
      " |      \n",
      " |      ``Rolling`` subclass if ``win_type`` is not passed\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.generic>` for further usage details\n",
      " |      and examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **window**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2 observations.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window span of 2 seconds.\n",
      " |      \n",
      " |      >>> df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                        index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df_time\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      >>> df_time.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Rolling sum with forward looking windows with 2 observations.\n",
      " |      \n",
      " |      >>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
      " |      >>> df.rolling(window=indexer, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  2.0\n",
      " |      3  4.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **min_periods**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2 observations, but only needs a minimum of 1\n",
      " |      observation to calculate a value.\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **center**\n",
      " |      \n",
      " |      Rolling sum with the result assigned to the center of the window index.\n",
      " |      \n",
      " |      >>> df.rolling(3, min_periods=1, center=True).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  3.0\n",
      " |      3  6.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.rolling(3, min_periods=1, center=False).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  6.0\n",
      " |      \n",
      " |      **step**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2 observations, minimum of 1 observation to\n",
      " |      calculate a value, and a step of 2.\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1, step=2).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      2  3.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **win_type**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the Scipy ``'gaussian'``\n",
      " |      window type. ``std`` is required in the aggregation function.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='gaussian').sum(std=3)\n",
      " |                B\n",
      " |      0       NaN\n",
      " |      1  0.986207\n",
      " |      2  2.958621\n",
      " |      3       NaN\n",
      " |      4       NaN\n",
      " |  \n",
      " |  sample(self: 'NDFrameT', n: 'int | None' = None, frac: 'float | None' = None, replace: 'bool_t' = False, weights=None, random_state: 'RandomState | None' = None, axis: 'Axis | None' = None, ignore_index: 'bool_t' = False) -> 'NDFrameT'\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          Infinite values not allowed.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional\n",
      " |          If int, array-like, or BitGenerator, seed for random number generator.\n",
      " |          If np.random.RandomState or np.random.Generator, use as given.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |              array-like and BitGenerator object now passed to np.random.RandomState()\n",
      " |              as seed\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |      \n",
      " |              np.random.Generator objects now accepted\n",
      " |      \n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type. For `Series` this parameter is unused and defaults to `None`.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing `n` items randomly\n",
      " |          sampled from the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrameGroupBy.sample: Generates random samples from each group of a\n",
      " |          DataFrame object.\n",
      " |      SeriesGroupBy.sample: Generates random samples from each group of a\n",
      " |          Series object.\n",
      " |      numpy.random.choice: Generates a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `frac` > 1, `replacement` should be set to `True`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0],\n",
      " |      ...                    'num_specimen_seen': [10, 2, 1, 8]},\n",
      " |      ...                   index=['falcon', 'dog', 'spider', 'fish'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      dog            4          0                  2\n",
      " |      spider         8          0                  1\n",
      " |      fish           0          0                  8\n",
      " |      \n",
      " |      Extract 3 random elements from the ``Series`` ``df['num_legs']``:\n",
      " |      Note that we use `random_state` to ensure the reproducibility of\n",
      " |      the examples.\n",
      " |      \n",
      " |      >>> df['num_legs'].sample(n=3, random_state=1)\n",
      " |      fish      0\n",
      " |      spider    8\n",
      " |      falcon    2\n",
      " |      Name: num_legs, dtype: int64\n",
      " |      \n",
      " |      A random 50% sample of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.5, replace=True, random_state=1)\n",
      " |            num_legs  num_wings  num_specimen_seen\n",
      " |      dog          4          0                  2\n",
      " |      fish         0          0                  8\n",
      " |      \n",
      " |      An upsample sample of the ``DataFrame`` with replacement:\n",
      " |      Note that `replace` parameter has to be `True` for `frac` parameter > 1.\n",
      " |      \n",
      " |      >>> df.sample(frac=2, replace=True, random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      falcon         2          2                 10\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      \n",
      " |      Using a DataFrame column as weights. Rows with larger value in the\n",
      " |      `num_specimen_seen` column are more likely to be sampled.\n",
      " |      \n",
      " |      >>> df.sample(n=2, weights='num_specimen_seen', random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |  \n",
      " |  set_flags(self: 'NDFrameT', *, copy: 'bool_t' = False, allows_duplicate_labels: 'bool_t | None' = None) -> 'NDFrameT'\n",
      " |      Return a new object with updated flags.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      allows_duplicate_labels : bool, optional\n",
      " |          Whether the returned object allows duplicate labels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          The same type as the caller.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method returns a new object that's a view on the same data\n",
      " |      as the input. Mutating the input or the output values will be reflected\n",
      " |      in the other.\n",
      " |      \n",
      " |      This method is intended to be used in method chains.\n",
      " |      \n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df2 = df.set_flags(allows_duplicate_labels=False)\n",
      " |      >>> df2.flags.allows_duplicate_labels\n",
      " |      False\n",
      " |  \n",
      " |  slice_shift(self: 'NDFrameT', periods: 'int' = 1, axis=0) -> 'NDFrameT'\n",
      " |      Equivalent to `shift` without copying data.\n",
      " |      \n",
      " |      .. deprecated:: 1.2.0\n",
      " |          slice_shift is deprecated,\n",
      " |          use DataFrame/Series.shift instead.\n",
      " |      \n",
      " |      The shifted data will not include the dropped periods and the\n",
      " |      shifted axis will be smaller than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze 1 dimensional axis objects into scalars.\n",
      " |      \n",
      " |      Series or DataFrames with a single element are squeezed to a scalar.\n",
      " |      DataFrames with a single column or a single row are squeezed to a\n",
      " |      Series. Otherwise the object is unchanged.\n",
      " |      \n",
      " |      This method is most useful when you don't know if your\n",
      " |      object is a Series or DataFrame, but you do know it has just a single\n",
      " |      column. In that case you can safely call `squeeze` to ensure you have a\n",
      " |      Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          A specific axis to squeeze. By default, all length-1 axes are\n",
      " |          squeezed. For `Series` this parameter is unused and defaults to `None`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series, or scalar\n",
      " |          The projection after squeezing `axis` or all the axes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.iloc : Integer-location based indexing for selecting scalars.\n",
      " |      DataFrame.iloc : Integer-location based indexing for selecting Series.\n",
      " |      Series.to_frame : Inverse of DataFrame.squeeze for a\n",
      " |          single-column DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> primes = pd.Series([2, 3, 5, 7])\n",
      " |      \n",
      " |      Slicing might produce a Series with a single value:\n",
      " |      \n",
      " |      >>> even_primes = primes[primes % 2 == 0]\n",
      " |      >>> even_primes\n",
      " |      0    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> even_primes.squeeze()\n",
      " |      2\n",
      " |      \n",
      " |      Squeezing objects with more than one value in every axis does nothing:\n",
      " |      \n",
      " |      >>> odd_primes = primes[primes % 2 == 1]\n",
      " |      >>> odd_primes\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> odd_primes.squeeze()\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Squeezing is even more effective when used with DataFrames.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])\n",
      " |      >>> df\n",
      " |         a  b\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      \n",
      " |      Slicing a single column will produce a DataFrame with the columns\n",
      " |      having only one value:\n",
      " |      \n",
      " |      >>> df_a = df[['a']]\n",
      " |      >>> df_a\n",
      " |         a\n",
      " |      0  1\n",
      " |      1  3\n",
      " |      \n",
      " |      So the columns can be squeezed down, resulting in a Series:\n",
      " |      \n",
      " |      >>> df_a.squeeze('columns')\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      Name: a, dtype: int64\n",
      " |      \n",
      " |      Slicing a single row from a single column will produce a single\n",
      " |      scalar DataFrame:\n",
      " |      \n",
      " |      >>> df_0a = df.loc[df.index < 1, ['a']]\n",
      " |      >>> df_0a\n",
      " |         a\n",
      " |      0  1\n",
      " |      \n",
      " |      Squeezing the rows produces a single scalar Series:\n",
      " |      \n",
      " |      >>> df_0a.squeeze('rows')\n",
      " |      a    1\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      Squeezing all axes will project directly into a scalar:\n",
      " |      \n",
      " |      >>> df_0a.squeeze()\n",
      " |      1\n",
      " |  \n",
      " |  swapaxes(self: 'NDFrameT', axis1: 'Axis', axis2: 'Axis', copy: 'bool_t' = True) -> 'NDFrameT'\n",
      " |      Interchange axes and swap values axes appropriately.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self: 'NDFrameT', n: 'int' = 5) -> 'NDFrameT'\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the first `|n|` rows, equivalent to ``df[|n|:]``.\n",
      " |      \n",
      " |      If n is larger than the number of rows, this function returns all rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.tail(-3)\n",
      " |         animal\n",
      " |      3    lion\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |  \n",
      " |  take(self: 'NDFrameT', indices, axis=0, is_copy: 'bool_t | None' = None, **kwargs) -> 'NDFrameT'\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      is_copy : bool\n",
      " |          Before pandas 1.0, ``is_copy=False`` can be specified to ensure\n",
      " |          that the return value is an actual copy. Starting with pandas 1.0,\n",
      " |          ``take`` always returns a copy, and the keyword is therefore\n",
      " |          deprecated.\n",
      " |      \n",
      " |          .. deprecated:: 1.0.0\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_clipboard(self, excel: 'bool_t' = True, sep: 'str | None' = None, **kwargs) -> 'None'\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          Produce output in a csv format for easy pasting into excel.\n",
      " |      \n",
      " |          - True, use the provided separator for csv pasting.\n",
      " |          - False, write a string representation of the object to the clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_csv.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - macOS : none\n",
      " |      \n",
      " |      This method uses the processes developed for the package `pyperclip`. A\n",
      " |      solution to render any output string format is given in the examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',')  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |      \n",
      " |      Using the original `pyperclip` package for any string output format.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |         import pyperclip\n",
      " |         html = df.style.to_html()\n",
      " |         pyperclip.copy(html)\n",
      " |  \n",
      " |  to_csv(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | Callable | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', lineterminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Write object to a comma-separated values (csv) file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string. If a non-binary file object is passed, it should\n",
      " |          be opened with `newline=''`, disabling universal newlines. If a binary\n",
      " |          file object is passed, `mode` might need to contain a `'b'`.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Support for binary file objects was introduced.\n",
      " |      \n",
      " |      sep : str, default ','\n",
      " |          String of length 1. Field delimiter for the output file.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, Callable, default None\n",
      " |          Format string for floating point numbers. If a Callable is given, it takes\n",
      " |          precedence over other numeric formatting parameters, like decimal.\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the object uses MultiIndex. If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R.\n",
      " |      mode : str, default 'w'\n",
      " |          Python write mode. The available write modes are the same as\n",
      " |          :py:func:`open`.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      " |          is a non-binary file object.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      " |          key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |              .. versionadded:: 1.5.0\n",
      " |                  Added support for `.tar` files.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             May now be a dict with key 'method' as compression mode\n",
      " |             and other entries as additional compression options if\n",
      " |             compression mode is 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |             Passing compression options as keys in dict is\n",
      " |             supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              Compression is supported for binary file objects.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              Previous versions forwarded dict entries for 'gzip' to\n",
      " |              `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      " |              setting `mtime`.\n",
      " |      \n",
      " |      quoting : optional constant from csv module\n",
      " |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric.\n",
      " |      quotechar : str, default '\\\"'\n",
      " |          String of length 1. Character used to quote fields.\n",
      " |      lineterminator : str, optional\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file. Defaults to `os.linesep`, which depends on the OS in which\n",
      " |          this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      " |      \n",
      " |          .. versionchanged:: 1.5.0\n",
      " |      \n",
      " |              Previously was line_terminator, changed for consistency with\n",
      " |              read_csv and the standard library 'csv' module.\n",
      " |      \n",
      " |      chunksize : int or None\n",
      " |          Rows to write at a time.\n",
      " |      date_format : str, default None\n",
      " |          Format string for datetime objects.\n",
      " |      doublequote : bool, default True\n",
      " |          Control quoting of `quotechar` inside a field.\n",
      " |      escapechar : str, default None\n",
      " |          String of length 1. Character used to escape `sep` and `quotechar`\n",
      " |          when appropriate.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting csv format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_csv : Load a CSV file into a DataFrame.\n",
      " |      to_excel : Write DataFrame to an Excel file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> df.to_csv(index=False)\n",
      " |      'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      " |      \n",
      " |      Create 'out.zip' containing 'out.csv'\n",
      " |      \n",
      " |      >>> compression_opts = dict(method='zip',\n",
      " |      ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      " |      >>> df.to_csv('out.zip', index=False,\n",
      " |      ...           compression=compression_opts)  # doctest: +SKIP\n",
      " |      \n",
      " |      To write a csv file to a new folder or nested folder you will first\n",
      " |      need to create it using either Pathlib or os:\n",
      " |      \n",
      " |      >>> from pathlib import Path  # doctest: +SKIP\n",
      " |      >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |      >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      " |      \n",
      " |      >>> import os  # doctest: +SKIP\n",
      " |      >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name: 'str' = 'Sheet1', na_rep: 'str' = '', float_format: 'str | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'Sequence[Hashable] | bool_t' = True, index: 'bool_t' = True, index_label: 'IndexLabel' = None, startrow: 'int' = 0, startcol: 'int' = 0, engine: 'str | None' = None, merge_cells: 'bool_t' = True, encoding: 'lib.NoDefault' = <no_default>, inf_rep: 'str' = 'inf', verbose: 'lib.NoDefault' = <no_default>, freeze_panes: 'tuple[int, int] | None' = None, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Write object to an Excel sheet.\n",
      " |      \n",
      " |      To write a single object to an Excel .xlsx file it is only necessary to\n",
      " |      specify a target file name. To write to multiple sheets it is necessary to\n",
      " |      create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      " |      in the file to write to.\n",
      " |      \n",
      " |      Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      " |      With all data written to the file it is necessary to save the changes.\n",
      " |      Note that creating an `ExcelWriter` object with a file name that already\n",
      " |      exists will result in the contents of the existing file being erased.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : path-like, file-like, or ExcelWriter object\n",
      " |          File path or existing ExcelWriter.\n",
      " |      sheet_name : str, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, optional\n",
      " |          Format string for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      " |      columns : sequence or list of str, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, optional\n",
      " |          Column label for index column(s) if desired. If not specified, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow : int, default 0\n",
      " |          Upper left cell row to dump data frame.\n",
      " |      startcol : int, default 0\n",
      " |          Upper left cell column to dump data frame.\n",
      " |      engine : str, optional\n",
      " |          Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      " |          via the options ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      \n",
      " |          .. deprecated:: 1.2.0\n",
      " |      \n",
      " |              As the `xlwt <https://pypi.org/project/xlwt/>`__ package is no longer\n",
      " |              maintained, the ``xlwt`` engine will be removed in a future version\n",
      " |              of pandas.\n",
      " |      \n",
      " |      merge_cells : bool, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding : str, optional\n",
      " |          Encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |      \n",
      " |              This keyword was not used.\n",
      " |      \n",
      " |      inf_rep : str, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel).\n",
      " |      verbose : bool, default True\n",
      " |          Display more information in the error logs.\n",
      " |      \n",
      " |          .. deprecated:: 1.5.0\n",
      " |      \n",
      " |              This keyword was not used.\n",
      " |      \n",
      " |      freeze_panes : tuple of int (length 2), optional\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      " |      ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      " |      read_excel : Read an Excel file into a pandas DataFrame.\n",
      " |      read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |      io.formats.style.Styler.to_excel : Add styles to Excel sheet.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For compatibility with :meth:`~DataFrame.to_csv`,\n",
      " |      to_excel serializes lists and dicts to strings before writing.\n",
      " |      \n",
      " |      Once a workbook has been saved it is not possible to write further\n",
      " |      data without rewriting the whole workbook.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create, write to and save a workbook:\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                    index=['row 1', 'row 2'],\n",
      " |      ...                    columns=['col 1', 'col 2'])\n",
      " |      >>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      " |      \n",
      " |      To specify the sheet name:\n",
      " |      \n",
      " |      >>> df1.to_excel(\"output.xlsx\",\n",
      " |      ...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      " |      \n",
      " |      If you wish to write to more than one sheet in the workbook, it is\n",
      " |      necessary to specify an ExcelWriter object:\n",
      " |      \n",
      " |      >>> df2 = df1.copy()\n",
      " |      >>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      " |      ...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      " |      \n",
      " |      ExcelWriter can also be used to append to an existing Excel file:\n",
      " |      \n",
      " |      >>> with pd.ExcelWriter('output.xlsx',\n",
      " |      ...                     mode='a') as writer:  # doctest: +SKIP\n",
      " |      ...     df.to_excel(writer, sheet_name='Sheet_name_3')\n",
      " |      \n",
      " |      To set the library that is used to write the Excel file,\n",
      " |      you can pass the `engine` keyword (the default engine is\n",
      " |      automatically chosen depending on the file extension):\n",
      " |      \n",
      " |      >>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf: 'FilePath | HDFStore', key: 'str', mode: 'str' = 'a', complevel: 'int | None' = None, complib: 'str | None' = None, append: 'bool_t' = False, format: 'str | None' = None, index: 'bool_t' = True, min_itemsize: 'int | dict[str, int] | None' = None, nan_rep=None, dropna: 'bool_t | None' = None, data_columns: 'Literal[True] | list[str] | None' = None, errors: 'str' = 'strict', encoding: 'str' = 'UTF-8') -> 'None'\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         One can store a subclass of ``DataFrame`` or ``Series`` to HDF5,\n",
      " |         but the type of the subclass is lost upon storing.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      complevel : {0-9}, default None\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 or None disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      format : {'fixed', 'table', None}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |          - If None, pd.get_option('io.hdf.default_format') is checked,\n",
      " |            followed by fallback to \"fixed\".\n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column.\n",
      " |      min_itemsize : dict or int, optional\n",
      " |          Map column names to minimum string sizes for columns.\n",
      " |      nan_rep : Any, optional\n",
      " |          How to represent null values as str.\n",
      " |          Not allowed with append=True.\n",
      " |      dropna : bool, default False, optional\n",
      " |          Remove missing values.\n",
      " |      data_columns : list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See\n",
      " |          :ref:`Query via data columns<io.hdf5-query-data-columns>`. for\n",
      " |          more information.\n",
      " |          Applicable only to format='table'.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      encoding : str, default \"UTF-8\"\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_orc : Write a DataFrame to the binary orc format.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a SQL table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])  # doctest: +SKIP\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')  # doctest: +SKIP\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])  # doctest: +SKIP\n",
      " |      >>> s.to_hdf('data.h5', key='s')  # doctest: +SKIP\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')  # doctest: +SKIP\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')  # doctest: +SKIP\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  to_json(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, orient: 'str | None' = None, date_format: 'str | None' = None, double_precision: 'int' = 10, force_ascii: 'bool_t' = True, date_unit: 'str' = 'ms', default_handler: 'Callable[[Any], JSONSerializable] | None' = None, lines: 'bool_t' = False, compression: 'CompressionOptions' = 'infer', index: 'bool_t' = True, indent: 'int | None' = None, storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string.\n",
      " |      orient : str\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series:\n",
      " |      \n",
      " |              - default is 'index'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      " |      \n",
      " |          * DataFrame:\n",
      " |      \n",
      " |              - default is 'columns'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'columns',\n",
      " |                'values', 'table'}.\n",
      " |      \n",
      " |          * The format of the JSON string:\n",
      " |      \n",
      " |              - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      " |                'data' -> [values]}\n",
      " |              - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      " |              - 'index' : dict like {index -> {column -> value}}\n",
      " |              - 'columns' : dict like {column -> {index -> value}}\n",
      " |              - 'values' : just the values array\n",
      " |              - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |      \n",
      " |              Describing the data, where data component is like ``orient='records'``.\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : bool, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : str, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : bool, default False\n",
      " |          If 'orient' is 'records' write out line-delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not\n",
      " |          list-like.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      " |          key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |              .. versionadded:: 1.5.0\n",
      " |                  Added support for `.tar` files.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      indent : int, optional\n",
      " |         Length of whitespace used to indent each record.\n",
      " |      \n",
      " |         .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting json format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_json : Convert a JSON string to pandas object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      " |      indent the output but does insert newlines. Currently, ``indent=0``\n",
      " |      and the default ``indent=None`` are equivalent in pandas, though this\n",
      " |      may change in a future release.\n",
      " |      \n",
      " |      ``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      " |      This stores the version of `pandas` used in the latest revision of the\n",
      " |      schema.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import json\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      " |      ...     index=[\"row 1\", \"row 2\"],\n",
      " |      ...     columns=[\"col 1\", \"col 2\"],\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"split\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"columns\": [\n",
      " |              \"col 1\",\n",
      " |              \"col 2\"\n",
      " |          ],\n",
      " |          \"index\": [\n",
      " |              \"row 1\",\n",
      " |              \"row 2\"\n",
      " |          ],\n",
      " |          \"data\": [\n",
      " |              [\n",
      " |                  \"a\",\n",
      " |                  \"b\"\n",
      " |              ],\n",
      " |              [\n",
      " |                  \"c\",\n",
      " |                  \"d\"\n",
      " |              ]\n",
      " |          ]\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"records\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"index\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"row 1\": {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          \"row 2\": {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"columns\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"col 1\": {\n",
      " |              \"row 1\": \"a\",\n",
      " |              \"row 2\": \"c\"\n",
      " |          },\n",
      " |          \"col 2\": {\n",
      " |              \"row 1\": \"b\",\n",
      " |              \"row 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"values\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          [\n",
      " |              \"a\",\n",
      " |              \"b\"\n",
      " |          ],\n",
      " |          [\n",
      " |              \"c\",\n",
      " |              \"d\"\n",
      " |          ]\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding with Table Schema:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"table\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"schema\": {\n",
      " |              \"fields\": [\n",
      " |                  {\n",
      " |                      \"name\": \"index\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 1\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 2\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  }\n",
      " |              ],\n",
      " |              \"primaryKey\": [\n",
      " |                  \"index\"\n",
      " |              ],\n",
      " |              \"pandas_version\": \"1.4.0\"\n",
      " |          },\n",
      " |          \"data\": [\n",
      " |              {\n",
      " |                  \"index\": \"row 1\",\n",
      " |                  \"col 1\": \"a\",\n",
      " |                  \"col 2\": \"b\"\n",
      " |              },\n",
      " |              {\n",
      " |                  \"index\": \"row 2\",\n",
      " |                  \"col 1\": \"c\",\n",
      " |                  \"col 2\": \"d\"\n",
      " |              }\n",
      " |          ]\n",
      " |      }\n",
      " |  \n",
      " |  to_latex(self, buf: 'FilePath | WriteBuffer[str] | None' = None, columns: 'Sequence[Hashable] | None' = None, col_space: 'ColspaceArgType | None' = None, header: 'bool_t | Sequence[str]' = True, index: 'bool_t' = True, na_rep: 'str' = 'NaN', formatters: 'FormattersType | None' = None, float_format: 'FloatFormatType | None' = None, sparsify: 'bool_t | None' = None, index_names: 'bool_t' = True, bold_rows: 'bool_t' = False, column_format: 'str | None' = None, longtable: 'bool_t | None' = None, escape: 'bool_t | None' = None, encoding: 'str | None' = None, decimal: 'str' = '.', multicolumn: 'bool_t | None' = None, multicolumn_format: 'str | None' = None, multirow: 'bool_t | None' = None, caption: 'str | tuple[str, str] | None' = None, label: 'str | None' = None, position: 'str | None' = None) -> 'str | None'\n",
      " |      Render object to a LaTeX tabular, longtable, or nested table.\n",
      " |      \n",
      " |      Requires ``\\usepackage{booktabs}``.  The output can be copy/pasted\n",
      " |      into a main LaTeX document or read from an external file\n",
      " |      with ``\\input{table.tex}``.\n",
      " |      \n",
      " |      .. versionchanged:: 1.0.0\n",
      " |         Added caption and label arguments.\n",
      " |      \n",
      " |      .. versionchanged:: 1.2.0\n",
      " |         Added position argument, changed meaning of caption argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : list of label, optional\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, optional\n",
      " |          The minimum width of each column.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given,\n",
      " |          it is assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      na_rep : str, default 'NaN'\n",
      " |          Missing data representation.\n",
      " |      formatters : list of functions or dict of {str: function}, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function or str, optional, default None\n",
      " |          Formatter for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` and ``float_format=\"{:0.2f}\".format`` will\n",
      " |          both result in 0.1234 being formatted as 0.12.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row. By default, the value will be\n",
      " |          read from the config module.\n",
      " |      index_names : bool, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      bold_rows : bool, default False\n",
      " |          Make the row labels bold in the output.\n",
      " |      column_format : str, optional\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g. 'rcl' for 3\n",
      " |          columns. By default, 'l' will be used for all columns except\n",
      " |          columns of numbers, which default to 'r'.\n",
      " |      longtable : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. Use a longtable environment instead of tabular. Requires\n",
      " |          adding a \\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      multicolumn : bool, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      multirow : bool, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows. Requires adding a\n",
      " |          \\usepackage{multirow} to your LaTeX preamble. Will print\n",
      " |          centered labels (instead of top-aligned) across the contained\n",
      " |          rows, separating groups via clines. The default will be read\n",
      " |          from the pandas config module.\n",
      " |      caption : str or tuple, optional\n",
      " |          Tuple (full_caption, short_caption),\n",
      " |          which results in ``\\caption[short_caption]{full_caption}``;\n",
      " |          if a single string is passed, no short caption will be set.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |             Optionally allow caption to be a tuple ``(full_caption, short_caption)``.\n",
      " |      \n",
      " |      label : str, optional\n",
      " |          The LaTeX label to be placed inside ``\\label{}`` in the output.\n",
      " |          This is used with ``\\ref{}`` in the main ``.tex`` file.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      position : str, optional\n",
      " |          The LaTeX positional argument for tables, to be placed after\n",
      " |          ``\\begin{}`` in the output.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |              Returns\n",
      " |              -------\n",
      " |              str or None\n",
      " |                  If buf is None, returns the result as a string. Otherwise returns\n",
      " |                  None.\n",
      " |          \n",
      " |      See Also\n",
      " |      --------\n",
      " |      io.formats.style.Styler.to_latex : Render a DataFrame to LaTeX\n",
      " |          with conditional formatting.\n",
      " |      DataFrame.to_string : Render a DataFrame to a console-friendly\n",
      " |          tabular output.\n",
      " |      DataFrame.to_html : Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],\n",
      " |      ...                   mask=['red', 'purple'],\n",
      " |      ...                   weapon=['sai', 'bo staff']))\n",
      " |      >>> print(df.to_latex(index=False))  # doctest: +SKIP\n",
      " |      \\begin{tabular}{lll}\n",
      " |       \\toprule\n",
      " |             name &    mask &    weapon \\\\\n",
      " |       \\midrule\n",
      " |          Raphael &     red &       sai \\\\\n",
      " |        Donatello &  purple &  bo staff \\\\\n",
      " |      \\bottomrule\n",
      " |      \\end{tabular}\n",
      " |  \n",
      " |  to_pickle(self, path: 'FilePath | WriteBuffer[bytes]', compression: 'CompressionOptions' = 'infer', protocol: 'int' = 5, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, or file-like object\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. File path where\n",
      " |          the pickled object will be stored.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      " |          key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |              .. versionadded:: 1.5.0\n",
      " |                  Added support for `.tar` files.\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values are 0, 1, 2, 3, 4, 5. A negative value for the protocol\n",
      " |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})  # doctest: +SKIP\n",
      " |      >>> original_df  # doctest: +SKIP\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")  # doctest: +SKIP\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")  # doctest: +SKIP\n",
      " |      >>> unpickled_df  # doctest: +SKIP\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |  \n",
      " |  to_sql(self, name: 'str', con, schema: 'str | None' = None, if_exists: 'str' = 'fail', index: 'bool_t' = True, index_label: 'IndexLabel' = None, chunksize: 'int | None' = None, dtype: 'DtypeArg | None' = None, method: 'str | None' = None) -> 'int | None'\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects. The user\n",
      " |          is responsible for engine disposal and connection closure for the SQLAlchemy\n",
      " |          connectable See `here                 <https://docs.sqlalchemy.org/en/13/core/connections.html>`_.\n",
      " |      \n",
      " |      schema : str, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : str or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Specify the number of rows in each batch to be written at a time.\n",
      " |          By default, all rows will be written at once.\n",
      " |      dtype : dict or scalar, optional\n",
      " |          Specifying the datatype for columns. If a dictionary is used, the\n",
      " |          keys should be the column names and the values should be the\n",
      " |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
      " |          scalar is provided, it will be applied to all columns.\n",
      " |      method : {None, 'multi', callable}, optional\n",
      " |          Controls the SQL insertion clause used:\n",
      " |      \n",
      " |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      " |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      " |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      " |      \n",
      " |          Details and a sample callable implementation can be found in the\n",
      " |          section :ref:`insert method <io.sql.method>`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or int\n",
      " |          Number of rows affected by to_sql. None is returned if the callable\n",
      " |          passed into ``method`` does not return an integer number of rows.\n",
      " |      \n",
      " |          The number of returned rows affected is the sum of the ``rowcount``\n",
      " |          attribute of ``sqlite3.Cursor`` or SQLAlchemy connectable which may not\n",
      " |          reflect the exact number of written rows as stipulated in the\n",
      " |          `sqlite3 <https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.rowcount>`__ or\n",
      " |          `SQLAlchemy <https://docs.sqlalchemy.org/en/14/core/connections.html#sqlalchemy.engine.BaseCursorResult.rowcount>`__.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_sql : Read a DataFrame from a table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Timezone aware datetime columns will be written as\n",
      " |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      " |      database. Otherwise, the datetimes will be stored as timezone unaware\n",
      " |      timestamps local to the original timezone.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      3\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      An `sqlalchemy.engine.Connection` can also be passed to `con`:\n",
      " |      \n",
      " |      >>> with engine.begin() as connection:\n",
      " |      ...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      ...     df1.to_sql('users', con=connection, if_exists='append')\n",
      " |      2\n",
      " |      \n",
      " |      This is allowed to support operations that require that the same\n",
      " |      DBAPI connection is used for the entire operation.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})\n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='append')\n",
      " |      2\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),\n",
      " |       (1, 'User 7')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df2``.\n",
      " |      \n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      2\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 6'), (1, 'User 7')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      3\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray.DataArray or xarray.Dataset\n",
      " |          Data in the pandas structure converted to Dataset if the object is\n",
      " |          a DataFrame, or a DataArray if the object is a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <https://xarray.pydata.org/en/stable/>`__\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),\n",
      " |      ...                    ('parrot', 'bird', 24.0, 2),\n",
      " |      ...                    ('lion', 'mammal', 80.5, 4),\n",
      " |      ...                    ('monkey', 'mammal', np.nan, 4)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed',\n",
      " |      ...                            'num_legs'])\n",
      " |      >>> df\n",
      " |           name   class  max_speed  num_legs\n",
      " |      0  falcon    bird      389.0         2\n",
      " |      1  parrot    bird       24.0         2\n",
      " |      2    lion  mammal       80.5         4\n",
      " |      3  monkey  mammal        NaN         4\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:    (index: 4)\n",
      " |      Coordinates:\n",
      " |        * index      (index) int64 0 1 2 3\n",
      " |      Data variables:\n",
      " |          name       (index) object 'falcon' 'parrot' 'lion' 'monkey'\n",
      " |          class      (index) object 'bird' 'bird' 'mammal' 'mammal'\n",
      " |          max_speed  (index) float64 389.0 24.0 80.5 nan\n",
      " |          num_legs   (index) int64 2 2 4 4\n",
      " |      \n",
      " |      >>> df['max_speed'].to_xarray()\n",
      " |      <xarray.DataArray 'max_speed' (index: 4)>\n",
      " |      array([389. ,  24. ,  80.5,   nan])\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2 3\n",
      " |      \n",
      " |      >>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',\n",
      " |      ...                         '2018-01-02', '2018-01-02'])\n",
      " |      >>> df_multiindex = pd.DataFrame({'date': dates,\n",
      " |      ...                               'animal': ['falcon', 'parrot',\n",
      " |      ...                                          'falcon', 'parrot'],\n",
      " |      ...                               'speed': [350, 18, 361, 15]})\n",
      " |      >>> df_multiindex = df_multiindex.set_index(['date', 'animal'])\n",
      " |      \n",
      " |      >>> df_multiindex\n",
      " |                         speed\n",
      " |      date       animal\n",
      " |      2018-01-01 falcon    350\n",
      " |                 parrot     18\n",
      " |      2018-01-02 falcon    361\n",
      " |                 parrot     15\n",
      " |      \n",
      " |      >>> df_multiindex.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (date: 2, animal: 2)\n",
      " |      Coordinates:\n",
      " |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02\n",
      " |        * animal   (animal) object 'falcon' 'parrot'\n",
      " |      Data variables:\n",
      " |          speed    (date, animal) int64 350 18 361 15\n",
      " |  \n",
      " |  truncate(self: 'NDFrameT', before=None, after=None, axis=None, copy: 'bool_t' = True) -> 'NDFrameT'\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, str, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, str, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      copy : bool, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                   index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self: 'NDFrameT', periods: 'int' = 1, freq=None, axis: 'Axis' = 0) -> 'NDFrameT'\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      .. deprecated:: 1.1.0\n",
      " |          Use `shift` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      freq : DateOffset, timedelta, or str, default None\n",
      " |          Increment to use from the tseries module\n",
      " |          or time rule expressed as a string (e.g. 'EOM').\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
      " |          Corresponds to the axis that contains the Index.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series/DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |  \n",
      " |  tz_convert(self: 'NDFrameT', tz, axis=0, level=None, copy: 'bool_t' = True) -> 'NDFrameT'\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis is a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Object with time zone converted axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self: 'NDFrameT', tz, axis=0, level=None, copy: 'bool_t' = True, ambiguous='raise', nonexistent: 'str' = 'raise') -> 'NDFrameT'\n",
      " |      Localize tz-naive index of a Series or DataFrame to target time zone.\n",
      " |      \n",
      " |      This operation localizes the Index. To localize the values in a\n",
      " |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      nonexistent : str, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST. Valid values are:\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Same type as the input.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Localize local times:\n",
      " |      \n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00']))\n",
      " |      >>> s.tz_localize('CET')\n",
      " |      2018-09-15 01:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Be careful with DST changes. When there is sequential data, pandas\n",
      " |      can infer the DST time:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(7),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 03:00:00',\n",
      " |      ...                                       '2018-10-28 03:30:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous='infer')\n",
      " |      2018-10-28 01:30:00+02:00    0\n",
      " |      2018-10-28 02:00:00+02:00    1\n",
      " |      2018-10-28 02:30:00+02:00    2\n",
      " |      2018-10-28 02:00:00+01:00    3\n",
      " |      2018-10-28 02:30:00+01:00    4\n",
      " |      2018-10-28 03:00:00+01:00    5\n",
      " |      2018-10-28 03:30:00+01:00    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',\n",
      " |      ...                                       '2018-10-28 02:36:00',\n",
      " |      ...                                       '2018-10-28 03:46:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      2018-10-28 01:20:00+02:00    0\n",
      " |      2018-10-28 02:36:00+02:00    1\n",
      " |      2018-10-28 03:46:00+01:00    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backward with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backward'`.\n",
      " |      \n",
      " |      >>> s = pd.Series(range(2),\n",
      " |      ...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',\n",
      " |      ...                                       '2015-03-29 03:30:00']))\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      2015-03-29 03:00:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      2015-03-29 01:59:59.999999999+01:00    0\n",
      " |      2015-03-29 03:30:00+02:00              1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))\n",
      " |      2015-03-29 03:30:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  xs(self: 'NDFrameT', key: 'IndexLabel', axis: 'Axis' = 0, level: 'IndexLabel' = None, drop_level: 'bool_t' = True) -> 'NDFrameT'\n",
      " |      Return cross-section from the Series/DataFrame.\n",
      " |      \n",
      " |      This method takes a `key` argument to select data at a particular\n",
      " |      level of a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label or tuple of label\n",
      " |          Label contained in the index, or partially in a MultiIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to retrieve cross-section on.\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : bool, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Cross-section from the original Series or DataFrame\n",
      " |          corresponding to the selected index levels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      DataFrame.iloc : Purely integer-location based indexing\n",
      " |          for selection by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `xs` can not be used to set values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on\n",
      " |      any level or levels.\n",
      " |      It is a superset of `xs` functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'num_legs': [4, 4, 2, 2],\n",
      " |      ...      'num_wings': [0, 0, 2, 2],\n",
      " |      ...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
      " |      ...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
      " |      ...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df = df.set_index(['class', 'animal', 'locomotion'])\n",
      " |      >>> df\n",
      " |                                 num_legs  num_wings\n",
      " |      class  animal  locomotion\n",
      " |      mammal cat     walks              4          0\n",
      " |             dog     walks              4          0\n",
      " |             bat     flies              2          2\n",
      " |      bird   penguin walks              2          2\n",
      " |      \n",
      " |      Get values at specified index\n",
      " |      \n",
      " |      >>> df.xs('mammal')\n",
      " |                         num_legs  num_wings\n",
      " |      animal locomotion\n",
      " |      cat    walks              4          0\n",
      " |      dog    walks              4          0\n",
      " |      bat    flies              2          2\n",
      " |      \n",
      " |      Get values at several indexes\n",
      " |      \n",
      " |      >>> df.xs(('mammal', 'dog'))\n",
      " |                  num_legs  num_wings\n",
      " |      locomotion\n",
      " |      walks              4          0\n",
      " |      \n",
      " |      Get values at specified index and level\n",
      " |      \n",
      " |      >>> df.xs('cat', level=1)\n",
      " |                         num_legs  num_wings\n",
      " |      class  locomotion\n",
      " |      mammal walks              4          0\n",
      " |      \n",
      " |      Get values at several indexes and levels\n",
      " |      \n",
      " |      >>> df.xs(('bird', 'walks'),\n",
      " |      ...       level=[0, 'locomotion'])\n",
      " |               num_legs  num_wings\n",
      " |      animal\n",
      " |      penguin         2          2\n",
      " |      \n",
      " |      Get values at specified column and axis\n",
      " |      \n",
      " |      >>> df.xs('num_wings', axis=1)\n",
      " |      class   animal   locomotion\n",
      " |      mammal  cat      walks         0\n",
      " |              dog      walks         0\n",
      " |              bat      flies         2\n",
      " |      bird    penguin  walks         2\n",
      " |      Name: num_wings, dtype: int64\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  empty\n",
      " |      Indicator whether Series/DataFrame is empty.\n",
      " |      \n",
      " |      True if Series/DataFrame is entirely empty (no items), meaning any of the\n",
      " |      axes are of length 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          If Series/DataFrame is empty, return True, if not return False.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If Series/DataFrame contains only NaNs, it is still not considered empty. See\n",
      " |      the example below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      An example of an actual empty DataFrame. Notice the index is empty:\n",
      " |      \n",
      " |      >>> df_empty = pd.DataFrame({'A' : []})\n",
      " |      >>> df_empty\n",
      " |      Empty DataFrame\n",
      " |      Columns: [A]\n",
      " |      Index: []\n",
      " |      >>> df_empty.empty\n",
      " |      True\n",
      " |      \n",
      " |      If we only have NaNs in our DataFrame, it is not considered empty! We\n",
      " |      will need to drop the NaNs to make the DataFrame empty:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [np.nan]})\n",
      " |      >>> df\n",
      " |          A\n",
      " |      0 NaN\n",
      " |      >>> df.empty\n",
      " |      False\n",
      " |      >>> df.dropna().empty\n",
      " |      True\n",
      " |      \n",
      " |      >>> ser_empty = pd.Series({'A' : []})\n",
      " |      >>> ser_empty\n",
      " |      A    []\n",
      " |      dtype: object\n",
      " |      >>> ser_empty.empty\n",
      " |      False\n",
      " |      >>> ser_empty = pd.Series()\n",
      " |      >>> ser_empty.empty\n",
      " |      True\n",
      " |  \n",
      " |  flags\n",
      " |      Get the properties associated with this pandas object.\n",
      " |      \n",
      " |      The available flags are\n",
      " |      \n",
      " |      * :attr:`Flags.allows_duplicate_labels`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Flags : Flags that apply to pandas objects.\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags\n",
      " |      <Flags(allows_duplicate_labels=True)>\n",
      " |      \n",
      " |      Flags can be get or set using ``.``\n",
      " |      \n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df.flags.allows_duplicate_labels = False\n",
      " |      \n",
      " |      Or by slicing with a key\n",
      " |      \n",
      " |      >>> df.flags[\"allows_duplicate_labels\"]\n",
      " |      False\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"] = True\n",
      " |  \n",
      " |  ndim\n",
      " |      Return an int representing the number of axes / array dimensions.\n",
      " |      \n",
      " |      Return 1 if Series. Otherwise return 2 if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.ndim : Number of array dimensions.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.ndim\n",
      " |      1\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.ndim\n",
      " |      2\n",
      " |  \n",
      " |  size\n",
      " |      Return an int representing the number of elements in this object.\n",
      " |      \n",
      " |      Return the number of rows if Series. Otherwise return the number of\n",
      " |      rows times number of columns if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.size : Number of elements in the array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.size\n",
      " |      3\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.size\n",
      " |      4\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  attrs\n",
      " |      Dictionary of global attributes of this dataset.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         attrs is experimental and may change without warning.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.indexing.IndexingMixin:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          * If getting a value and 'label' does not exist in a DataFrame or\n",
      " |              Series.\n",
      " |      ValueError\n",
      " |          * If row/column label pair is not a tuple or if any label from\n",
      " |              the pair is not a scalar for DataFrame.\n",
      " |          * If label is list-like (*excluding* NamedTuple) for Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column pair by label.\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer\n",
      " |          position(s).\n",
      " |      Series.at : Access a single value by label.\n",
      " |      Series.iat : Access a single value by integer position.\n",
      " |      Series.loc : Access a group of rows by label(s).\n",
      " |      Series.iloc : Access a group of rows by integer position(s).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Fast scalar value getting and setting <indexing.basics.get_value>`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above).\n",
      " |        This is useful in method chains, when you don't have a reference to the\n",
      " |        calling object, but would like to base your selection on some value.\n",
      " |      - A tuple of row and column indexes. The tuple elements consist of one of the\n",
      " |        above inputs, e.g. ``(0, 1)``.\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Fast integer location scalar accessor.\n",
      " |      DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      " |      Series.iloc : Purely integer-location based indexing for\n",
      " |                     selection by position.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      " |      ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      " |      ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
      " |      >>> df = pd.DataFrame(mydict)\n",
      " |      >>> df\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing just the rows**\n",
      " |      \n",
      " |      With a scalar integer.\n",
      " |      \n",
      " |      >>> type(df.iloc[0])\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      >>> df.iloc[0]\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      d    4\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      With a list of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0]]\n",
      " |         a  b  c  d\n",
      " |      0  1  2  3  4\n",
      " |      >>> type(df.iloc[[0]])\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      \n",
      " |      >>> df.iloc[[0, 1]]\n",
      " |           a    b    c    d\n",
      " |      0    1    2    3    4\n",
      " |      1  100  200  300  400\n",
      " |      \n",
      " |      With a `slice` object.\n",
      " |      \n",
      " |      >>> df.iloc[:3]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a boolean mask the same length as the index.\n",
      " |      \n",
      " |      >>> df.iloc[[True, False, True]]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a callable, useful in method chains. The `x` passed\n",
      " |      to the ``lambda`` is the DataFrame being sliced. This selects\n",
      " |      the rows whose index label even.\n",
      " |      \n",
      " |      >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing both axes**\n",
      " |      \n",
      " |      You can mix the indexer types for the index and columns. Use ``:`` to\n",
      " |      select the entire axis.\n",
      " |      \n",
      " |      With scalar integers.\n",
      " |      \n",
      " |      >>> df.iloc[0, 1]\n",
      " |      2\n",
      " |      \n",
      " |      With lists of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0, 2], [1, 3]]\n",
      " |            b     d\n",
      " |      0     2     4\n",
      " |      2  2000  4000\n",
      " |      \n",
      " |      With `slice` objects.\n",
      " |      \n",
      " |      >>> df.iloc[1:3, 0:3]\n",
      " |            a     b     c\n",
      " |      1   100   200   300\n",
      " |      2  1000  2000  3000\n",
      " |      \n",
      " |      With a boolean array whose length matches the columns.\n",
      " |      \n",
      " |      >>> df.iloc[:, [True, False, True, False]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |      \n",
      " |      With a callable function that expects the Series or DataFrame.\n",
      " |      \n",
      " |      >>> df.iloc[:, lambda df: [0, 2]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - An alignable boolean Series. The index of the key will be aligned before\n",
      " |        masking.\n",
      " |      - An alignable Index. The Index of the returned selection will be the input.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any items are not found.\n",
      " |      IndexingError\n",
      " |          If an indexed key is passed and its index is unalignable to the frame index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Alignable boolean Series:\n",
      " |      \n",
      " |      >>> df.loc[pd.Series([False, True, False],\n",
      " |      ...        index=['viper', 'sidewinder', 'cobra'])]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Index (same behavior as ``df.reindex``)\n",
      " |      \n",
      " |      >>> df.loc[pd.Index([\"cobra\", \"viper\"], name=\"foo\")]\n",
      " |             max_speed  shield\n",
      " |      foo\n",
      " |      cobra          1       2\n",
      " |      viper          4       5\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |      \n",
      " |      Please see the :ref:`user guide<advanced.advanced_hierarchical>`\n",
      " |      for more details and explanations of advanced indexing.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  __and__(self, other)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __floordiv__(self, other)\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, other)\n",
      " |  \n",
      " |  __mul__(self, other)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __or__(self, other)\n",
      " |  \n",
      " |  __pow__(self, other)\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |  \n",
      " |  __rand__(self, other)\n",
      " |  \n",
      " |  __rfloordiv__(self, other)\n",
      " |  \n",
      " |  __rmod__(self, other)\n",
      " |  \n",
      " |  __rmul__(self, other)\n",
      " |  \n",
      " |  __ror__(self, other)\n",
      " |  \n",
      " |  __rpow__(self, other)\n",
      " |  \n",
      " |  __rsub__(self, other)\n",
      " |  \n",
      " |  __rtruediv__(self, other)\n",
      " |  \n",
      " |  __rxor__(self, other)\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |  \n",
      " |  __truediv__(self, other)\n",
      " |  \n",
      " |  __xor__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ctl.Timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WOLF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WOLF_CTLSB = ctl.ControlSBML(\"https://www.ebi.ac.uk/biomodels/model/download/BIOMD0000000206.2?filename=BIOMD0000000206_url.xml\", \n",
    "                        input_names=[\"at\"], output_names=[\"s5\"])\n",
    "WOLF_RR = WOLF_CTLSB.roadrunner\n",
    "WOLF_RR.simulate(0, 1, 100)\n",
    "WOLF_RR.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlDsf1MeLSC0"
   },
   "source": [
    "# Sequential Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "ZpD-B4pljgpz",
    "outputId": "edb393b7-a9d0-4097-b2c8-e380a1c00fd6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LINEAR_MDL= \"\"\"\n",
    "S1 -> S2; k1*S1\n",
    "S2 -> S3; k2*S2\n",
    "\n",
    "S1 = 10\n",
    "S2 = 0\n",
    "S3 = 0\n",
    "k1 = 2\n",
    "k2 = 1\n",
    "\"\"\"\n",
    "LINEAR_RR = te.loada(LINEAR_MDL)\n",
    "LINEAR_RR.plot(LINEAR_RR.simulate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzEL6BDSkF1w"
   },
   "source": [
    "How do we explain this behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRGYXd5wq6gW"
   },
   "source": [
    "For the system $\\dot{{\\bf x}} (t) = {\\bf A} {\\bf x}(t)$, the solution is \n",
    "${\\bf x}(t) = \\sum_{n=1}^N c_n {\\bf u}_n e^{\\lambda_n t}$, where the $c_n$ are computed from ${\\bf x})0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "bgtShlLnkIVY",
    "outputId": "4a651e35-7625-4299-f006-c7877c64f845"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     S1   S2   S3\n",
       "S1 -2.0  0.0  0.0\n",
       "S2  2.0 -1.0  0.0\n",
       "S3  0.0  1.0  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A is the Jacobian\n",
    "A = LINEAR_RR.getFullJacobian()\n",
    "ctl.mat2DF(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -1., -2.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "eb5_yZTKGxEQ",
    "outputId": "d683da90-137a-456c-8ee5-8f1da18f352a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "S1  0.0\n",
       "S2 -1.0\n",
       "S3 -2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "ctl.mat2DF(eigenvalues, row_names=A.rownames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "Iwregm7PDilE",
    "outputId": "0507db7f-eb61-41e6-f320-2e932984776b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>-1</th>\n",
       "      <th>-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        -1        -2\n",
       "S1  0.0  0.000000  0.408248\n",
       "S2  0.0  0.707107 -0.816497\n",
       "S3  1.0 -0.707107  0.408248"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctl.mat2DF(eigenvectors, column_names=[\"0\", \"-1\", \"-2\"], \n",
    "           row_names=[\"S1\", \"S2\", \"S3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhROIpUcsOXj"
   },
   "source": [
    "To find the $c_n$, we solve ${\\bf U} {\\bf c} = {\\bf x}(0)$.\n",
    "Or, ${\\bf U}^{-1} {\\bf x}(0) = {\\bf c}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTlB5N3ssqc8",
    "outputId": "c5e8eac9-c1d6-45e3-c9c6-4c24ada29c03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the eigenvectors are linearly independent. So, the above inverse exists, and \n",
    "# we get a unique solution for the linear system.\n",
    "np.linalg.matrix_rank(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6h08BHIZtF1T",
    "outputId": "85a5c7c7-31c0-4895-8901-60d2c2af05a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.         28.28427125 24.49489743]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.linalg.inv(eigenvectors), np.array([10, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eqt63xfttWW2",
    "outputId": "d7ebf98c-aab0-4d32-87f0-f97985160830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "def calcX(A, time, x0):\n",
    "    \"\"\"\n",
    "    Calculate the time solution of a linear system with initial values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A: np.ndarray (N X N)\n",
    "    time: float\n",
    "    x0: np.ndarray (N X 1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nd.array (N X 1)\n",
    "    \"\"\"\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "    eigenvectors_inv = np.linalg.inv(eigenvectors)\n",
    "    c_vec = np.matmul(eigenvectors_inv, x0)\n",
    "    c_mat = np.diag(c_vec)\n",
    "    result1 = np.matmul(eigenvectors, c_mat)\n",
    "    exp_vec = np.array([np.e**(time*v) for  v in eigenvalues])\n",
    "    result = np.matmul(result1, exp_vec)\n",
    "    return result\n",
    "    \n",
    "# TESTS\n",
    "x0 = np.array([10, 0, 0])\n",
    "x = calcX(A, 0, x0)\n",
    "assert(all([np.isclose(x[n], x0[n], 0) for n in range(len(x))]))\n",
    "assert(x[0] == x0[0])\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmxX_LTQLw2a",
    "outputId": "2c8de5a9-82c3-4178-c973-e09bac95794d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "def getXEigens(A, time, x0):\n",
    "    \"\"\"\n",
    "    Calculates the contributions of the different eigenvectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A: np.ndarray (N X N)\n",
    "    time: float\n",
    "    x0: np.ndarray (N X 1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Column: eigenvalue\n",
    "        Row: species\n",
    "    \"\"\"\n",
    "    N = np.shape(A)[0]\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "    eigenvectors_inv = np.linalg.inv(eigenvectors)\n",
    "    c_vec = np.matmul(eigenvectors_inv, x0)\n",
    "    weighted_eigens = [c_vec[n]*eigenvectors[:, n] for n in range(N)]\n",
    "    exp_vec =[np.e**(time*v) for  v in eigenvalues]\n",
    "    weighted_eigens = [w*e for w, e in zip(weighted_eigens, exp_vec)]\n",
    "    df = pd.DataFrame(weighted_eigens).transpose()\n",
    "    if \"rownames\" in dir(A):\n",
    "        if len(A.rownames) > 0:\n",
    "            rownames = A.rownames\n",
    "        else:\n",
    "            rownames = None\n",
    "    else:\n",
    "        rownames = None\n",
    "    df.index = rownames\n",
    "    df.columns = [round(v, 4) for v in eigenvalues]\n",
    "    df[\"total\"] = df.sum(axis=1)\n",
    "    return df\n",
    "    \n",
    "# TESTS\n",
    "x0 = np.array([10, 0, 0])\n",
    "df = getXEigens(A, 1, x0)\n",
    "assert(isinstance(df, pd.DataFrame))\n",
    "assert(len(df) > 0)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "8dCZsOaWSEu5",
    "outputId": "bc18506c-9d89-4d10-c37d-db1310079783"
   },
   "outputs": [],
   "source": [
    "dfss = [[] for n in range(4)]  # Container for the data frames\n",
    "fuzz = 0.2\n",
    "# Collect the weighted eigenvalues over time\n",
    "x0 = np.array([10, 0, 0])\n",
    "times = makeSimulationTimes(end_time=5)\n",
    "for time in times:\n",
    "    df = getXEigens(A, time, x0)\n",
    "    columns = list(df.columns)\n",
    "    for idx, col in enumerate(columns):\n",
    "        col_df = pd.DataFrame(df[col]).transpose()\n",
    "        dfss[idx].append(col_df)\n",
    "df_dct = {}\n",
    "for dfs in dfss:\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "    df = df.applymap(lambda v: v + np.random.rand()*fuzz)\n",
    "    lams = list(df.index)\n",
    "    if isinstance(lams[0], str):\n",
    "        lam = lams[0]\n",
    "    else:\n",
    "        lam = str(int(lams[0]))\n",
    "    df.index = times\n",
    "    df_dct[lam] = ctl.Timeseries(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot: title={'center': 'S1'}, xlabel='time'>,\n",
       "        <AxesSubplot: title={'center': 'S2'}, xlabel='time'>,\n",
       "        <AxesSubplot: title={'center': 'S3'}, xlabel='time'>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tss = list(df_dct.values())\n",
    "ctl.plotManyTS(*tss, ncol=3, figsize=(15, 5), names=[\"l=0\", \"l=-1\", \"l=-2\", \"total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ts88w43APvg9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.0  -1.0  -2.0         total\n",
      "S1   0.0   0.0  10.0  1.000000e+01\n",
      "S2   0.0  20.0 -20.0 -3.552714e-15\n",
      "S3  10.0 -20.0  10.0  1.776357e-15\n",
      "     0.0       -1.0       -2.0     total\n",
      "S1   0.0   0.000000   6.703200  6.703200\n",
      "S2   0.0  16.374615 -13.406401  2.968214\n",
      "S3  10.0 -16.374615   6.703200  0.328585\n",
      "     0.0       -1.0      -2.0     total\n",
      "S1   0.0   0.000000  3.678794  3.678794\n",
      "S2   0.0  12.130613 -7.357589  4.773024\n",
      "S3  10.0 -12.130613  3.678794  1.548181\n",
      "     0.0      -1.0      -2.0     total\n",
      "S1   0.0  0.000000  1.353353  1.353353\n",
      "S2   0.0  7.357589 -2.706706  4.650883\n",
      "S3  10.0 -7.357589  1.353353  3.995764\n",
      "     0.0      -1.0      -2.0     total\n",
      "S1   0.0  0.000000  0.183156  0.183156\n",
      "S2   0.0  2.706706 -0.366313  2.340393\n",
      "S3  10.0 -2.706706  0.183156  7.476451\n",
      "     0.0      -1.0      -2.0     total\n",
      "S1   0.0  0.000000  0.003355  0.003355\n",
      "S2   0.0  0.366313 -0.006709  0.359604\n",
      "S3  10.0 -0.366313  0.003355  9.637042\n"
     ]
    }
   ],
   "source": [
    "# Create 4 Timeseries, one for each eigenvector and one for the total.\n",
    "# Then create 3 Timeseries, one for each species with a column for each eigenvalue\n",
    "# Plot over time.\n",
    "for time in [0, 0.2, 0.5, 1, 2, 4]:\n",
    "    ctl.ppMat(getXEigens(A, time, x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3Zmtewns878r"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare with Tellurium simulation\n",
    "times = np.linspace(0, 5, 51)\n",
    "times\n",
    "result = np.array([calcX(A, t, x0) for t in times])\n",
    "plt.plot(times, result)\n",
    "plt.title(\"Calculated\")\n",
    "LINEAR_RR.reset()\n",
    "LINEAR_RR.plot(LINEAR_RR.simulate(), title=\"Simulated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximations with linear differential equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x297b452e0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(LINEAR_DF.index, LINEAR_DF[\"S2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Dynamical-Systems-Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
